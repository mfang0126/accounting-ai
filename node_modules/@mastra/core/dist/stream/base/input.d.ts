import type { LanguageModelV2StreamPart } from '@ai-sdk/provider-v5';
import { MastraBase } from '../../base.js';
import type { ChunkType, CreateStream, OnResult } from '../types.js';
/**
 * Safely enqueue a chunk into a ReadableStreamDefaultController.
 * Returns true if the enqueue succeeded, false if the controller was already closed/errored.
 *
 * Prefer this over checking desiredSize before enqueue, because desiredSize === 0
 * indicates backpressure (queue full, stream still open) â€” not closure.
 * Guarding on desiredSize would silently drop chunks under normal backpressure.
 */
export declare function safeEnqueue<T>(controller: ReadableStreamDefaultController<T>, chunk: T): boolean;
/**
 * Safely close a ReadableStreamDefaultController.
 * Returns true if the close succeeded, false if the controller was already closed/errored.
 */
export declare function safeClose(controller: ReadableStreamDefaultController<any>): boolean;
/**
 * Safely signal an error on a ReadableStreamDefaultController.
 * Returns true if the error succeeded, false if the controller was already closed/errored.
 */
export declare function safeError(controller: ReadableStreamDefaultController<any>, error: unknown): boolean;
export declare abstract class MastraModelInput extends MastraBase {
    abstract transform({ runId, stream, controller, }: {
        runId: string;
        stream: ReadableStream<LanguageModelV2StreamPart | Record<string, unknown>>;
        controller: ReadableStreamDefaultController<ChunkType>;
    }): Promise<void>;
    initialize({ runId, createStream, onResult }: {
        createStream: CreateStream;
        runId: string;
        onResult: OnResult;
    }): ReadableStream<ChunkType>;
}
//# sourceMappingURL=input.d.ts.map
import { createTool } from './chunk-63G75DJE.js';
import { MastraBase } from './chunk-WCAFTXGK.js';
import { RegisteredLogger } from './chunk-X2WMFSPB.js';
import posixPath from 'path/posix';
import { constants, existsSync } from 'fs';
import * as fs2 from 'fs/promises';
import * as nodePath from 'path';
import nodePath__default, { parse, join, dirname } from 'path';
import picomatch from 'picomatch';
import { createRequire } from 'module';
import { pathToFileURL } from 'url';
import * as childProcess from 'child_process';
import { execFileSync } from 'child_process';
import * as crypto from 'crypto';
import { createHash } from 'crypto';
import matter from 'gray-matter';
import * as os from 'os';
import os__default from 'os';
import { Readable, Writable } from 'stream';
import { z } from 'zod';

// src/workspace/errors.ts
var WorkspaceError = class extends Error {
  constructor(message, code, workspaceId) {
    super(message);
    this.code = code;
    this.workspaceId = workspaceId;
    this.name = "WorkspaceError";
  }
};
var WorkspaceNotAvailableError = class extends WorkspaceError {
  constructor() {
    super("Workspace not available. Ensure the agent has a workspace configured.", "NO_WORKSPACE");
    this.name = "WorkspaceNotAvailableError";
  }
};
var FilesystemNotAvailableError = class extends WorkspaceError {
  constructor() {
    super("Workspace does not have a filesystem configured", "NO_FILESYSTEM");
    this.name = "FilesystemNotAvailableError";
  }
};
var SandboxNotAvailableError = class extends WorkspaceError {
  constructor(message) {
    super(message ?? "Workspace does not have a sandbox configured", "NO_SANDBOX");
    this.name = "SandboxNotAvailableError";
  }
};
var SandboxFeatureNotSupportedError = class extends WorkspaceError {
  constructor(feature) {
    super(`Sandbox does not support ${feature}`, "FEATURE_NOT_SUPPORTED");
    this.name = "SandboxFeatureNotSupportedError";
  }
};
var SearchNotAvailableError = class extends WorkspaceError {
  constructor() {
    super("Workspace does not have search configured (enable bm25 or provide vectorStore + embedder)", "NO_SEARCH");
    this.name = "SearchNotAvailableError";
  }
};
var WorkspaceNotReadyError = class extends WorkspaceError {
  constructor(workspaceId, status) {
    super(`Workspace is not ready (status: ${status})`, "NOT_READY", workspaceId);
    this.name = "WorkspaceNotReadyError";
  }
};
var WorkspaceReadOnlyError = class extends WorkspaceError {
  constructor(operation) {
    super(`Workspace is in read-only mode. Cannot perform: ${operation}`, "READ_ONLY");
    this.name = "WorkspaceReadOnlyError";
  }
};
var FilesystemError = class extends Error {
  constructor(message, code, path6) {
    super(message);
    this.code = code;
    this.path = path6;
    this.name = "FilesystemError";
  }
};
var FileNotFoundError = class extends FilesystemError {
  constructor(path6) {
    super(`File not found: ${path6}`, "ENOENT", path6);
    this.name = "FileNotFoundError";
  }
};
var DirectoryNotFoundError = class extends FilesystemError {
  constructor(path6) {
    super(`Directory not found: ${path6}`, "ENOENT", path6);
    this.name = "DirectoryNotFoundError";
  }
};
var FileExistsError = class extends FilesystemError {
  constructor(path6) {
    super(`File already exists: ${path6}`, "EEXIST", path6);
    this.name = "FileExistsError";
  }
};
var IsDirectoryError = class extends FilesystemError {
  constructor(path6) {
    super(`Path is a directory: ${path6}`, "EISDIR", path6);
    this.name = "IsDirectoryError";
  }
};
var NotDirectoryError = class extends FilesystemError {
  constructor(path6) {
    super(`Path is not a directory: ${path6}`, "ENOTDIR", path6);
    this.name = "NotDirectoryError";
  }
};
var DirectoryNotEmptyError = class extends FilesystemError {
  constructor(path6) {
    super(`Directory not empty: ${path6}`, "ENOTEMPTY", path6);
    this.name = "DirectoryNotEmptyError";
  }
};
var PermissionError = class extends FilesystemError {
  constructor(path6, operation) {
    super(`Permission denied: ${operation} on ${path6}`, "EACCES", path6);
    this.operation = operation;
    this.name = "PermissionError";
  }
};
var FileReadRequiredError = class extends FilesystemError {
  constructor(path6, reason) {
    super(reason, "EREAD_REQUIRED", path6);
    this.name = "FileReadRequiredError";
  }
};
var FilesystemNotReadyError = class extends FilesystemError {
  constructor(id) {
    super(`Filesystem "${id}" is not ready. Call init() first or use ensureReady().`, "ENOTREADY", id);
    this.name = "FilesystemNotReadyError";
  }
};

// src/workspace/lifecycle.ts
async function callLifecycle(provider, method) {
  const wrapped = `_${method}`;
  const wrappedFn = provider[wrapped];
  if (typeof wrappedFn === "function") {
    await wrappedFn.call(provider);
  } else {
    const plainFn = provider[method];
    if (typeof plainFn === "function") {
      await plainFn.call(provider);
    }
  }
}

// src/workspace/filesystem/composite-filesystem.ts
var CompositeFilesystem = class {
  id;
  name = "CompositeFilesystem";
  provider = "composite";
  readOnly;
  status = "ready";
  _mounts;
  constructor(config) {
    this.id = `cfs-${Date.now().toString(36)}`;
    this._mounts = /* @__PURE__ */ new Map();
    for (const [path6, fs5] of Object.entries(config.mounts)) {
      const normalized = this.normalizePath(path6);
      this._mounts.set(normalized, fs5);
    }
    if (this._mounts.size === 0) {
      throw new Error("CompositeFilesystem requires at least one mount");
    }
    this.readOnly = [...this._mounts.values()].every((fs5) => fs5.readOnly) || void 0;
    const mountPaths = [...this._mounts.keys()];
    for (const a of mountPaths) {
      for (const b of mountPaths) {
        if (a !== b && b.startsWith(a + "/")) {
          throw new Error(`Nested mount paths are not supported: "${b}" is nested under "${a}"`);
        }
      }
    }
  }
  /**
   * Get all mount paths.
   */
  get mountPaths() {
    return Array.from(this._mounts.keys());
  }
  /**
   * Get the mounts map.
   * Returns a typed map where `get()` preserves the concrete filesystem type per mount path.
   */
  get mounts() {
    return this._mounts;
  }
  /**
   * Get status and metadata for this composite filesystem.
   * Includes info from each mounted filesystem in `metadata.mounts`.
   */
  async getInfo() {
    const mounts = {};
    for (const [mountPath, fs5] of this._mounts) {
      mounts[mountPath] = await fs5.getInfo?.() ?? null;
    }
    return {
      id: this.id,
      name: this.name,
      provider: this.provider,
      status: this.status,
      readOnly: this.readOnly,
      metadata: { mounts }
    };
  }
  /**
   * Get the underlying filesystem for a given path.
   * Returns undefined if the path doesn't resolve to any mount.
   */
  getFilesystemForPath(path6) {
    const resolved = this.resolveMount(path6);
    return resolved?.fs;
  }
  /**
   * Get the mount path for a given path.
   * Returns undefined if the path doesn't resolve to any mount.
   */
  getMountPathForPath(path6) {
    const resolved = this.resolveMount(path6);
    return resolved?.mountPath;
  }
  /**
   * Resolve a workspace-relative path to an absolute disk path.
   * Strips the mount prefix and delegates to the underlying filesystem.
   */
  resolveAbsolutePath(path6) {
    const r = this.resolveMount(path6);
    if (!r) return void 0;
    return r.fs.resolveAbsolutePath?.(r.fsPath);
  }
  normalizePath(path6) {
    if (!path6 || path6 === "/") return "/";
    let n = posixPath.normalize(path6);
    if (!n.startsWith("/")) n = `/${n}`;
    if (n.length > 1 && n.endsWith("/")) n = n.slice(0, -1);
    return n;
  }
  resolveMount(path6) {
    const normalized = this.normalizePath(path6);
    let best = null;
    for (const [mountPath, fs5] of this._mounts) {
      if (normalized === mountPath || normalized.startsWith(mountPath + "/")) {
        if (!best || mountPath.length > best.mountPath.length) {
          best = { mountPath, fs: fs5 };
        }
      }
    }
    if (!best) return null;
    let fsPath = normalized.slice(best.mountPath.length);
    if (!fsPath) fsPath = "/";
    if (!fsPath.startsWith("/")) fsPath = "/" + fsPath;
    return { fs: best.fs, fsPath, mountPath: best.mountPath };
  }
  getVirtualEntries(path6) {
    const normalized = this.normalizePath(path6);
    if (this.resolveMount(normalized)) return null;
    const entriesMap = /* @__PURE__ */ new Map();
    for (const [mountPath, fs5] of this._mounts.entries()) {
      const isUnder = normalized === "/" ? mountPath.startsWith("/") : mountPath.startsWith(normalized + "/");
      if (isUnder) {
        const remaining = normalized === "/" ? mountPath.slice(1) : mountPath.slice(normalized.length + 1);
        const next = remaining.split("/")[0];
        if (next && !entriesMap.has(next)) {
          const isDirectMount = remaining === next;
          const entry = { name: next, type: "directory" };
          if (isDirectMount) {
            entry.mount = {
              provider: fs5.provider,
              icon: fs5.icon,
              displayName: fs5.displayName,
              description: fs5.description,
              status: fs5.status,
              error: fs5.error
            };
          }
          entriesMap.set(next, entry);
        }
      }
    }
    return entriesMap.size > 0 ? Array.from(entriesMap.values()) : null;
  }
  isVirtualPath(path6) {
    const normalized = this.normalizePath(path6);
    if (normalized === "/" && !this._mounts.has("/")) return true;
    for (const mountPath of this._mounts.keys()) {
      if (mountPath.startsWith(normalized + "/")) return true;
    }
    return false;
  }
  /**
   * Assert that a filesystem is writable (not read-only).
   * @throws {PermissionError} if the filesystem is read-only
   */
  assertWritable(fs5, path6, operation) {
    if (fs5.readOnly) {
      throw new PermissionError(path6, `${operation} (filesystem is read-only)`);
    }
  }
  // ===========================================================================
  // WorkspaceFilesystem Implementation
  // ===========================================================================
  async init() {
    this.status = "initializing";
    for (const [mountPath, fs5] of this._mounts.entries()) {
      try {
        await callLifecycle(fs5, "init");
      } catch (e) {
        const message = e instanceof Error ? e.message : String(e);
        console.warn(`[CompositeFilesystem] Mount "${mountPath}" failed to initialize: ${message}`);
      }
    }
    this.status = "ready";
  }
  async destroy() {
    this.status = "destroying";
    const errors = [];
    for (const fs5 of this._mounts.values()) {
      try {
        await callLifecycle(fs5, "destroy");
      } catch (e) {
        errors.push(e instanceof Error ? e : new Error(String(e)));
      }
    }
    if (errors.length > 0) {
      this.status = "error";
      throw new AggregateError(errors, "Some filesystems failed to destroy");
    }
    this.status = "destroyed";
  }
  async readFile(path6, options) {
    const r = this.resolveMount(path6);
    if (!r) throw new Error(`No mount for path: ${path6}`);
    return r.fs.readFile(r.fsPath, options);
  }
  async writeFile(path6, content, options) {
    const r = this.resolveMount(path6);
    if (!r) throw new Error(`No mount for path: ${path6}`);
    this.assertWritable(r.fs, path6, "writeFile");
    return r.fs.writeFile(r.fsPath, content, options);
  }
  async appendFile(path6, content) {
    const r = this.resolveMount(path6);
    if (!r) throw new Error(`No mount for path: ${path6}`);
    this.assertWritable(r.fs, path6, "appendFile");
    return r.fs.appendFile(r.fsPath, content);
  }
  async deleteFile(path6, options) {
    const r = this.resolveMount(path6);
    if (!r) throw new Error(`No mount for path: ${path6}`);
    this.assertWritable(r.fs, path6, "deleteFile");
    return r.fs.deleteFile(r.fsPath, options);
  }
  async copyFile(src, dest, options) {
    const srcR = this.resolveMount(src);
    const destR = this.resolveMount(dest);
    if (!srcR) throw new Error(`No mount for source: ${src}`);
    if (!destR) throw new Error(`No mount for dest: ${dest}`);
    this.assertWritable(destR.fs, dest, "copyFile");
    if (srcR.mountPath === destR.mountPath) {
      return srcR.fs.copyFile(srcR.fsPath, destR.fsPath, options);
    }
    const content = await srcR.fs.readFile(srcR.fsPath);
    await destR.fs.writeFile(destR.fsPath, content, { overwrite: options?.overwrite });
  }
  async moveFile(src, dest, options) {
    const srcR = this.resolveMount(src);
    const destR = this.resolveMount(dest);
    if (!srcR) throw new Error(`No mount for source: ${src}`);
    if (!destR) throw new Error(`No mount for dest: ${dest}`);
    this.assertWritable(destR.fs, dest, "moveFile");
    this.assertWritable(srcR.fs, src, "moveFile");
    if (srcR.mountPath === destR.mountPath) {
      return srcR.fs.moveFile(srcR.fsPath, destR.fsPath, options);
    }
    await this.copyFile(src, dest, options);
    await srcR.fs.deleteFile(srcR.fsPath);
  }
  async readdir(path6, options) {
    const virtual = this.getVirtualEntries(path6);
    if (virtual) return virtual;
    const r = this.resolveMount(path6);
    if (!r) throw new Error(`No mount for path: ${path6}`);
    return r.fs.readdir(r.fsPath, options);
  }
  async mkdir(path6, options) {
    const r = this.resolveMount(path6);
    if (!r) throw new Error(`No mount for path: ${path6}`);
    this.assertWritable(r.fs, path6, "mkdir");
    return r.fs.mkdir(r.fsPath, options);
  }
  async rmdir(path6, options) {
    const r = this.resolveMount(path6);
    if (!r) throw new Error(`No mount for path: ${path6}`);
    this.assertWritable(r.fs, path6, "rmdir");
    return r.fs.rmdir(r.fsPath, options);
  }
  async exists(path6) {
    if (this.isVirtualPath(path6)) return true;
    const r = this.resolveMount(path6);
    if (!r) return false;
    if (r.fsPath === "/") return true;
    return r.fs.exists(r.fsPath);
  }
  async stat(path6) {
    const normalized = this.normalizePath(path6);
    if (this.isVirtualPath(path6)) {
      const parts = normalized.split("/").filter(Boolean);
      const now = /* @__PURE__ */ new Date();
      return {
        name: parts[parts.length - 1] || "",
        path: normalized,
        type: "directory",
        size: 0,
        createdAt: now,
        modifiedAt: now
      };
    }
    const r = this.resolveMount(path6);
    if (!r) throw new Error(`No mount for path: ${path6}`);
    if (r.fsPath === "/") {
      const parts = normalized.split("/").filter(Boolean);
      const now = /* @__PURE__ */ new Date();
      return {
        name: parts[parts.length - 1] || "",
        path: normalized,
        type: "directory",
        size: 0,
        createdAt: now,
        modifiedAt: now
      };
    }
    return r.fs.stat(r.fsPath);
  }
  async isFile(path6) {
    if (this.isVirtualPath(path6)) return false;
    const r = this.resolveMount(path6);
    if (!r) return false;
    try {
      const stat3 = await r.fs.stat(r.fsPath);
      return stat3.type === "file";
    } catch {
      return false;
    }
  }
  async isDirectory(path6) {
    if (this.isVirtualPath(path6)) return true;
    const r = this.resolveMount(path6);
    if (!r) return false;
    if (r.fsPath === "/") return true;
    try {
      const stat3 = await r.fs.stat(r.fsPath);
      return stat3.type === "directory";
    } catch {
      return false;
    }
  }
  /**
   * Get instructions describing the mounted filesystems.
   * Used by agents to understand available storage locations.
   */
  getInstructions(_opts) {
    const mountDescriptions = Array.from(this._mounts.entries()).map(([mountPath, fs5]) => {
      const name = fs5.displayName || fs5.provider;
      const access2 = fs5.readOnly ? "(read-only)" : "(read-write)";
      return `- ${mountPath}: ${name} ${access2}`;
    }).join("\n");
    return `Filesystem mount points:
${mountDescriptions}`;
  }
};

// src/workspace/filesystem/mastra-filesystem.ts
var MastraFilesystem = class extends MastraBase {
  /** Error message when status is 'error' */
  error;
  // ---------------------------------------------------------------------------
  // Lifecycle Promise Tracking (prevents race conditions)
  // ---------------------------------------------------------------------------
  /** Promise for _init() to prevent race conditions from concurrent calls */
  _initPromise;
  /** Promise for _destroy() to prevent race conditions from concurrent calls */
  _destroyPromise;
  /** Lifecycle callbacks */
  _onInit;
  _onDestroy;
  constructor(options) {
    super({ name: options.name, component: RegisteredLogger.WORKSPACE });
    this._onInit = options.onInit;
    this._onDestroy = options.onDestroy;
  }
  // ---------------------------------------------------------------------------
  // Lifecycle Wrappers (race-condition-safe)
  // ---------------------------------------------------------------------------
  /**
   * Initialize the filesystem (wrapper with status management and race-condition safety).
   *
   * This method is race-condition-safe - concurrent calls will return the same promise.
   * Handles status management automatically.
   *
   * Subclasses override `init()` to provide their initialization logic.
   */
  async _init() {
    if (this.status === "ready") {
      return;
    }
    if (this._destroyPromise) {
      try {
        await this._destroyPromise;
      } catch {
      }
    }
    if (this._initPromise) {
      return this._initPromise;
    }
    this._initPromise = this._executeInit();
    try {
      await this._initPromise;
    } finally {
      this._initPromise = void 0;
    }
  }
  /**
   * Internal init execution - handles status.
   */
  async _executeInit() {
    this.status = "initializing";
    this.error = void 0;
    try {
      await this.init();
      this.status = "ready";
      try {
        await this._onInit?.({ filesystem: this });
      } catch (error) {
        this.logger.warn("onInit callback failed", { error });
      }
    } catch (error) {
      this.status = "error";
      this.error = error instanceof Error ? error.message : String(error);
      this.logger.error("Failed to initialize filesystem", { error, id: this.id });
      throw error;
    }
  }
  /**
   * Override this method to implement filesystem initialization logic.
   *
   * Called by `_init()` after status is set to 'initializing'.
   * Status will be set to 'ready' on success, 'error' on failure.
   *
   * @example
   * ```typescript
   * async init(): Promise<void> {
   *   this._client = new StorageClient({ ... });
   *   await this._client.connect();
   * }
   * ```
   */
  async init() {
  }
  /**
   * Ensure the filesystem is ready.
   *
   * Calls `_init()` if status is not 'ready'. Useful for lazy initialization
   * where operations should automatically initialize the filesystem if needed.
   *
   * @throws {FilesystemNotReadyError} if the filesystem fails to reach 'ready' status
   *
   * @example
   * ```typescript
   * async readFile(path: string): Promise<string | Buffer> {
   *   await this.ensureReady();
   *   // Now safe to use the filesystem
   * }
   * ```
   */
  async ensureReady() {
    if (this.status !== "ready") {
      await this._init();
    }
    if (this.status !== "ready") {
      throw new FilesystemNotReadyError(this.id);
    }
  }
  /**
   * Destroy the filesystem and clean up all resources (wrapper with status management).
   *
   * This method is race-condition-safe - concurrent calls will return the same promise.
   * Handles status management.
   *
   * Subclasses override `destroy()` to provide their destroy logic.
   */
  async _destroy() {
    if (this.status === "destroyed") {
      return;
    }
    if (this.status === "pending") {
      this.status = "destroyed";
      return;
    }
    if (this._destroyPromise) {
      return this._destroyPromise;
    }
    this._destroyPromise = this._executeDestroy();
    try {
      await this._destroyPromise;
    } finally {
      this._destroyPromise = void 0;
    }
  }
  /**
   * Internal destroy execution - handles status.
   */
  async _executeDestroy() {
    if (this._initPromise) {
      try {
        await this._initPromise;
      } catch {
      }
    }
    this.status = "destroying";
    try {
      await this._onDestroy?.({ filesystem: this });
      await this.destroy();
      this.status = "destroyed";
    } catch (error) {
      this.status = "error";
      this.logger.error("Failed to destroy filesystem", { error, id: this.id });
      throw error;
    }
  }
  /**
   * Override this method to implement filesystem destroy logic.
   *
   * Called by `_destroy()` after status is set to 'destroying'.
   * Status will be set to 'destroyed' on success, 'error' on failure.
   */
  async destroy() {
  }
};

// src/workspace/utils.ts
function resolveInstructions(override, getDefault, requestContext) {
  if (typeof override === "string") return override;
  const defaultInstructions = getDefault();
  if (override === void 0) return defaultInstructions;
  return override({ defaultInstructions, requestContext });
}
function isEnoentError(error) {
  return error !== null && typeof error === "object" && "code" in error && error.code === "ENOENT";
}
function isEexistError(error) {
  return error !== null && typeof error === "object" && "code" in error && error.code === "EEXIST";
}
var MIME_TYPES = {
  // Text
  txt: "text/plain",
  html: "text/html",
  htm: "text/html",
  css: "text/css",
  csv: "text/csv",
  md: "text/markdown",
  // Code
  js: "application/javascript",
  mjs: "application/javascript",
  ts: "application/typescript",
  tsx: "application/typescript",
  jsx: "application/javascript",
  json: "application/json",
  xml: "application/xml",
  yaml: "text/yaml",
  yml: "text/yaml",
  // Programming languages
  py: "text/x-python",
  rb: "text/x-ruby",
  go: "text/x-go",
  rs: "text/x-rust",
  java: "text/x-java",
  c: "text/x-c",
  cpp: "text/x-c++",
  h: "text/x-c",
  hpp: "text/x-c++",
  sh: "text/x-sh",
  bash: "text/x-sh",
  zsh: "text/x-sh",
  // Config
  toml: "text/toml",
  ini: "text/plain",
  env: "text/plain",
  // Database/Query
  sql: "text/x-sql",
  graphql: "application/graphql",
  gql: "application/graphql",
  // Frameworks
  vue: "text/x-vue",
  // Images
  png: "image/png",
  jpg: "image/jpeg",
  jpeg: "image/jpeg",
  gif: "image/gif",
  svg: "image/svg+xml",
  webp: "image/webp",
  ico: "image/x-icon",
  // Documents
  pdf: "application/pdf"
};
function getMimeType(filename) {
  const ext = nodePath.extname(filename).slice(1).toLowerCase();
  return MIME_TYPES[ext] ?? "application/octet-stream";
}
var TEXT_EXTENSIONS = /* @__PURE__ */ new Set([
  ".md",
  ".txt",
  ".json",
  ".yaml",
  ".yml",
  ".js",
  ".mjs",
  ".ts",
  ".tsx",
  ".jsx",
  ".py",
  ".rb",
  ".go",
  ".rs",
  ".java",
  ".c",
  ".cpp",
  ".h",
  ".hpp",
  ".sh",
  ".bash",
  ".zsh",
  ".html",
  ".htm",
  ".css",
  ".xml",
  ".toml",
  ".ini",
  ".env",
  ".csv",
  ".sql",
  ".graphql",
  ".gql",
  ".vue",
  ".svg"
]);
function isTextFile(filename) {
  const ext = nodePath.extname(filename).toLowerCase();
  return TEXT_EXTENSIONS.has(ext);
}
function resolveWorkspacePath(basePath, filePath) {
  if (nodePath.isAbsolute(filePath)) {
    const normalizedBase = nodePath.normalize(basePath);
    const normalizedFile = nodePath.normalize(filePath);
    const rel = nodePath.relative(normalizedBase, normalizedFile);
    if (!rel.startsWith("..") && !nodePath.isAbsolute(rel)) {
      return normalizedFile;
    }
  }
  return nodePath.join(basePath, filePath.replace(/^\/+/, ""));
}
async function fsExists(absolutePath) {
  try {
    await fs2.access(absolutePath);
    return true;
  } catch {
    return false;
  }
}
async function fsStat(absolutePath, userPath) {
  try {
    const stats = await fs2.stat(absolutePath);
    return {
      name: nodePath.basename(absolutePath),
      type: stats.isDirectory() ? "directory" : "file",
      size: stats.size,
      createdAt: stats.birthtime,
      modifiedAt: stats.mtime,
      mimeType: stats.isFile() ? getMimeType(absolutePath) : void 0
    };
  } catch (error) {
    if (isEnoentError(error)) {
      throw new FileNotFoundError(userPath);
    }
    throw error;
  }
}

// src/workspace/filesystem/local-filesystem.ts
var LocalFilesystem = class extends MastraFilesystem {
  id;
  name = "LocalFilesystem";
  provider = "local";
  readOnly;
  status = "pending";
  _basePath;
  _contained;
  _allowedPaths;
  _instructionsOverride;
  /**
   * The absolute base path on disk where files are stored.
   * Useful for understanding how workspace paths map to disk paths.
   */
  get basePath() {
    return this._basePath;
  }
  /**
   * Current set of additional allowed paths (absolute, resolved).
   * These paths are permitted beyond basePath when containment is enabled.
   */
  get allowedPaths() {
    return this._allowedPaths;
  }
  /**
   * Update allowed paths. Accepts a direct array or an updater callback
   * receiving the current paths (React setState pattern).
   *
   * @example
   * ```typescript
   * // Set directly
   * fs.setAllowedPaths(['/home/user/.config']);
   *
   * // Update with callback
   * fs.setAllowedPaths(prev => [...prev, '/home/user/.ssh']);
   * ```
   */
  setAllowedPaths(pathsOrUpdater) {
    const newPaths = typeof pathsOrUpdater === "function" ? pathsOrUpdater(this._allowedPaths) : pathsOrUpdater;
    this._allowedPaths = newPaths.map((p) => nodePath.resolve(p));
  }
  constructor(options) {
    super({ ...options, name: "LocalFilesystem" });
    this.id = options.id ?? this.generateId();
    this._basePath = nodePath.resolve(options.basePath);
    this._contained = options.contained ?? true;
    this.readOnly = options.readOnly;
    this._allowedPaths = (options.allowedPaths ?? []).map((p) => nodePath.resolve(p));
    this._instructionsOverride = options.instructions;
  }
  generateId() {
    return `local-fs-${Date.now().toString(36)}-${Math.random().toString(36).slice(2, 8)}`;
  }
  /**
   * Check if an absolute path falls within basePath or any allowed path.
   */
  _isWithinAnyRoot(absolutePath) {
    const roots = [this._basePath, ...this._allowedPaths];
    return roots.some((root) => {
      const relative3 = nodePath.relative(root, absolutePath);
      return !relative3.startsWith("..") && !nodePath.isAbsolute(relative3);
    });
  }
  toBuffer(content) {
    if (Buffer.isBuffer(content)) return content;
    if (content instanceof Uint8Array) return Buffer.from(content);
    return Buffer.from(content, "utf-8");
  }
  resolvePath(inputPath) {
    let absolutePath;
    if (!this._contained && nodePath.isAbsolute(inputPath)) {
      absolutePath = nodePath.normalize(inputPath);
    } else if (this._contained && nodePath.isAbsolute(inputPath)) {
      const normalized = nodePath.normalize(inputPath);
      if (this._isWithinAnyRoot(normalized)) {
        absolutePath = normalized;
      } else {
        absolutePath = resolveWorkspacePath(this._basePath, inputPath);
      }
    } else {
      absolutePath = resolveWorkspacePath(this._basePath, inputPath);
    }
    if (this._contained) {
      if (!this._isWithinAnyRoot(absolutePath)) {
        throw new PermissionError(inputPath, "access");
      }
    }
    return absolutePath;
  }
  /**
   * Resolve a workspace-relative path to an absolute disk path.
   * Uses the same resolution logic as internal file operations.
   * Returns `undefined` if the path violates containment.
   */
  resolveAbsolutePath(inputPath) {
    try {
      return this.resolvePath(inputPath);
    } catch {
      return void 0;
    }
  }
  toRelativePath(absolutePath) {
    return "/" + nodePath.relative(this._basePath, absolutePath).replace(/\\/g, "/");
  }
  assertWritable(operation) {
    if (this.readOnly) {
      throw new WorkspaceReadOnlyError(operation);
    }
  }
  /**
   * Verify that the resolved path doesn't escape basePath via symlinks.
   * Uses realpath to resolve symlinks and check the actual target.
   */
  async assertPathContained(absolutePath) {
    if (!this._contained) return;
    const rootReals = [];
    for (const root of [this._basePath, ...this._allowedPaths]) {
      try {
        rootReals.push(await fs2.realpath(root));
      } catch (error) {
        if (isEnoentError(error)) {
          continue;
        }
        throw error;
      }
    }
    if (rootReals.length === 0) {
      throw new DirectoryNotFoundError(this._basePath);
    }
    let targetReal;
    try {
      targetReal = await fs2.realpath(absolutePath);
    } catch (error) {
      if (isEnoentError(error)) {
        let parentPath = absolutePath;
        while (true) {
          const nextParent = nodePath.dirname(parentPath);
          if (nextParent === parentPath) {
            throw new DirectoryNotFoundError(absolutePath);
          }
          parentPath = nextParent;
          try {
            targetReal = await fs2.realpath(parentPath);
            break;
          } catch (parentError) {
            if (!isEnoentError(parentError)) {
              throw parentError;
            }
          }
        }
      } else {
        throw error;
      }
    }
    const isWithinRoot = rootReals.some(
      (rootReal) => targetReal === rootReal || targetReal.startsWith(rootReal + nodePath.sep)
    );
    if (!isWithinRoot) {
      throw new PermissionError(absolutePath, "access");
    }
  }
  async readFile(inputPath, options) {
    this.logger.debug("Reading file", { path: inputPath, encoding: options?.encoding });
    await this.ensureReady();
    const absolutePath = this.resolvePath(inputPath);
    await this.assertPathContained(absolutePath);
    try {
      const stats = await fs2.stat(absolutePath);
      if (stats.isDirectory()) {
        throw new IsDirectoryError(inputPath);
      }
      if (options?.encoding) {
        return await fs2.readFile(absolutePath, { encoding: options.encoding });
      }
      return await fs2.readFile(absolutePath);
    } catch (error) {
      if (error instanceof IsDirectoryError) throw error;
      if (isEnoentError(error)) {
        throw new FileNotFoundError(inputPath);
      }
      throw error;
    }
  }
  async writeFile(inputPath, content, options) {
    const contentSize = Buffer.isBuffer(content) ? content.length : content.length;
    this.logger.debug("Writing file", { path: inputPath, size: contentSize, recursive: options?.recursive });
    await this.ensureReady();
    this.assertWritable("writeFile");
    const absolutePath = this.resolvePath(inputPath);
    await this.assertPathContained(absolutePath);
    if (options?.recursive === false) {
      const dir = nodePath.dirname(absolutePath);
      const parentPath = nodePath.dirname(inputPath);
      try {
        const stat3 = await fs2.stat(dir);
        if (!stat3.isDirectory()) {
          throw new NotDirectoryError(parentPath);
        }
      } catch (error) {
        if (error instanceof NotDirectoryError) throw error;
        if (isEnoentError(error)) {
          throw new DirectoryNotFoundError(parentPath);
        }
        throw error;
      }
    }
    if (options?.recursive !== false) {
      const dir = nodePath.dirname(absolutePath);
      await fs2.mkdir(dir, { recursive: true });
    }
    const writeFlag = options?.overwrite === false ? "wx" : "w";
    try {
      await fs2.writeFile(absolutePath, this.toBuffer(content), { flag: writeFlag });
    } catch (error) {
      if (options?.overwrite === false && isEexistError(error)) {
        throw new FileExistsError(inputPath);
      }
      throw error;
    }
  }
  async appendFile(inputPath, content) {
    const contentSize = Buffer.isBuffer(content) ? content.length : content.length;
    this.logger.debug("Appending to file", { path: inputPath, size: contentSize });
    await this.ensureReady();
    this.assertWritable("appendFile");
    const absolutePath = this.resolvePath(inputPath);
    await this.assertPathContained(absolutePath);
    const dir = nodePath.dirname(absolutePath);
    await fs2.mkdir(dir, { recursive: true });
    await fs2.appendFile(absolutePath, this.toBuffer(content));
  }
  async deleteFile(inputPath, options) {
    this.logger.debug("Deleting file", { path: inputPath, force: options?.force });
    await this.ensureReady();
    this.assertWritable("deleteFile");
    const absolutePath = this.resolvePath(inputPath);
    await this.assertPathContained(absolutePath);
    try {
      const stats = await fs2.stat(absolutePath);
      if (stats.isDirectory()) {
        throw new IsDirectoryError(inputPath);
      }
      await fs2.unlink(absolutePath);
    } catch (error) {
      if (error instanceof IsDirectoryError) throw error;
      if (isEnoentError(error)) {
        if (!options?.force) {
          throw new FileNotFoundError(inputPath);
        }
      } else {
        throw error;
      }
    }
  }
  async copyFile(src, dest, options) {
    this.logger.debug("Copying file", { src, dest, recursive: options?.recursive });
    await this.ensureReady();
    this.assertWritable("copyFile");
    const srcPath = this.resolvePath(src);
    const destPath = this.resolvePath(dest);
    await this.assertPathContained(srcPath);
    await this.assertPathContained(destPath);
    try {
      const stats = await fs2.stat(srcPath);
      if (stats.isDirectory()) {
        if (!options?.recursive) {
          throw new IsDirectoryError(src);
        }
        await this.copyDirectory(srcPath, destPath, options);
      } else {
        await fs2.mkdir(nodePath.dirname(destPath), { recursive: true });
        const copyFlags = options?.overwrite === false ? constants.COPYFILE_EXCL : 0;
        try {
          await fs2.copyFile(srcPath, destPath, copyFlags);
        } catch (error) {
          if (options?.overwrite === false && isEexistError(error)) {
            throw new FileExistsError(dest);
          }
          throw error;
        }
      }
    } catch (error) {
      if (error instanceof IsDirectoryError || error instanceof FileExistsError) throw error;
      if (isEnoentError(error)) {
        throw new FileNotFoundError(src);
      }
      throw error;
    }
  }
  async copyDirectory(src, dest, options) {
    await this.ensureReady();
    await fs2.mkdir(dest, { recursive: true });
    const entries = await fs2.readdir(src, { withFileTypes: true });
    for (const entry of entries) {
      const srcEntry = nodePath.join(src, entry.name);
      const destEntry = nodePath.join(dest, entry.name);
      await this.assertPathContained(srcEntry);
      await this.assertPathContained(destEntry);
      if (entry.isDirectory()) {
        await this.copyDirectory(srcEntry, destEntry, options);
      } else {
        const copyFlags = options?.overwrite === false ? constants.COPYFILE_EXCL : 0;
        try {
          await fs2.copyFile(srcEntry, destEntry, copyFlags);
        } catch (error) {
          if (options?.overwrite === false && isEexistError(error)) {
            continue;
          }
          throw error;
        }
      }
    }
  }
  async moveFile(src, dest, options) {
    this.logger.debug("Moving file", { src, dest, overwrite: options?.overwrite });
    await this.ensureReady();
    this.assertWritable("moveFile");
    const srcPath = this.resolvePath(src);
    const destPath = this.resolvePath(dest);
    await this.assertPathContained(srcPath);
    await this.assertPathContained(destPath);
    try {
      await fs2.mkdir(nodePath.dirname(destPath), { recursive: true });
      if (options?.overwrite === false) {
        await this.copyFile(src, dest, { ...options, overwrite: false });
        await fs2.rm(srcPath, { recursive: true, force: true });
        return;
      }
      try {
        await fs2.rename(srcPath, destPath);
      } catch (error) {
        const code = error.code;
        if (code !== "EXDEV") {
          throw error;
        }
        await this.copyFile(src, dest, options);
        await fs2.rm(srcPath, { recursive: true, force: true });
      }
    } catch (error) {
      if (error instanceof FileExistsError) throw error;
      if (isEnoentError(error)) {
        throw new FileNotFoundError(src);
      }
      throw error;
    }
  }
  async mkdir(inputPath, options) {
    this.logger.debug("Creating directory", { path: inputPath, recursive: options?.recursive });
    await this.ensureReady();
    this.assertWritable("mkdir");
    const absolutePath = this.resolvePath(inputPath);
    await this.assertPathContained(absolutePath);
    try {
      await fs2.mkdir(absolutePath, { recursive: options?.recursive ?? true });
    } catch (error) {
      if (isEexistError(error)) {
        const stats = await fs2.stat(absolutePath);
        if (!stats.isDirectory()) {
          throw new FileExistsError(inputPath);
        }
      } else if (isEnoentError(error)) {
        const parentPath = nodePath.dirname(inputPath);
        throw new DirectoryNotFoundError(parentPath);
      } else {
        throw error;
      }
    }
  }
  async rmdir(inputPath, options) {
    this.logger.debug("Removing directory", { path: inputPath, recursive: options?.recursive, force: options?.force });
    await this.ensureReady();
    this.assertWritable("rmdir");
    const absolutePath = this.resolvePath(inputPath);
    await this.assertPathContained(absolutePath);
    try {
      const stats = await fs2.stat(absolutePath);
      if (!stats.isDirectory()) {
        throw new NotDirectoryError(inputPath);
      }
      if (options?.recursive) {
        await fs2.rm(absolutePath, { recursive: true, force: options?.force ?? false });
      } else {
        const entries = await fs2.readdir(absolutePath);
        if (entries.length > 0) {
          throw new DirectoryNotEmptyError(inputPath);
        }
        await fs2.rmdir(absolutePath);
      }
    } catch (error) {
      if (error instanceof NotDirectoryError || error instanceof DirectoryNotEmptyError) {
        throw error;
      }
      if (isEnoentError(error)) {
        if (!options?.force) {
          throw new DirectoryNotFoundError(inputPath);
        }
      } else {
        throw error;
      }
    }
  }
  async readdir(inputPath, options) {
    this.logger.debug("Reading directory", { path: inputPath, recursive: options?.recursive });
    await this.ensureReady();
    const absolutePath = this.resolvePath(inputPath);
    await this.assertPathContained(absolutePath);
    try {
      const stats = await fs2.stat(absolutePath);
      if (!stats.isDirectory()) {
        throw new NotDirectoryError(inputPath);
      }
      const entries = await fs2.readdir(absolutePath, { withFileTypes: true });
      const result = [];
      for (const entry of entries) {
        const entryPath = nodePath.join(absolutePath, entry.name);
        if (options?.extension) {
          const extensions = Array.isArray(options.extension) ? options.extension : [options.extension];
          if (entry.isFile()) {
            const ext = nodePath.extname(entry.name);
            if (!extensions.some((e) => e === ext || e === ext.slice(1))) {
              continue;
            }
          }
        }
        const isSymlink = entry.isSymbolicLink();
        let symlinkTarget;
        let resolvedType = "file";
        if (isSymlink) {
          try {
            symlinkTarget = await fs2.readlink(entryPath);
            const targetStat = await fs2.stat(entryPath);
            resolvedType = targetStat.isDirectory() ? "directory" : "file";
          } catch {
            resolvedType = "file";
          }
        } else {
          resolvedType = entry.isDirectory() ? "directory" : "file";
        }
        const fileEntry = {
          name: entry.name,
          type: resolvedType,
          isSymlink: isSymlink || void 0,
          symlinkTarget
        };
        if (resolvedType === "file" && !isSymlink) {
          try {
            const stat3 = await fs2.stat(entryPath);
            fileEntry.size = stat3.size;
          } catch {
          }
        }
        result.push(fileEntry);
        if (options?.recursive && resolvedType === "directory") {
          const depth = options.maxDepth ?? 100;
          if (depth > 0) {
            const subEntries = await this.readdir(this.toRelativePath(entryPath), { ...options, maxDepth: depth - 1 });
            result.push(
              ...subEntries.map((e) => ({
                ...e,
                name: `${entry.name}/${e.name}`
              }))
            );
          }
        }
      }
      return result;
    } catch (error) {
      if (error instanceof NotDirectoryError) throw error;
      if (isEnoentError(error)) {
        throw new DirectoryNotFoundError(inputPath);
      }
      throw error;
    }
  }
  async exists(inputPath) {
    await this.ensureReady();
    const absolutePath = this.resolvePath(inputPath);
    await this.assertPathContained(absolutePath);
    return fsExists(absolutePath);
  }
  async stat(inputPath) {
    await this.ensureReady();
    const absolutePath = this.resolvePath(inputPath);
    await this.assertPathContained(absolutePath);
    const result = await fsStat(absolutePath, inputPath);
    return {
      ...result,
      path: this.toRelativePath(absolutePath)
    };
  }
  /**
   * Initialize the local filesystem by creating the base directory.
   * Status management is handled by the base class.
   */
  async init() {
    this.logger.debug("Initializing filesystem", { basePath: this._basePath });
    await fs2.mkdir(this._basePath, { recursive: true });
    this.logger.debug("Filesystem initialized", { basePath: this._basePath });
  }
  /**
   * Clean up the local filesystem.
   * LocalFilesystem doesn't delete files on destroy by default.
   * Status management is handled by the base class.
   */
  async destroy() {
  }
  getInfo() {
    return {
      id: this.id,
      name: this.name,
      provider: this.provider,
      readOnly: this.readOnly,
      status: this.status,
      error: this.error,
      metadata: {
        basePath: this.basePath,
        contained: this._contained,
        ...this._allowedPaths.length > 0 && { allowedPaths: [...this._allowedPaths] }
      }
    };
  }
  getInstructions(opts) {
    return resolveInstructions(this._instructionsOverride, () => this._getDefaultInstructions(), opts?.requestContext);
  }
  _getDefaultInstructions() {
    const allowedNote = this._allowedPaths.length > 0 ? ` Additionally, the following paths outside basePath are accessible: ${this._allowedPaths.join(", ")}.` : "";
    if (this._contained) {
      return `Local filesystem at "${this.basePath}". Files at workspace path "/foo" are stored at "${this.basePath}/foo" on disk.${allowedNote}`;
    }
    return `Local filesystem rooted at "${this.basePath}". Containment is disabled so absolute paths access the real filesystem. Use paths relative to "${this.basePath}" (e.g. "foo/bar.txt") for workspace files. Avoid unnecessary listing "/" as it would traverse the entire host filesystem.${allowedNote}`;
  }
};
var InMemoryFileReadTracker = class {
  records = /* @__PURE__ */ new Map();
  recordRead(path6, modifiedAt) {
    const normalizedPath = this.normalizePath(path6);
    this.records.set(normalizedPath, {
      path: normalizedPath,
      readAt: /* @__PURE__ */ new Date(),
      modifiedAtRead: modifiedAt
    });
  }
  getReadRecord(path6) {
    return this.records.get(this.normalizePath(path6));
  }
  needsReRead(path6, currentModifiedAt) {
    const record = this.getReadRecord(path6);
    if (!record) {
      return {
        needsReRead: true,
        reason: `File "${path6}" has not been read. You must read a file before writing to it.`
      };
    }
    if (currentModifiedAt.getTime() > record.modifiedAtRead.getTime()) {
      return {
        needsReRead: true,
        reason: `File "${path6}" was modified since last read (read at: ${record.modifiedAtRead.toISOString()}, current: ${currentModifiedAt.toISOString()}). Please re-read the file to get the latest contents.`
      };
    }
    return { needsReRead: false };
  }
  clearReadRecord(path6) {
    this.records.delete(this.normalizePath(path6));
  }
  clear() {
    this.records.clear();
  }
  normalizePath(pathStr) {
    const normalized = nodePath.posix.normalize(pathStr.replace(/\\/g, "/"));
    return normalized.replace(/\/$/, "") || "/";
  }
};
var InMemoryFileWriteLock = class {
  queues = /* @__PURE__ */ new Map();
  timeoutMs;
  constructor(opts) {
    this.timeoutMs = opts?.timeoutMs ?? 3e4;
  }
  get size() {
    return this.queues.size;
  }
  withLock(filePath, fn) {
    const key = this.normalizePath(filePath);
    const currentQueue = this.queues.get(key) ?? Promise.resolve();
    let resolve3;
    let reject;
    const resultPromise = new Promise((res, rej) => {
      resolve3 = res;
      reject = rej;
    });
    const queuePromise = currentQueue.catch(() => {
    }).then(async () => {
      let timeoutId;
      try {
        const result = await Promise.race([
          fn(),
          new Promise((_, rej) => {
            timeoutId = setTimeout(
              () => rej(new Error(`write-lock timeout on "${key}" after ${this.timeoutMs}ms`)),
              this.timeoutMs
            );
          })
        ]);
        clearTimeout(timeoutId);
        resolve3(result);
      } catch (error) {
        clearTimeout(timeoutId);
        reject(error);
      }
    });
    this.queues.set(key, queuePromise);
    void queuePromise.finally(() => {
      if (this.queues.get(key) === queuePromise) {
        this.queues.delete(key);
      }
    });
    return resultPromise;
  }
  normalizePath(pathStr) {
    const normalized = nodePath.posix.normalize(pathStr.replace(/\\/g, "/").replace(/^\/\/+/, "/"));
    return normalized.replace(/\/+$/, "") || "/";
  }
};
var GLOB_CHARS = /[*?{}[\]]/;
function isGlobPattern(input) {
  return GLOB_CHARS.test(input);
}
function extractGlobBase(pattern) {
  const firstMeta = pattern.search(GLOB_CHARS);
  if (firstMeta === -1) {
    return pattern;
  }
  const prefix = pattern.slice(0, firstMeta);
  const lastSlash = prefix.lastIndexOf("/");
  if (lastSlash <= 0) {
    return "/";
  }
  return prefix.slice(0, lastSlash);
}
function normalizeForMatch(input) {
  if (input.startsWith("./")) return input.slice(2);
  if (input.startsWith("/")) return input.slice(1);
  return input;
}
function createGlobMatcher(patterns, options) {
  const patternArray = (Array.isArray(patterns) ? patterns : [patterns]).map(normalizeForMatch);
  const matcher = picomatch(patternArray, {
    posix: true,
    dot: options?.dot ?? false
  });
  return (path6) => matcher(normalizeForMatch(path6));
}
function matchGlob(path6, pattern, options) {
  return createGlobMatcher(pattern, options)(path6);
}

// src/workspace/lsp/language.ts
var LANGUAGE_EXTENSIONS = {
  // TypeScript/JavaScript
  ".ts": "typescript",
  ".tsx": "typescriptreact",
  ".js": "javascript",
  ".jsx": "javascriptreact",
  ".mjs": "javascript",
  ".cjs": "javascript",
  // Python
  ".py": "python",
  ".pyi": "python",
  // Go
  ".go": "go",
  // Rust
  ".rs": "rust",
  // C/C++
  ".c": "c",
  ".cpp": "cpp",
  ".cc": "cpp",
  ".cxx": "cpp",
  ".h": "c",
  ".hpp": "cpp",
  // Java
  ".java": "java",
  // JSON
  ".json": "json",
  ".jsonc": "jsonc",
  // YAML
  ".yaml": "yaml",
  ".yml": "yaml",
  // Markdown
  ".md": "markdown",
  // HTML/CSS
  ".html": "html",
  ".css": "css",
  ".scss": "scss",
  ".sass": "sass",
  ".less": "less"
};
function getLanguageId(filePath) {
  const dotIndex = filePath.lastIndexOf(".");
  if (dotIndex === -1) return void 0;
  const ext = filePath.substring(dotIndex);
  return LANGUAGE_EXTENSIONS[ext];
}
var jsonrpcModule;
var lspProtocolModule;
function isLSPAvailable() {
  if (jsonrpcModule !== void 0) {
    return jsonrpcModule !== null;
  }
  try {
    const req = createRequire(import.meta.url);
    req.resolve("vscode-jsonrpc/node");
    req.resolve("vscode-languageserver-protocol");
    return true;
  } catch {
    return false;
  }
}
async function loadLSPDeps() {
  if (jsonrpcModule !== void 0 && lspProtocolModule !== void 0) {
    if (jsonrpcModule === null || lspProtocolModule === null) return null;
    return { ...jsonrpcModule, ...lspProtocolModule };
  }
  try {
    const req = createRequire(import.meta.url);
    const jsonrpc = req("vscode-jsonrpc/node");
    const protocol = req("vscode-languageserver-protocol");
    jsonrpcModule = {
      StreamMessageReader: jsonrpc.StreamMessageReader,
      StreamMessageWriter: jsonrpc.StreamMessageWriter,
      createMessageConnection: jsonrpc.createMessageConnection
    };
    lspProtocolModule = {
      TextDocumentIdentifier: protocol.TextDocumentIdentifier,
      Position: protocol.Position
    };
    return { ...jsonrpcModule, ...lspProtocolModule };
  } catch {
    jsonrpcModule = null;
    lspProtocolModule = null;
    return null;
  }
}
function toFileUri(fsPath) {
  return pathToFileURL(fsPath).toString();
}
var LSPClient = class {
  connection = null;
  handle = null;
  serverDef;
  workspaceRoot;
  processManager;
  diagnostics = /* @__PURE__ */ new Map();
  initializationOptions = null;
  constructor(serverDef, workspaceRoot, processManager) {
    this.serverDef = serverDef;
    this.workspaceRoot = workspaceRoot;
    this.processManager = processManager;
  }
  /** Whether the underlying server process is still running. */
  get isAlive() {
    return this.handle !== null && this.handle.exitCode === void 0;
  }
  /**
   * Initialize the LSP connection â€” spawns the server and performs the handshake.
   */
  async initialize(initTimeout = 1e4) {
    const deps = await loadLSPDeps();
    if (!deps) {
      throw new Error("LSP dependencies (vscode-jsonrpc) are not available");
    }
    const { StreamMessageReader, StreamMessageWriter, createMessageConnection } = deps;
    const command = this.serverDef.command(this.workspaceRoot);
    if (!command) {
      throw new Error("Failed to resolve LSP server command");
    }
    this.handle = await this.processManager.spawn(command, { cwd: this.workspaceRoot });
    const initializationOptions = this.serverDef.initialization?.(this.workspaceRoot);
    const reader = new StreamMessageReader(this.handle.reader);
    const writer = new StreamMessageWriter(this.handle.writer);
    this.connection = createMessageConnection(reader, writer);
    this.connection.onError(() => {
    });
    this.connection.onNotification("textDocument/publishDiagnostics", (params) => {
      this.diagnostics.set(params.uri, params.diagnostics);
    });
    this.connection.listen();
    const initParams = {
      processId: process.pid,
      rootUri: toFileUri(this.workspaceRoot),
      workspaceFolders: [
        {
          name: "workspace",
          uri: toFileUri(this.workspaceRoot)
        }
      ],
      capabilities: {
        window: { workDoneProgress: true },
        workspace: { configuration: true },
        textDocument: {
          publishDiagnostics: {
            relatedInformation: true,
            tagSupport: { valueSet: [1, 2] },
            versionSupport: false
          },
          synchronization: {
            didOpen: true,
            didChange: true,
            dynamicRegistration: false,
            willSave: false,
            willSaveWaitUntil: false,
            didSave: false
          },
          completion: {
            dynamicRegistration: false,
            completionItem: {
              snippetSupport: false,
              commitCharactersSupport: false,
              documentationFormat: ["markdown", "plaintext"],
              deprecatedSupport: false,
              preselectSupport: false
            }
          },
          definition: { dynamicRegistration: false, linkSupport: true },
          typeDefinition: { dynamicRegistration: false, linkSupport: true },
          implementation: { dynamicRegistration: false, linkSupport: true },
          references: { dynamicRegistration: false },
          documentHighlight: { dynamicRegistration: false },
          documentSymbol: { dynamicRegistration: false, hierarchicalDocumentSymbolSupport: true },
          codeAction: {
            dynamicRegistration: false,
            codeActionLiteralSupport: {
              codeActionKind: {
                valueSet: [
                  "quickfix",
                  "refactor",
                  "refactor.extract",
                  "refactor.inline",
                  "refactor.rewrite",
                  "source",
                  "source.organizeImports"
                ]
              }
            }
          },
          hover: { dynamicRegistration: false, contentFormat: ["markdown", "plaintext"] }
        }
      }
    };
    if (initializationOptions) {
      initParams.initializationOptions = initializationOptions;
      this.initializationOptions = initializationOptions;
    }
    this.connection.onRequest("workspace/configuration", (params) => {
      return params.items?.map(() => ({})) || [];
    });
    this.connection.onRequest("window/workDoneProgress/create", () => null);
    let initTimer;
    await Promise.race([
      this.connection.sendRequest("initialize", initParams),
      new Promise((_, reject) => {
        initTimer = setTimeout(() => reject(new Error("LSP initialize request timed out")), initTimeout);
      })
    ]).finally(() => clearTimeout(initTimer));
    this.connection.sendNotification("initialized", {});
    this.connection.sendNotification("workspace/didChangeConfiguration", {
      settings: this.initializationOptions ?? {}
    });
  }
  /**
   * Notify the server that a document has been opened.
   */
  notifyOpen(filePath, content, languageId) {
    if (!this.connection) return;
    const uri = toFileUri(filePath);
    this.diagnostics.delete(uri);
    this.connection.sendNotification("textDocument/didOpen", {
      textDocument: { uri, languageId, version: 0, text: content }
    });
  }
  /**
   * Notify the server that a document has changed.
   */
  notifyChange(filePath, content, version) {
    if (!this.connection) return;
    this.connection.sendNotification("textDocument/didChange", {
      textDocument: { uri: toFileUri(filePath), version },
      contentChanges: [{ text: content }]
    });
  }
  /**
   * Wait for diagnostics to arrive for a file.
   *
   * When `waitForChange` is false (default), returns as soon as diagnostics
   * are available. To avoid returning a premature empty array (servers may
   * publish `[]` first while still analysing), empty results trigger a short
   * settle window: polling continues for up to `settleMs` (default 500ms)
   * to see if non-empty diagnostics arrive. Non-empty results are returned
   * immediately.
   */
  async waitForDiagnostics(filePath, timeoutMs = 5e3, waitForChange = false, settleMs = 500) {
    if (!this.connection) return [];
    const uri = toFileUri(filePath);
    const startTime = Date.now();
    const initialDiagnostics = this.diagnostics.get(uri);
    let emptyReceivedAt;
    while (Date.now() - startTime < timeoutMs) {
      const currentDiagnostics = this.diagnostics.get(uri);
      if (waitForChange) {
        if (currentDiagnostics !== void 0 && currentDiagnostics !== initialDiagnostics) {
          return currentDiagnostics;
        }
      } else {
        if (currentDiagnostics !== void 0) {
          if (currentDiagnostics.length > 0) return currentDiagnostics;
          if (emptyReceivedAt === void 0) emptyReceivedAt = Date.now();
          if (Date.now() - emptyReceivedAt >= settleMs) return currentDiagnostics;
        }
      }
      await new Promise((resolve3) => setTimeout(resolve3, 100));
    }
    return waitForChange ? initialDiagnostics || [] : this.diagnostics.get(uri) || [];
  }
  /**
   * Notify the server that a document was closed.
   */
  notifyClose(filePath) {
    if (!this.connection) return;
    const uri = toFileUri(filePath);
    this.diagnostics.delete(uri);
    this.connection.sendNotification("textDocument/didClose", {
      textDocument: { uri }
    });
  }
  /**
   * Shutdown the connection and kill the process.
   */
  async shutdown() {
    if (this.connection) {
      try {
        if (this.handle && this.handle.exitCode === void 0) {
          let shutdownTimer;
          await Promise.race([
            this.connection.sendRequest("shutdown"),
            new Promise((_, reject) => {
              shutdownTimer = setTimeout(() => reject(new Error("Shutdown request timed out")), 1e3);
            })
          ]).finally(() => clearTimeout(shutdownTimer));
          this.connection.sendNotification("exit");
        }
      } catch {
      }
      try {
        this.connection.dispose();
      } catch {
      }
      this.connection = null;
    }
    if (this.handle) {
      try {
        await this.handle.kill();
      } catch {
      }
      this.handle = null;
    }
    this.diagnostics = /* @__PURE__ */ new Map();
  }
};
function whichSync(binary) {
  try {
    const cmd = process.platform === "win32" ? "where" : "which";
    execFileSync(cmd, [binary], { stdio: "ignore" });
    return true;
  } catch {
    return false;
  }
}
function resolveRequire(root, moduleId) {
  try {
    const req = createRequire(pathToFileURL(join(root, "package.json")));
    return { require: req, resolved: req.resolve(moduleId) };
  } catch {
  }
  try {
    const req = createRequire(pathToFileURL(join(process.cwd(), "package.json")));
    return { require: req, resolved: req.resolve(moduleId) };
  } catch {
    return null;
  }
}
function walkUp(startDir, markers) {
  let current = startDir;
  const fsRoot = parse(current).root;
  while (true) {
    for (const marker of markers) {
      if (existsSync(join(current, marker))) {
        return current;
      }
    }
    if (current === fsRoot) break;
    const parent = dirname(current);
    if (parent === current) break;
    current = parent;
  }
  return null;
}
async function walkUpAsync(startDir, markers, fs5) {
  let current = startDir;
  const fsRoot = parse(current).root;
  while (true) {
    for (const marker of markers) {
      if (await fs5.exists(join(current, marker))) {
        return current;
      }
    }
    if (current === fsRoot) break;
    const parent = dirname(current);
    if (parent === current) break;
    current = parent;
  }
  return null;
}
var DEFAULT_MARKERS = [
  "tsconfig.json",
  "package.json",
  "pyproject.toml",
  "go.mod",
  "Cargo.toml",
  "composer.json",
  ".git"
];
function findProjectRoot(startDir) {
  return walkUp(startDir, DEFAULT_MARKERS);
}
var BUILTIN_SERVERS = {
  typescript: {
    id: "typescript",
    name: "TypeScript Language Server",
    languageIds: ["typescript", "typescriptreact", "javascript", "javascriptreact"],
    markers: ["tsconfig.json", "package.json"],
    command: (root) => {
      const ts = resolveRequire(root, "typescript/lib/tsserver.js");
      if (!ts) return void 0;
      const localBin = join(root, "node_modules", ".bin", "typescript-language-server");
      const cwdBin = join(process.cwd(), "node_modules", ".bin", "typescript-language-server");
      if (existsSync(localBin)) return `${localBin} --stdio`;
      if (existsSync(cwdBin)) return `${cwdBin} --stdio`;
      return void 0;
    },
    initialization: (root) => {
      const ts = resolveRequire(root, "typescript/lib/tsserver.js");
      if (!ts) return void 0;
      return {
        tsserver: {
          path: ts.resolved,
          logVerbosity: "off"
        }
      };
    }
  },
  eslint: {
    id: "eslint",
    name: "ESLint Language Server",
    languageIds: ["typescript", "typescriptreact", "javascript", "javascriptreact"],
    markers: [
      "package.json",
      ".eslintrc.js",
      ".eslintrc.json",
      ".eslintrc.yml",
      ".eslintrc.yaml",
      "eslint.config.js",
      "eslint.config.mjs",
      "eslint.config.ts"
    ],
    command: (root) => {
      const localBin = join(root, "node_modules", ".bin", "vscode-eslint-language-server");
      const cwdBin = join(process.cwd(), "node_modules", ".bin", "vscode-eslint-language-server");
      if (existsSync(localBin)) return `${localBin} --stdio`;
      if (existsSync(cwdBin)) return `${cwdBin} --stdio`;
      return void 0;
    }
  },
  python: {
    id: "python",
    name: "Python Language Server (Pyright)",
    languageIds: ["python"],
    markers: ["pyproject.toml", "setup.py", "requirements.txt", "setup.cfg"],
    command: (root) => {
      const localBin = join(root, "node_modules", ".bin", "pyright-langserver");
      const cwdBin = join(process.cwd(), "node_modules", ".bin", "pyright-langserver");
      if (existsSync(localBin)) return `${localBin} --stdio`;
      if (existsSync(cwdBin)) return `${cwdBin} --stdio`;
      return whichSync("pyright-langserver") ? "pyright-langserver --stdio" : void 0;
    }
  },
  go: {
    id: "go",
    name: "Go Language Server (gopls)",
    languageIds: ["go"],
    markers: ["go.mod"],
    command: () => {
      return whichSync("gopls") ? "gopls serve" : void 0;
    }
  },
  rust: {
    id: "rust",
    name: "Rust Language Server (rust-analyzer)",
    languageIds: ["rust"],
    markers: ["Cargo.toml"],
    command: () => {
      return whichSync("rust-analyzer") ? "rust-analyzer --stdio" : void 0;
    }
  }
};
function getServersForFile(filePath, disabledServers) {
  const languageId = getLanguageId(filePath);
  if (!languageId) return [];
  const disabled = new Set(disabledServers ?? []);
  return Object.values(BUILTIN_SERVERS).filter(
    (server) => !disabled.has(server.id) && server.languageIds.includes(languageId)
  );
}
function mapSeverity(severity) {
  switch (severity) {
    case 1:
      return "error";
    case 2:
      return "warning";
    case 3:
      return "info";
    case 4:
      return "hint";
    default:
      return "warning";
  }
}
var LSPManager = class {
  clients = /* @__PURE__ */ new Map();
  initPromises = /* @__PURE__ */ new Map();
  fileLocks = /* @__PURE__ */ new Map();
  processManager;
  _root;
  config;
  filesystem;
  constructor(processManager, root, config = {}, filesystem) {
    this.processManager = processManager;
    this._root = root;
    this.config = config;
    this.filesystem = filesystem;
  }
  /** Default project root (fallback when per-file walkup finds nothing). */
  get root() {
    return this._root;
  }
  /**
   * Resolve the project root for a given file path using the server's markers.
   * Uses the workspace filesystem when available (supports remote filesystems),
   * falls back to sync walkUp (local disk) otherwise.
   */
  async resolveRoot(filePath, markers) {
    const fileDir = nodePath__default.dirname(filePath);
    if (this.filesystem) {
      return await walkUpAsync(fileDir, markers, this.filesystem) ?? this._root;
    }
    return walkUp(fileDir, markers) ?? this._root;
  }
  /**
   * Acquire a per-file lock so that concurrent getDiagnostics calls for the
   * same file are serialized (preventing interleaved open/change/close).
   * Different files can run in parallel.
   */
  async acquireFileLock(filePath) {
    while (this.fileLocks.has(filePath)) {
      await this.fileLocks.get(filePath);
    }
    let release;
    const lockPromise = new Promise((resolve3) => {
      release = resolve3;
    });
    this.fileLocks.set(filePath, lockPromise);
    return () => {
      this.fileLocks.delete(filePath);
      release();
    };
  }
  /**
   * Initialize an LSP client for the given server definition and project root.
   * Handles timeout, deduplication of concurrent init calls, and caching.
   */
  async initClient(serverDef, projectRoot, key) {
    if (this.initPromises.has(key)) {
      await this.initPromises.get(key);
      return this.clients.get(key) || null;
    }
    const initTimeout = this.config.initTimeout ?? 15e3;
    let timedOut = false;
    const initPromise = (async () => {
      const client = new LSPClient(serverDef, projectRoot, this.processManager);
      await client.initialize(initTimeout);
      if (timedOut) {
        await client.shutdown().catch(() => {
        });
        return;
      }
      this.clients.set(key, client);
    })();
    this.initPromises.set(key, initPromise);
    initPromise.catch(() => {
    });
    try {
      await Promise.race([
        initPromise,
        new Promise(
          (_, reject) => setTimeout(() => reject(new Error("LSP client initialization timed out")), initTimeout + 1e3)
        )
      ]);
      return this.clients.get(key) || null;
    } catch {
      timedOut = true;
      this.clients.delete(key);
      return null;
    } finally {
      this.initPromises.delete(key);
    }
  }
  /**
   * Get or create an LSP client for a file path.
   * Resolves the project root per-file using the server's markers.
   * Returns null if no server is available.
   */
  async getClient(filePath) {
    const servers = getServersForFile(filePath, this.config.disableServers);
    if (servers.length === 0) return null;
    const serverDef = servers.find(
      (s) => s.languageIds.includes("typescript") || s.languageIds.includes("javascript") || s.languageIds.includes("python") || s.languageIds.includes("go")
    ) ?? servers[0];
    const projectRoot = await this.resolveRoot(filePath, serverDef.markers);
    if (serverDef.command(projectRoot) === void 0) return null;
    const key = `${serverDef.name}:${projectRoot}`;
    if (this.clients.has(key)) {
      const existing = this.clients.get(key);
      if (!existing.isAlive) {
        this.clients.delete(key);
        existing.shutdown().catch(() => {
        });
      } else {
        return existing;
      }
    }
    return this.initClient(serverDef, projectRoot, key);
  }
  /**
   * Convenience method: open file, send content, wait for diagnostics, return normalized results.
   * Returns an empty array on any failure (non-blocking).
   * Uses a per-file lock to serialize concurrent calls for the same file.
   */
  async getDiagnostics(filePath, content) {
    const release = await this.acquireFileLock(filePath);
    try {
      const client = await this.getClient(filePath);
      if (!client) return [];
      const languageId = getLanguageId(filePath);
      if (!languageId) return [];
      client.notifyOpen(filePath, content, languageId);
      client.notifyChange(filePath, content, 1);
      const diagnosticTimeout = this.config.diagnosticTimeout ?? 5e3;
      let rawDiagnostics;
      try {
        rawDiagnostics = await client.waitForDiagnostics(filePath, diagnosticTimeout);
      } finally {
        client.notifyClose(filePath);
      }
      return rawDiagnostics.map((d) => ({
        severity: mapSeverity(d.severity),
        message: d.message,
        line: (d.range?.start?.line ?? 0) + 1,
        // LSP is 0-indexed, we report 1-indexed
        character: (d.range?.start?.character ?? 0) + 1,
        source: d.source
      }));
    } catch {
      return [];
    } finally {
      release();
    }
  }
  /**
   * Get diagnostics from ALL matching language servers for a file.
   * Deduplicates results by (line, character, message).
   * Individual server failures don't block other servers.
   */
  async getDiagnosticsMulti(filePath, content) {
    const servers = getServersForFile(filePath, this.config.disableServers);
    if (servers.length === 0) return [];
    const release = await this.acquireFileLock(filePath);
    try {
      const languageId = getLanguageId(filePath);
      if (!languageId) return [];
      const allDiagnostics = [];
      const results = await Promise.allSettled(
        servers.map(async (serverDef) => {
          const projectRoot = await this.resolveRoot(filePath, serverDef.markers);
          if (serverDef.command(projectRoot) === void 0) return [];
          const key = `${serverDef.name}:${projectRoot}`;
          if (this.clients.has(key)) {
            const existing = this.clients.get(key);
            if (!existing.isAlive) {
              this.clients.delete(key);
              existing.shutdown().catch(() => {
              });
            } else {
              return this.collectDiagnostics(existing, filePath, content, languageId);
            }
          }
          const client = await this.initClient(serverDef, projectRoot, key);
          if (!client) return [];
          return this.collectDiagnostics(client, filePath, content, languageId);
        })
      );
      for (const result of results) {
        if (result.status === "fulfilled") {
          allDiagnostics.push(...result.value);
        }
      }
      const seen = /* @__PURE__ */ new Set();
      return allDiagnostics.filter((d) => {
        const key = `${d.line}:${d.character}:${d.message}`;
        if (seen.has(key)) return false;
        seen.add(key);
        return true;
      });
    } finally {
      release();
    }
  }
  /**
   * Collect diagnostics from a single client for a file.
   */
  async collectDiagnostics(client, filePath, content, languageId) {
    client.notifyOpen(filePath, content, languageId);
    client.notifyChange(filePath, content, 1);
    const diagnosticTimeout = this.config.diagnosticTimeout ?? 5e3;
    let rawDiagnostics;
    try {
      rawDiagnostics = await client.waitForDiagnostics(filePath, diagnosticTimeout);
    } finally {
      client.notifyClose(filePath);
    }
    return rawDiagnostics.map((d) => ({
      severity: mapSeverity(d.severity),
      message: d.message,
      line: (d.range?.start?.line ?? 0) + 1,
      character: (d.range?.start?.character ?? 0) + 1,
      source: d.source
    }));
  }
  /**
   * Shutdown all managed LSP clients.
   */
  async shutdownAll() {
    await Promise.allSettled(Array.from(this.clients.values()).map((client) => client.shutdown()));
    this.clients.clear();
    this.initPromises.clear();
    this.fileLocks.clear();
  }
};

// src/workspace/sandbox/errors.ts
var SandboxError = class extends Error {
  constructor(message, code, details) {
    super(message);
    this.code = code;
    this.details = details;
    this.name = "SandboxError";
  }
};
var SandboxExecutionError = class extends SandboxError {
  constructor(message, exitCode, stdout, stderr) {
    super(message, "EXECUTION_FAILED", { exitCode, stdout, stderr });
    this.exitCode = exitCode;
    this.stdout = stdout;
    this.stderr = stderr;
    this.name = "SandboxExecutionError";
  }
};
var SandboxTimeoutError = class extends SandboxError {
  constructor(timeoutMs, operation) {
    super(`Execution timed out after ${timeoutMs}ms`, "TIMEOUT", { timeoutMs, operation });
    this.timeoutMs = timeoutMs;
    this.operation = operation;
    this.name = "SandboxTimeoutError";
  }
};
var SandboxNotReadyError = class extends SandboxError {
  constructor(idOrStatus) {
    super(`Sandbox is not ready: ${idOrStatus}`, "NOT_READY", { id: idOrStatus });
    this.name = "SandboxNotReadyError";
  }
};
var IsolationUnavailableError = class extends SandboxError {
  constructor(backend, reason) {
    super(`Isolation backend '${backend}' is not available: ${reason}`, "ISOLATION_UNAVAILABLE", { backend, reason });
    this.backend = backend;
    this.reason = reason;
    this.name = "IsolationUnavailableError";
  }
};
var MountError = class extends SandboxError {
  constructor(message, mountPath, details) {
    super(message, "MOUNT_ERROR", { ...details, mountPath });
    this.mountPath = mountPath;
    this.name = "MountError";
  }
};
var MountNotSupportedError = class extends SandboxError {
  constructor(sandboxProvider) {
    super(`Sandbox provider '${sandboxProvider}' does not support mounting`, "MOUNT_NOT_SUPPORTED", {
      sandboxProvider
    });
    this.name = "MountNotSupportedError";
  }
};
var FilesystemNotMountableError = class extends SandboxError {
  constructor(filesystemProvider, reason) {
    const message = reason ? `Filesystem '${filesystemProvider}' cannot be mounted: ${reason}` : `Filesystem '${filesystemProvider}' does not support mounting`;
    super(message, "FILESYSTEM_NOT_MOUNTABLE", { filesystemProvider, reason });
    this.name = "FilesystemNotMountableError";
  }
};
var MountManager = class {
  _entries = /* @__PURE__ */ new Map();
  _mountFn;
  _onMount;
  _sandbox;
  _workspace;
  logger;
  constructor(config) {
    this._mountFn = config.mount;
    this.logger = config.logger;
  }
  /**
   * Set the sandbox and workspace references for onMount hook args.
   * Called by Workspace during construction.
   */
  setContext(context) {
    this._sandbox = context.sandbox;
    this._workspace = context.workspace;
  }
  /**
   * Set the onMount hook for custom mount handling.
   * Called before each mount - can skip, handle, or defer to default.
   */
  setOnMount(hook) {
    this._onMount = hook;
  }
  /**
   * Update the logger instance.
   * Called when the sandbox receives a logger from Mastra.
   * @internal
   */
  __setLogger(logger) {
    this.logger = logger;
  }
  // ---------------------------------------------------------------------------
  // Entry Access
  // ---------------------------------------------------------------------------
  /**
   * Get all mount entries.
   */
  get entries() {
    return this._entries;
  }
  /**
   * Get a mount entry by path.
   */
  get(path6) {
    return this._entries.get(path6);
  }
  /**
   * Check if a mount exists at the given path.
   */
  has(path6) {
    return this._entries.has(path6);
  }
  // ---------------------------------------------------------------------------
  // Entry Modification
  // ---------------------------------------------------------------------------
  /**
   * Add pending mounts from workspace config.
   * These will be processed when `processPending()` is called.
   */
  add(mounts) {
    const paths = Object.keys(mounts);
    this.logger.debug(`Adding ${paths.length} pending mount(s)`, { paths });
    for (const [path6, filesystem] of Object.entries(mounts)) {
      this._entries.set(path6, {
        filesystem,
        state: "pending"
      });
    }
  }
  /**
   * Update a mount entry's state.
   * Creates the entry if it doesn't exist.
   */
  set(path6, updates) {
    const existing = this._entries.get(path6);
    if (existing) {
      existing.state = updates.state;
      if (updates.config) {
        existing.config = updates.config;
        existing.configHash = this.hashConfig(updates.config);
      }
      if ("error" in updates) {
        existing.error = updates.error;
      }
    } else if (updates.filesystem) {
      this._entries.set(path6, {
        filesystem: updates.filesystem,
        state: updates.state,
        config: updates.config,
        configHash: updates.config ? this.hashConfig(updates.config) : void 0,
        error: updates.error
      });
    } else {
      this.logger.debug(`set() called for unknown path "${path6}" without filesystem \u2014 no entry created`);
    }
  }
  /**
   * Delete a mount entry.
   */
  delete(path6) {
    return this._entries.delete(path6);
  }
  /**
   * Clear all mount entries.
   */
  clear() {
    this._entries.clear();
  }
  // ---------------------------------------------------------------------------
  // Mount Processing
  // ---------------------------------------------------------------------------
  /**
   * Process all pending mounts.
   * Call this after sandbox is ready (in start()).
   */
  async processPending() {
    const pendingCount = [...this._entries.values()].filter((e) => e.state === "pending").length;
    if (pendingCount === 0) {
      return;
    }
    this.logger.debug(`Processing ${pendingCount} pending mount(s)`);
    for (const [path6, entry] of this._entries) {
      if (entry.state !== "pending") {
        continue;
      }
      const fsProvider = entry.filesystem.provider;
      const config = entry.filesystem.getMountConfig?.();
      if (this._onMount) {
        try {
          const hookResult = await this._onMount({
            filesystem: entry.filesystem,
            mountPath: path6,
            config,
            sandbox: this._sandbox,
            workspace: this._workspace
          });
          if (hookResult === false) {
            entry.state = "unsupported";
            entry.error = "Skipped by onMount hook";
            this.logger.debug(`Mount skipped by onMount hook`, { path: path6, provider: fsProvider });
            continue;
          }
          if (hookResult && typeof hookResult === "object") {
            if (hookResult.success) {
              entry.state = "mounted";
              entry.config = config;
              entry.configHash = config ? this.hashConfig(config) : void 0;
              this.logger.info(`Mount handled by onMount hook`, { path: path6, provider: fsProvider });
            } else {
              entry.state = "error";
              entry.error = hookResult.error ?? "Mount hook failed";
              this.logger.error(`Mount hook failed`, { path: path6, provider: fsProvider, error: entry.error });
            }
            continue;
          }
        } catch (err) {
          entry.state = "error";
          entry.error = `Mount hook error: ${String(err)}`;
          this.logger.error(`Mount hook threw error`, { path: path6, provider: fsProvider, error: entry.error });
          continue;
        }
      }
      if (!config) {
        entry.state = "unsupported";
        entry.error = "Filesystem does not support mounting";
        this.logger.debug(`Filesystem does not support mounting`, { path: path6, provider: fsProvider });
        continue;
      }
      entry.config = config;
      entry.configHash = this.hashConfig(config);
      entry.state = "mounting";
      this.logger.debug(`Mounting filesystem`, { path: path6, provider: fsProvider, type: config.type });
      try {
        const result = await this._mountFn(entry.filesystem, path6);
        if (result.success) {
          entry.state = "mounted";
          this.logger.info(`Mount successful`, { path: path6, provider: fsProvider });
        } else {
          entry.state = "error";
          entry.error = result.error ?? "Mount failed";
          this.logger.error(`Mount failed`, { path: path6, provider: fsProvider, error: entry.error });
        }
      } catch (err) {
        entry.state = "error";
        entry.error = String(err);
        this.logger.error(`Mount threw error`, { path: path6, provider: fsProvider, error: entry.error });
      }
    }
  }
  // ---------------------------------------------------------------------------
  // Marker File Helpers
  // ---------------------------------------------------------------------------
  /**
   * Generate a marker filename for a mount path.
   * Used by sandboxes to store mount metadata for reconnection detection.
   *
   * @param mountPath - The mount path to generate a filename for
   * @returns A safe filename like "mount-abc123"
   */
  markerFilename(mountPath) {
    let hash = 0;
    for (let i = 0; i < mountPath.length; i++) {
      const char = mountPath.charCodeAt(i);
      hash = (hash << 5) - hash + char;
      hash |= 0;
    }
    return `mount-${Math.abs(hash).toString(36)}`;
  }
  /**
   * Generate marker file content for a mount path.
   * Format: "path|configHash" - used for detecting config changes on reconnect.
   *
   * @param mountPath - The mount path
   * @returns Marker content string, or null if no config hash available
   */
  getMarkerContent(mountPath) {
    const entry = this._entries.get(mountPath);
    if (!entry?.configHash) {
      return null;
    }
    return `${mountPath}|${entry.configHash}`;
  }
  /**
   * Parse marker file content.
   *
   * @param content - The marker file content (format: "path|configHash")
   * @returns Parsed path and configHash, or null if invalid format
   */
  parseMarkerContent(content) {
    const separatorIndex = content.lastIndexOf("|");
    if (separatorIndex <= 0) {
      return null;
    }
    const path6 = content.slice(0, separatorIndex);
    const configHash = content.slice(separatorIndex + 1);
    if (!path6 || !configHash) return null;
    return { path: path6, configHash };
  }
  /**
   * Check if a config hash matches the expected hash for a mount path.
   *
   * @param mountPath - The mount path to check
   * @param storedHash - The hash from the marker file
   * @returns true if the hashes match
   */
  isConfigMatching(mountPath, storedHash) {
    const entry = this._entries.get(mountPath);
    return entry?.configHash === storedHash;
  }
  /**
   * Compute a hash for a mount config. Used for comparing configs across mounts.
   *
   * @param config - The config to hash
   * @returns A hash string suitable for comparison
   */
  computeConfigHash(config) {
    return this.hashConfig(config);
  }
  // ---------------------------------------------------------------------------
  // Internal
  // ---------------------------------------------------------------------------
  /**
   * Hash a mount config for comparison.
   */
  hashConfig(config) {
    const normalized = JSON.stringify(this.sortKeysDeep(config));
    return createHash("sha256").update(normalized).digest("hex").slice(0, 16);
  }
  sortKeysDeep(obj) {
    if (obj === null || typeof obj !== "object") return obj;
    if (Array.isArray(obj)) return obj.map((item) => this.sortKeysDeep(item));
    return Object.keys(obj).sort().reduce(
      (acc, key) => {
        acc[key] = this.sortKeysDeep(obj[key]);
        return acc;
      },
      {}
    );
  }
};

// src/workspace/sandbox/utils.ts
function shellQuote(arg) {
  if (/^[a-zA-Z0-9._\-\/=:@]+$/.test(arg)) return arg;
  return `'${arg.replace(/'/g, "'\\''")}'`;
}

// src/workspace/sandbox/mastra-sandbox.ts
var MastraSandbox = class extends MastraBase {
  /** Process manager */
  processes;
  /** Mount manager - automatically created if subclass implements mount() */
  mounts;
  // ---------------------------------------------------------------------------
  // Lifecycle Promise Tracking (prevents race conditions)
  // ---------------------------------------------------------------------------
  /** Promise for _start() to prevent race conditions from concurrent calls */
  _startPromise;
  /** Promise for _stop() to prevent race conditions from concurrent calls */
  _stopPromise;
  /** Promise for _destroy() to prevent race conditions from concurrent calls */
  _destroyPromise;
  /** Lifecycle callbacks */
  _onStart;
  _onStop;
  _onDestroy;
  constructor(options) {
    super({ name: options.name, component: RegisteredLogger.WORKSPACE });
    this._onStart = options.onStart;
    this._onStop = options.onStop;
    this._onDestroy = options.onDestroy;
    if (this.mount) {
      this.mounts = new MountManager({
        mount: this.mount.bind(this),
        logger: this.logger
      });
    }
    if (options.processes) {
      const pm = options.processes;
      pm.sandbox = this;
      this.processes = pm;
      if (!this.executeCommand) {
        this.executeCommand = async (command, args, opts) => {
          const fullCommand = args?.length ? `${command} ${args.map((a) => shellQuote(a)).join(" ")}` : command;
          this.logger.debug(`[${this.name}] Executing: ${fullCommand}`, { cwd: opts?.cwd });
          const handle = await pm.spawn(fullCommand, opts ?? {});
          const result = await handle.wait();
          this.logger.debug(`[${this.name}] Exit code: ${result.exitCode} (${result.executionTimeMs}ms)`);
          return { ...result, command: fullCommand };
        };
      }
    }
  }
  // ---------------------------------------------------------------------------
  // Lifecycle Wrappers (race-condition-safe)
  // ---------------------------------------------------------------------------
  /**
   * Start the sandbox (wrapper with status management and race-condition safety).
   *
   * This method is race-condition-safe - concurrent calls will return the same promise.
   * Handles status management and automatically processes pending mounts after startup.
   *
   * Subclasses override `start()` to provide their startup logic.
   */
  async _start() {
    if (this.status === "running") {
      return;
    }
    if (this._stopPromise) await this._stopPromise;
    if (this._destroyPromise) await this._destroyPromise;
    if (this.status === "destroyed") {
      throw new Error("Cannot start a destroyed sandbox");
    }
    if (this._startPromise) {
      return this._startPromise;
    }
    this._startPromise = this._executeStart();
    try {
      await this._startPromise;
    } finally {
      this._startPromise = void 0;
    }
  }
  /**
   * Internal start execution - handles status and mount processing.
   */
  async _executeStart() {
    this.status = "starting";
    try {
      await this.start();
      this.status = "running";
      try {
        await this._onStart?.({ sandbox: this });
      } catch (error) {
        this.logger.warn("onStart callback failed", { error });
      }
    } catch (error) {
      this.status = "error";
      throw error;
    }
    try {
      await this.mounts?.processPending();
    } catch (error) {
      this.logger.warn("Unexpected error processing pending mounts", { error });
    }
  }
  /**
   * Override this method to implement sandbox startup logic.
   *
   * Called by `_start()` after status is set to 'starting'.
   * Status will be set to 'running' on success, 'error' on failure.
   *
   * @example
   * ```typescript
   * async start(): Promise<void> {
   *   this._sandbox = await Sandbox.create({ ... });
   * }
   * ```
   */
  async start() {
  }
  /**
   * Ensure the sandbox is running.
   *
   * Calls `_start()` if status is not 'running'. Useful for lazy initialization
   * where operations should automatically start the sandbox if needed.
   *
   * @throws {SandboxNotReadyError} if the sandbox fails to reach 'running' status
   *
   * @example
   * ```typescript
   * async executeCommand(command: string): Promise<CommandResult> {
   *   await this.ensureRunning();
   *   // Now safe to use the sandbox
   * }
   * ```
   */
  async ensureRunning() {
    if (this.status === "destroyed") {
      throw new SandboxNotReadyError(this.id);
    }
    if (this.status === "destroying" || this.status === "stopping") {
      return;
    }
    if (this.status !== "running") {
      await this._start();
    }
    if (this.status !== "running") {
      throw new SandboxNotReadyError(this.id);
    }
  }
  /**
   * Stop the sandbox (wrapper with status management and race-condition safety).
   *
   * This method is race-condition-safe - concurrent calls will return the same promise.
   * Handles status management.
   *
   * Subclasses override `stop()` to provide their stop logic.
   */
  async _stop() {
    if (this.status === "stopped") {
      return;
    }
    if (this._startPromise) await this._startPromise.catch(() => {
    });
    if (this._stopPromise) {
      return this._stopPromise;
    }
    this._stopPromise = this._executeStop();
    try {
      await this._stopPromise;
    } finally {
      this._stopPromise = void 0;
    }
  }
  /**
   * Internal stop execution - handles status.
   */
  async _executeStop() {
    this.status = "stopping";
    try {
      await this._onStop?.({ sandbox: this });
      await this.stop();
      this.status = "stopped";
    } catch (error) {
      this.status = "error";
      throw error;
    }
  }
  /**
   * Override this method to implement sandbox stop logic.
   *
   * Called by `_stop()` after status is set to 'stopping'.
   * Status will be set to 'stopped' on success, 'error' on failure.
   */
  async stop() {
  }
  /**
   * Destroy the sandbox and clean up all resources (wrapper with status management).
   *
   * This method is race-condition-safe - concurrent calls will return the same promise.
   * Handles status management.
   *
   * Subclasses override `destroy()` to provide their destroy logic.
   */
  async _destroy() {
    if (this.status === "destroyed") {
      return;
    }
    if (this.status === "pending") {
      this.status = "destroyed";
      return;
    }
    if (this._startPromise) await this._startPromise.catch(() => {
    });
    if (this._stopPromise) await this._stopPromise.catch(() => {
    });
    if (this._destroyPromise) {
      return this._destroyPromise;
    }
    this._destroyPromise = this._executeDestroy();
    try {
      await this._destroyPromise;
    } finally {
      this._destroyPromise = void 0;
    }
  }
  /**
   * Internal destroy execution - handles status.
   */
  async _executeDestroy() {
    this.status = "destroying";
    try {
      await this._onDestroy?.({ sandbox: this });
      await this.destroy();
      this.status = "destroyed";
    } catch (error) {
      this.status = "error";
      throw error;
    }
  }
  /**
   * Override this method to implement sandbox destroy logic.
   *
   * Called by `_destroy()` after status is set to 'destroying'.
   * Status will be set to 'destroyed' on success, 'error' on failure.
   */
  async destroy() {
  }
  // ---------------------------------------------------------------------------
  // Logger Propagation
  // ---------------------------------------------------------------------------
  /**
   * Override to propagate logger to MountManager.
   * @internal
   */
  __setLogger(logger) {
    super.__setLogger(logger);
    this.mounts?.__setLogger(logger);
  }
};

// src/workspace/line-utils.ts
function extractLines(content, startLine, endLine) {
  const allLines = content.split("\n");
  const totalLines = allLines.length;
  const start = Math.max(1, startLine ?? 1);
  const end = Math.min(totalLines, endLine ?? totalLines);
  const extractedLines = allLines.slice(start - 1, end);
  return {
    content: extractedLines.join("\n"),
    lines: { start, end },
    totalLines
  };
}
function extractLinesWithLimit(content, offset, limit) {
  const startLine = offset ?? 1;
  const endLine = limit ? startLine + limit - 1 : void 0;
  return extractLines(content, startLine, endLine);
}
function formatWithLineNumbers(content, startLineNumber = 1) {
  const lines = content.split("\n");
  const maxLineNum = startLineNumber + lines.length - 1;
  const padWidth = Math.max(6, String(maxLineNum).length + 1);
  return lines.map((line, i) => {
    const lineNum = startLineNumber + i;
    return `${String(lineNum).padStart(padWidth)}\u2192${line}`;
  }).join("\n");
}
function countOccurrences(content, searchString) {
  if (!searchString) return 0;
  let count = 0;
  let position = 0;
  while ((position = content.indexOf(searchString, position)) !== -1) {
    count++;
    position += searchString.length;
  }
  return count;
}
function replaceString(content, oldString, newString, replaceAll = false) {
  const count = countOccurrences(content, oldString);
  if (count === 0) {
    throw new StringNotFoundError(oldString);
  }
  if (!replaceAll && count > 1) {
    throw new StringNotUniqueError(oldString, count);
  }
  if (replaceAll) {
    const result = content.split(oldString).join(newString);
    return { content: result, replacements: count };
  } else {
    const result = content.replace(oldString, newString);
    return { content: result, replacements: 1 };
  }
}
var StringNotFoundError = class extends Error {
  constructor(searchString) {
    super(`The specified text was not found. Make sure you use the exact text from the file.`);
    this.searchString = searchString;
    this.name = "StringNotFoundError";
  }
};
var StringNotUniqueError = class extends Error {
  constructor(searchString, occurrences) {
    super(
      `The specified text appears ${occurrences} times. Provide more surrounding context to make the match unique, or use replace_all to replace all occurrences.`
    );
    this.searchString = searchString;
    this.occurrences = occurrences;
    this.name = "StringNotUniqueError";
  }
};

// src/workspace/search/bm25.ts
var DEFAULT_STOPWORDS = /* @__PURE__ */ new Set([
  "a",
  "an",
  "and",
  "are",
  "as",
  "at",
  "be",
  "by",
  "for",
  "from",
  "has",
  "he",
  "in",
  "is",
  "it",
  "its",
  "of",
  "on",
  "or",
  "that",
  "the",
  "to",
  "was",
  "were",
  "will",
  "with"
]);
var DEFAULT_TOKENIZE_OPTIONS = {
  lowercase: true,
  removePunctuation: true,
  minLength: 2,
  stopwords: DEFAULT_STOPWORDS,
  splitPattern: /\s+/
};
function tokenize(text, options = {}) {
  const opts = { ...DEFAULT_TOKENIZE_OPTIONS, ...options };
  let processed = text;
  if (opts.lowercase) {
    processed = processed.toLowerCase();
  }
  if (opts.removePunctuation) {
    processed = processed.replace(/[^\w\s]/g, " ");
  }
  const tokens = processed.split(opts.splitPattern).filter((token) => {
    if (token.length < opts.minLength) {
      return false;
    }
    if (opts.stopwords?.has(token)) {
      return false;
    }
    return true;
  });
  return tokens;
}
function findLineRange(content, queryTerms, options = {}) {
  if (queryTerms.length === 0) return void 0;
  const lines = content.split("\n");
  const defaultOpts = { lowercase: true, removePunctuation: true, minLength: 2 };
  const opts = { ...defaultOpts, ...options };
  const normalizedTerms = new Set(queryTerms.map((t) => opts.lowercase ? t.toLowerCase() : t));
  let firstMatchLine;
  let lastMatchLine;
  for (let i = 0; i < lines.length; i++) {
    const lineTokens = tokenize(lines[i], options);
    for (const token of lineTokens) {
      if (normalizedTerms.has(token)) {
        const lineNum = i + 1;
        if (firstMatchLine === void 0) {
          firstMatchLine = lineNum;
        }
        lastMatchLine = lineNum;
        break;
      }
    }
  }
  if (firstMatchLine !== void 0 && lastMatchLine !== void 0) {
    return { start: firstMatchLine, end: lastMatchLine };
  }
  return void 0;
}
function computeTermFrequencies(tokens) {
  const frequencies = /* @__PURE__ */ new Map();
  for (const token of tokens) {
    frequencies.set(token, (frequencies.get(token) || 0) + 1);
  }
  return frequencies;
}
var BM25Index = class _BM25Index {
  /** BM25 k1 parameter */
  k1;
  /** BM25 b parameter */
  b;
  /** Documents in the index */
  #documents = /* @__PURE__ */ new Map();
  /** Inverted index: term -> document IDs containing the term */
  #invertedIndex = /* @__PURE__ */ new Map();
  /** Document frequency: term -> number of documents containing the term */
  #documentFrequency = /* @__PURE__ */ new Map();
  /** Average document length */
  #avgDocLength = 0;
  /** Total number of documents */
  #docCount = 0;
  /** Tokenization options */
  #tokenizeOptions;
  constructor(config = {}, tokenizeOptions = {}) {
    this.k1 = config.k1 ?? 1.5;
    this.b = config.b ?? 0.75;
    this.#tokenizeOptions = tokenizeOptions;
  }
  /**
   * Add a document to the index
   */
  add(id, content, metadata) {
    if (this.#documents.has(id)) {
      this.remove(id);
    }
    const tokens = tokenize(content, this.#tokenizeOptions);
    const termFrequencies = computeTermFrequencies(tokens);
    const doc = {
      id,
      content,
      tokens,
      termFrequencies,
      length: tokens.length,
      metadata
    };
    this.#documents.set(id, doc);
    this.#docCount++;
    for (const term of termFrequencies.keys()) {
      if (!this.#invertedIndex.has(term)) {
        this.#invertedIndex.set(term, /* @__PURE__ */ new Set());
      }
      this.#invertedIndex.get(term).add(id);
      this.#documentFrequency.set(term, (this.#documentFrequency.get(term) || 0) + 1);
    }
    this.#updateAvgDocLength();
  }
  /**
   * Remove a document from the index
   */
  remove(id) {
    const doc = this.#documents.get(id);
    if (!doc) {
      return false;
    }
    for (const term of doc.termFrequencies.keys()) {
      const docIds = this.#invertedIndex.get(term);
      if (docIds) {
        docIds.delete(id);
        if (docIds.size === 0) {
          this.#invertedIndex.delete(term);
          this.#documentFrequency.delete(term);
        } else {
          this.#documentFrequency.set(term, (this.#documentFrequency.get(term) || 1) - 1);
        }
      }
    }
    this.#documents.delete(id);
    this.#docCount--;
    this.#updateAvgDocLength();
    return true;
  }
  /**
   * Clear all documents from the index
   */
  clear() {
    this.#documents.clear();
    this.#invertedIndex.clear();
    this.#documentFrequency.clear();
    this.#docCount = 0;
    this.#avgDocLength = 0;
  }
  /**
   * Search for documents matching the query
   */
  search(query, topK = 10, minScore = 0) {
    const queryTokens = tokenize(query, this.#tokenizeOptions);
    if (queryTokens.length === 0 || this.#docCount === 0) {
      return [];
    }
    const scores = /* @__PURE__ */ new Map();
    for (const queryTerm of queryTokens) {
      const docIds = this.#invertedIndex.get(queryTerm);
      if (!docIds) {
        continue;
      }
      const df = this.#documentFrequency.get(queryTerm) || 0;
      const idf = this.#computeIDF(df);
      for (const docId of docIds) {
        const doc = this.#documents.get(docId);
        const tf = doc.termFrequencies.get(queryTerm) || 0;
        const termScore = this.#computeTermScore(tf, doc.length, idf);
        scores.set(docId, (scores.get(docId) || 0) + termScore);
      }
    }
    const results = [];
    for (const [docId, score] of scores.entries()) {
      if (score >= minScore) {
        const doc = this.#documents.get(docId);
        results.push({
          id: docId,
          content: doc.content,
          score,
          metadata: doc.metadata
        });
      }
    }
    results.sort((a, b) => b.score - a.score);
    return results.slice(0, topK);
  }
  /**
   * Get a document by ID
   */
  get(id) {
    return this.#documents.get(id);
  }
  /**
   * Check if a document exists in the index
   */
  has(id) {
    return this.#documents.has(id);
  }
  /**
   * Get the number of documents in the index
   */
  get size() {
    return this.#docCount;
  }
  /**
   * Get all document IDs
   */
  get documentIds() {
    return Array.from(this.#documents.keys());
  }
  /**
   * Serialize the index to a JSON-compatible object
   */
  serialize() {
    const documents = [];
    for (const [id, doc] of this.#documents.entries()) {
      documents.push({
        id,
        content: doc.content,
        tokens: doc.tokens,
        termFrequencies: Object.fromEntries(doc.termFrequencies),
        length: doc.length,
        metadata: doc.metadata
      });
    }
    return {
      k1: this.k1,
      b: this.b,
      documents,
      avgDocLength: this.#avgDocLength
    };
  }
  /**
   * Deserialize an index from a JSON object
   */
  static deserialize(data, tokenizeOptions = {}) {
    const index = new _BM25Index({ k1: data.k1, b: data.b }, tokenizeOptions);
    for (const doc of data.documents) {
      const termFrequencies = new Map(Object.entries(doc.termFrequencies));
      const document = {
        id: doc.id,
        content: doc.content,
        tokens: doc.tokens,
        termFrequencies,
        length: doc.length,
        metadata: doc.metadata
      };
      index.#documents.set(doc.id, document);
      index.#docCount++;
      for (const term of termFrequencies.keys()) {
        if (!index.#invertedIndex.has(term)) {
          index.#invertedIndex.set(term, /* @__PURE__ */ new Set());
        }
        index.#invertedIndex.get(term).add(doc.id);
        index.#documentFrequency.set(term, (index.#documentFrequency.get(term) || 0) + 1);
      }
    }
    index.#avgDocLength = data.avgDocLength;
    return index;
  }
  /**
   * Update average document length after add/remove operations
   */
  #updateAvgDocLength() {
    if (this.#docCount === 0) {
      this.#avgDocLength = 0;
      return;
    }
    let totalLength = 0;
    for (const doc of this.#documents.values()) {
      totalLength += doc.length;
    }
    this.#avgDocLength = totalLength / this.#docCount;
  }
  /**
   * Compute IDF (Inverse Document Frequency) for a term
   */
  #computeIDF(df) {
    return Math.log((this.#docCount - df + 0.5) / (df + 0.5) + 1);
  }
  /**
   * Compute the BM25 score component for a single term
   */
  #computeTermScore(tf, docLength, idf) {
    const numerator = tf * (this.k1 + 1);
    const denominator = tf + this.k1 * (1 - this.b + this.b * (docLength / this.#avgDocLength));
    return idf * (numerator / denominator);
  }
};

// src/workspace/search/search-engine.ts
var SearchEngine = class {
  /** BM25 index for keyword search */
  #bm25Index;
  /** Tokenization options (stored for lineRange computation) */
  #tokenizeOptions;
  /** Vector configuration */
  #vectorConfig;
  /** Whether to use lazy vector indexing */
  #lazyVectorIndex;
  /** Documents pending vector indexing (for lazy mode) */
  #pendingVectorDocs = [];
  /** Whether vector index has been built (for lazy mode) */
  #vectorIndexBuilt = false;
  constructor(config = {}) {
    if (config.bm25 !== void 0) {
      this.#tokenizeOptions = config.bm25.tokenize;
      this.#bm25Index = new BM25Index(config.bm25.bm25, this.#tokenizeOptions);
    }
    if (config.vector) {
      this.#vectorConfig = config.vector;
    }
    this.#lazyVectorIndex = config.lazyVectorIndex ?? false;
  }
  // ===========================================================================
  // Public API
  // ===========================================================================
  /**
   * Index a document for search
   */
  async index(doc) {
    const metadata = {
      ...doc.metadata
    };
    if (doc.startLineOffset !== void 0) {
      metadata._startLineOffset = doc.startLineOffset;
    }
    if (this.#bm25Index) {
      this.#bm25Index.add(doc.id, doc.content, metadata);
    }
    if (this.#vectorConfig) {
      const docWithMergedMetadata = { ...doc, metadata };
      if (this.#lazyVectorIndex) {
        this.#pendingVectorDocs.push(docWithMergedMetadata);
        this.#vectorIndexBuilt = false;
      } else {
        await this.#indexVector(docWithMergedMetadata);
      }
    }
  }
  /**
   * Index multiple documents
   */
  async indexMany(docs) {
    for (const doc of docs) {
      await this.index(doc);
    }
  }
  /**
   * Remove a document from the index
   */
  async remove(id) {
    if (this.#bm25Index) {
      this.#bm25Index.remove(id);
    }
    if (this.#vectorConfig) {
      try {
        await this.#vectorConfig.vectorStore.deleteVector({
          indexName: this.#vectorConfig.indexName,
          id
        });
      } catch {
      }
      if (this.#lazyVectorIndex) {
        this.#pendingVectorDocs = this.#pendingVectorDocs.filter((d) => d.id !== id);
      }
    }
  }
  /**
   * Clear all indexed documents
   */
  clear() {
    if (this.#bm25Index) {
      this.#bm25Index.clear();
    }
    this.#pendingVectorDocs = [];
    this.#vectorIndexBuilt = false;
  }
  /**
   * Search for documents
   */
  async search(query, options = {}) {
    const { topK = 10, minScore, mode, vectorWeight = 0.5, filter } = options;
    const effectiveMode = this.#determineSearchMode(mode);
    if (effectiveMode === "bm25") {
      return this.#searchBM25(query, topK, minScore);
    }
    if (effectiveMode === "vector") {
      return this.#searchVector(query, topK, minScore, filter);
    }
    return this.#searchHybrid(query, topK, minScore, vectorWeight, filter);
  }
  /**
   * Check if BM25 search is available
   */
  get canBM25() {
    return !!this.#bm25Index;
  }
  /**
   * Check if vector search is available
   */
  get canVector() {
    return !!this.#vectorConfig;
  }
  /**
   * Check if hybrid search is available
   */
  get canHybrid() {
    return this.canBM25 && this.canVector;
  }
  /**
   * Get the BM25 index (for serialization/debugging)
   */
  get bm25Index() {
    return this.#bm25Index;
  }
  // ===========================================================================
  // Private Methods
  // ===========================================================================
  /**
   * Determine the effective search mode
   */
  #determineSearchMode(requestedMode) {
    if (requestedMode) {
      if (requestedMode === "vector" && !this.canVector) {
        throw new Error("Vector search requires vector configuration.");
      }
      if (requestedMode === "bm25" && !this.canBM25) {
        throw new Error("BM25 search requires BM25 configuration.");
      }
      if (requestedMode === "hybrid" && !this.canHybrid) {
        throw new Error("Hybrid search requires both vector and BM25 configuration.");
      }
      return requestedMode;
    }
    if (this.canHybrid) {
      return "hybrid";
    }
    if (this.canVector) {
      return "vector";
    }
    if (this.canBM25) {
      return "bm25";
    }
    throw new Error("No search configuration available. Provide bm25 or vector config.");
  }
  /**
   * Index a single document in the vector store
   */
  async #indexVector(doc) {
    if (!this.#vectorConfig) return;
    const { vectorStore, embedder, indexName } = this.#vectorConfig;
    const embedding = await embedder(doc.content);
    await vectorStore.upsert({
      indexName,
      vectors: [embedding],
      metadata: [
        {
          id: doc.id,
          text: doc.content,
          ...doc.metadata
        }
      ],
      ids: [doc.id]
    });
  }
  /**
   * Ensure vector index is built (for lazy mode)
   */
  async #ensureVectorIndex() {
    if (!this.#lazyVectorIndex || this.#vectorIndexBuilt || this.#pendingVectorDocs.length === 0) {
      return;
    }
    for (const doc of this.#pendingVectorDocs) {
      await this.#indexVector(doc);
    }
    this.#pendingVectorDocs = [];
    this.#vectorIndexBuilt = true;
  }
  /**
   * BM25 keyword search
   */
  #searchBM25(query, topK, minScore) {
    if (!this.#bm25Index) {
      throw new Error("BM25 search requires BM25 configuration.");
    }
    const results = this.#bm25Index.search(query, topK, minScore);
    const queryTokens = tokenize(query, this.#tokenizeOptions);
    return results.map((result) => {
      const rawLineRange = findLineRange(result.content, queryTokens, this.#tokenizeOptions);
      const lineRange = this.#adjustLineRange(rawLineRange, result.metadata);
      const { _startLineOffset, ...cleanMetadata } = result.metadata ?? {};
      return {
        id: result.id,
        content: result.content,
        score: result.score,
        lineRange,
        metadata: Object.keys(cleanMetadata).length > 0 ? cleanMetadata : void 0,
        scoreDetails: { bm25: result.score }
      };
    });
  }
  /**
   * Vector semantic search
   */
  async #searchVector(query, topK, minScore, filter) {
    if (!this.#vectorConfig) {
      throw new Error("Vector search requires vector configuration.");
    }
    await this.#ensureVectorIndex();
    const { vectorStore, embedder, indexName } = this.#vectorConfig;
    const queryEmbedding = await embedder(query);
    const vectorResults = await vectorStore.query({
      indexName,
      queryVector: queryEmbedding,
      topK,
      filter
    });
    const queryTokens = tokenize(query, this.#tokenizeOptions);
    const results = [];
    for (const result of vectorResults) {
      if (minScore !== void 0 && result.score < minScore) {
        continue;
      }
      const id = result.metadata?.id ?? result.id;
      const content = result.metadata?.text ?? "";
      const { id: _id, text: _text, _startLineOffset, ...restMetadata } = result.metadata ?? {};
      const rawLineRange = findLineRange(content, queryTokens, this.#tokenizeOptions);
      const lineRange = this.#adjustLineRange(rawLineRange, result.metadata);
      results.push({
        id,
        content,
        score: result.score,
        lineRange,
        metadata: Object.keys(restMetadata).length > 0 ? restMetadata : void 0,
        scoreDetails: { vector: result.score }
      });
    }
    return results;
  }
  /**
   * Hybrid search combining vector and BM25 scores
   */
  async #searchHybrid(query, topK, minScore, vectorWeight = 0.5, filter) {
    const expandedTopK = Math.min(topK * 2, 50);
    const [vectorResults, bm25Results] = await Promise.all([
      this.#searchVector(query, expandedTopK, void 0, filter),
      Promise.resolve(this.#searchBM25(query, expandedTopK, void 0))
    ]);
    const normalizedBM25 = this.#normalizeBM25Scores(bm25Results);
    const bm25Map = /* @__PURE__ */ new Map();
    for (const result of normalizedBM25) {
      bm25Map.set(result.id, result);
    }
    const vectorMap = /* @__PURE__ */ new Map();
    for (const result of vectorResults) {
      vectorMap.set(result.id, result);
    }
    const combinedResults = /* @__PURE__ */ new Map();
    const allIds = /* @__PURE__ */ new Set([...vectorMap.keys(), ...bm25Map.keys()]);
    const bm25Weight = 1 - vectorWeight;
    for (const id of allIds) {
      const vectorResult = vectorMap.get(id);
      const bm25Result = bm25Map.get(id);
      const vectorScore = vectorResult?.scoreDetails?.vector ?? 0;
      const bm25Score = bm25Result?.score ?? 0;
      const combinedScore = vectorWeight * vectorScore + bm25Weight * bm25Score;
      const baseResult = vectorResult ?? bm25Result;
      combinedResults.set(id, {
        id,
        content: baseResult.content,
        score: combinedScore,
        lineRange: bm25Result?.lineRange ?? vectorResult?.lineRange,
        metadata: baseResult.metadata,
        scoreDetails: {
          vector: vectorResult?.scoreDetails?.vector,
          bm25: bm25Result?.scoreDetails?.bm25
        }
      });
    }
    let results = Array.from(combinedResults.values());
    results.sort((a, b) => b.score - a.score);
    if (minScore !== void 0) {
      results = results.filter((r) => r.score >= minScore);
    }
    return results.slice(0, topK);
  }
  /**
   * Normalize BM25 scores to 0-1 range using min-max normalization
   */
  #normalizeBM25Scores(results) {
    if (results.length === 0) return results;
    const scores = results.map((r) => r.scoreDetails?.bm25 ?? r.score);
    const maxScore = Math.max(...scores);
    const minScore = Math.min(...scores);
    const range = maxScore - minScore;
    if (range === 0) {
      return results.map((r) => ({ ...r, score: 1 }));
    }
    return results.map((r) => ({
      ...r,
      score: ((r.scoreDetails?.bm25 ?? r.score) - minScore) / range
    }));
  }
  /**
   * Adjust line range for chunked documents.
   * If the document has a _startLineOffset in metadata, adjust the line range
   * to reflect the original document's line numbers.
   */
  #adjustLineRange(lineRange, metadata) {
    if (!lineRange) return void 0;
    const startLineOffset = metadata?._startLineOffset;
    if (typeof startLineOffset !== "number") {
      return lineRange;
    }
    return {
      start: lineRange.start + startLineOffset - 1,
      end: lineRange.end + startLineOffset - 1
    };
  }
};

// src/workspace/skills/schemas.ts
var SKILL_LIMITS = {
  /** Recommended max tokens for instructions */
  MAX_INSTRUCTION_TOKENS: 5e3,
  /** Recommended max lines for SKILL.md */
  MAX_INSTRUCTION_LINES: 500,
  /** Max characters for name field */
  MAX_NAME_LENGTH: 64,
  /** Max characters for description field */
  MAX_DESCRIPTION_LENGTH: 1024};
function validateSkillName(name) {
  const errors = [];
  const fieldPath = "name";
  if (typeof name !== "string") {
    errors.push(`${fieldPath}: Expected string, received ${typeof name}`);
    return errors;
  }
  if (name.length === 0) {
    errors.push(`${fieldPath}: Skill name cannot be empty`);
    return errors;
  }
  if (name.length > SKILL_LIMITS.MAX_NAME_LENGTH) {
    errors.push(`${fieldPath}: Skill name must be ${SKILL_LIMITS.MAX_NAME_LENGTH} characters or less`);
  }
  if (!/^[a-z0-9-]+$/.test(name)) {
    errors.push(`${fieldPath}: Skill name must contain only lowercase letters, numbers, and hyphens`);
  }
  if (name.startsWith("-") || name.endsWith("-")) {
    errors.push(`${fieldPath}: Skill name must not start or end with a hyphen`);
  }
  if (name.includes("--")) {
    errors.push(`${fieldPath}: Skill name must not contain consecutive hyphens`);
  }
  return errors;
}
function validateSkillDescription(description) {
  const errors = [];
  const fieldPath = "description";
  if (typeof description !== "string") {
    errors.push(`${fieldPath}: Expected string, received ${typeof description}`);
    return errors;
  }
  if (description.length === 0) {
    errors.push(`${fieldPath}: Skill description cannot be empty`);
    return errors;
  }
  if (description.length > SKILL_LIMITS.MAX_DESCRIPTION_LENGTH) {
    errors.push(`${fieldPath}: Skill description must be ${SKILL_LIMITS.MAX_DESCRIPTION_LENGTH} characters or less`);
  }
  if (description.trim().length === 0) {
    errors.push(`${fieldPath}: Skill description cannot be only whitespace`);
  }
  return errors;
}
function validateSkillLicense(license) {
  const errors = [];
  const fieldPath = "license";
  if (license === void 0 || license === null) {
    return errors;
  }
  if (typeof license !== "string") {
    errors.push(`${fieldPath}: Expected string, received ${typeof license}`);
  }
  return errors;
}
function validateSkillCompatibility(_compatibility) {
  return [];
}
function validateSkillMetadataField(metadata) {
  const errors = [];
  const fieldPath = "metadata";
  if (metadata === void 0 || metadata === null) {
    return errors;
  }
  if (typeof metadata !== "object" || Array.isArray(metadata)) {
    errors.push(`${fieldPath}: Expected object, received ${Array.isArray(metadata) ? "array" : typeof metadata}`);
    return errors;
  }
  return errors;
}
function estimateTokens(text) {
  const words = text.split(/\s+/).filter(Boolean).length;
  return Math.ceil(words * 1.3);
}
function countLines(text) {
  return text.split("\n").length;
}
function validateSkillMetadata(metadata, dirName, instructions) {
  const errors = [];
  const warnings = [];
  if (typeof metadata !== "object" || metadata === null || Array.isArray(metadata)) {
    errors.push(
      `Expected object, received ${metadata === null ? "null" : Array.isArray(metadata) ? "array" : typeof metadata}`
    );
    return { valid: false, errors, warnings };
  }
  const data = metadata;
  errors.push(...validateSkillName(data.name));
  errors.push(...validateSkillDescription(data.description));
  errors.push(...validateSkillLicense(data.license));
  errors.push(...validateSkillCompatibility());
  errors.push(...validateSkillMetadataField(data.metadata));
  if (dirName && typeof data.name === "string" && data.name !== dirName) {
    errors.push(`Skill name "${data.name}" must match directory name "${dirName}"`);
  }
  if (instructions) {
    const lineCount = countLines(instructions);
    const tokenEstimate = estimateTokens(instructions);
    if (lineCount > SKILL_LIMITS.MAX_INSTRUCTION_LINES) {
      warnings.push(
        `Instructions have ${lineCount} lines (recommended: <${SKILL_LIMITS.MAX_INSTRUCTION_LINES}). Consider moving content to references/.`
      );
    }
    if (tokenEstimate > SKILL_LIMITS.MAX_INSTRUCTION_TOKENS) {
      warnings.push(
        `Instructions have ~${tokenEstimate} estimated tokens (recommended: <${SKILL_LIMITS.MAX_INSTRUCTION_TOKENS}). Consider moving content to references/.`
      );
    }
  }
  return {
    valid: errors.length === 0,
    errors,
    warnings
  };
}
var LocalSkillSource = class {
  #basePath;
  constructor(options = {}) {
    this.#basePath = options.basePath ?? process.cwd();
  }
  /**
   * Resolve a path relative to the base path.
   * Handles both absolute and relative paths.
   */
  #resolvePath(skillPath) {
    if (nodePath.isAbsolute(skillPath)) {
      return skillPath;
    }
    return nodePath.resolve(this.#basePath, skillPath);
  }
  async exists(skillPath) {
    return fsExists(this.#resolvePath(skillPath));
  }
  async stat(skillPath) {
    return fsStat(this.#resolvePath(skillPath), skillPath);
  }
  async readFile(skillPath) {
    const resolved = this.#resolvePath(skillPath);
    const content = await fs2.readFile(resolved);
    if (isTextFile(skillPath)) {
      return content.toString("utf-8");
    }
    return content;
  }
  async readdir(skillPath) {
    const resolved = this.#resolvePath(skillPath);
    const entries = await fs2.readdir(resolved, { withFileTypes: true });
    return entries.map((entry) => ({
      name: entry.name,
      type: entry.isDirectory() ? "directory" : "file",
      isSymlink: entry.isSymbolicLink() || void 0
    }));
  }
};

// src/workspace/skills/versioned-skill-source.ts
var VersionedSkillSource = class {
  #tree;
  #blobStore;
  #versionCreatedAt;
  /** Computed set of directory paths from the tree entries */
  #directories;
  constructor(tree, blobStore, versionCreatedAt) {
    this.#tree = tree;
    this.#blobStore = blobStore;
    this.#versionCreatedAt = versionCreatedAt;
    this.#directories = this.#computeDirectories();
  }
  /**
   * Compute all directory paths implied by the file tree.
   * For a file at "references/api.md", this adds "" (root), "references".
   */
  #computeDirectories() {
    const dirs = /* @__PURE__ */ new Set();
    dirs.add("");
    dirs.add(".");
    for (const filePath of Object.keys(this.#tree.entries)) {
      const parts = filePath.split("/");
      for (let i = 1; i < parts.length; i++) {
        dirs.add(parts.slice(0, i).join("/"));
      }
    }
    return dirs;
  }
  /**
   * Normalize a path by stripping leading/trailing slashes and dots.
   */
  #normalizePath(path6) {
    let normalized = path6.replace(/^[./\\]+|[/\\]+$/g, "");
    if (normalized === "") return "";
    return normalized;
  }
  async exists(path6) {
    const normalized = this.#normalizePath(path6);
    if (this.#tree.entries[normalized]) return true;
    return this.#directories.has(normalized);
  }
  async stat(path6) {
    const normalized = this.#normalizePath(path6);
    const name = normalized.split("/").pop() || normalized || ".";
    const entry = this.#tree.entries[normalized];
    if (entry) {
      return {
        name,
        type: "file",
        size: entry.size,
        createdAt: this.#versionCreatedAt,
        modifiedAt: this.#versionCreatedAt,
        mimeType: entry.mimeType
      };
    }
    if (this.#directories.has(normalized)) {
      return {
        name,
        type: "directory",
        size: 0,
        createdAt: this.#versionCreatedAt,
        modifiedAt: this.#versionCreatedAt
      };
    }
    throw new Error(`Path not found in skill version tree: ${path6}`);
  }
  async readFile(path6) {
    const normalized = this.#normalizePath(path6);
    const entry = this.#tree.entries[normalized];
    if (!entry) {
      throw new Error(`File not found in skill version tree: ${path6}`);
    }
    const blob = await this.#blobStore.get(entry.blobHash);
    if (!blob) {
      throw new Error(`Blob not found for hash ${entry.blobHash} (file: ${path6})`);
    }
    if (entry.encoding === "base64") {
      return Buffer.from(blob.content, "base64");
    }
    return blob.content;
  }
  async readdir(path6) {
    const normalized = this.#normalizePath(path6);
    if (!this.#directories.has(normalized)) {
      throw new Error(`Directory not found in skill version tree: ${path6}`);
    }
    const prefix = normalized === "" ? "" : normalized + "/";
    const seen = /* @__PURE__ */ new Set();
    const entries = [];
    for (const filePath of Object.keys(this.#tree.entries)) {
      if (!filePath.startsWith(prefix)) continue;
      const remaining = filePath.slice(prefix.length);
      const nextSegment = remaining.split("/")[0];
      if (!nextSegment || seen.has(nextSegment)) continue;
      seen.add(nextSegment);
      const isDirectory = remaining.includes("/");
      entries.push({
        name: nextSegment,
        type: isDirectory ? "directory" : "file"
      });
    }
    return entries;
  }
};

// src/workspace/skills/composite-versioned-skill-source.ts
var CompositeVersionedSkillSource = class {
  #sources = /* @__PURE__ */ new Map();
  #fallback;
  #fallbackSkills;
  constructor(entries, blobStore, options) {
    for (const entry of entries) {
      this.#sources.set(entry.dirName, new VersionedSkillSource(entry.tree, blobStore, entry.versionCreatedAt));
    }
    this.#fallback = options?.fallback;
    this.#fallbackSkills = new Set(options?.fallbackSkills ?? []);
  }
  #normalizePath(path6) {
    return path6.replace(/^[./\\]+|[/\\]+$/g, "");
  }
  /**
   * Route a path to the correct source.
   * Returns the source and the remaining path within that source.
   */
  #routePath(path6) {
    const normalized = this.#normalizePath(path6);
    if (normalized === "") return null;
    const segments = normalized.split("/");
    const skillDir = segments[0];
    const subPath = segments.slice(1).join("/");
    if (this.#fallbackSkills.has(skillDir) && this.#fallback) {
      return { source: this.#fallback, subPath: normalized };
    }
    const versionedSource = this.#sources.get(skillDir);
    if (versionedSource) {
      return { source: versionedSource, subPath };
    }
    if (this.#fallback) {
      return { source: this.#fallback, subPath: normalized };
    }
    return null;
  }
  async exists(path6) {
    const normalized = this.#normalizePath(path6);
    if (normalized === "") return true;
    const route = this.#routePath(path6);
    if (!route) return false;
    return route.source.exists(route.subPath);
  }
  async stat(path6) {
    const normalized = this.#normalizePath(path6);
    if (normalized === "") {
      return {
        name: ".",
        type: "directory",
        size: 0,
        createdAt: /* @__PURE__ */ new Date(),
        modifiedAt: /* @__PURE__ */ new Date()
      };
    }
    const route = this.#routePath(path6);
    if (!route) {
      throw new Error(`Path not found in composite skill source: ${path6}`);
    }
    return route.source.stat(route.subPath);
  }
  async readFile(path6) {
    const route = this.#routePath(path6);
    if (!route) {
      throw new Error(`File not found in composite skill source: ${path6}`);
    }
    return route.source.readFile(route.subPath);
  }
  async readdir(path6) {
    const normalized = this.#normalizePath(path6);
    if (normalized === "") {
      const entries = [];
      const seen = /* @__PURE__ */ new Set();
      for (const dirName of this.#sources.keys()) {
        entries.push({ name: dirName, type: "directory" });
        seen.add(dirName);
      }
      for (const dirName of this.#fallbackSkills) {
        if (!seen.has(dirName)) {
          entries.push({ name: dirName, type: "directory" });
          seen.add(dirName);
        }
      }
      return entries;
    }
    const route = this.#routePath(path6);
    if (!route) {
      throw new Error(`Directory not found in composite skill source: ${path6}`);
    }
    return route.source.readdir(route.subPath);
  }
};
var WorkspaceSkillsImpl = class _WorkspaceSkillsImpl {
  #source;
  #skillsResolver;
  #searchEngine;
  #validateOnLoad;
  /** Map of skill name -> full skill data */
  #skills = /* @__PURE__ */ new Map();
  /** Whether skills have been discovered */
  #initialized = false;
  /** Promise for ongoing initialization (prevents concurrent discovery) */
  #initPromise = null;
  /** Timestamp of last skills discovery (for staleness check) */
  #lastDiscoveryTime = 0;
  /** Currently resolved skills paths (used to detect changes) */
  #resolvedPaths = [];
  /** Cached glob-resolved directories and per-pattern resolve timestamps */
  #globDirCache = /* @__PURE__ */ new Map();
  #globResolveTimes = /* @__PURE__ */ new Map();
  static GLOB_RESOLVE_INTERVAL = 5e3;
  // Re-walk glob dirs every 5s
  static STALENESS_CHECK_COOLDOWN = 2e3;
  // Skip staleness check for 2s after discovery
  constructor(config) {
    this.#source = config.source;
    this.#skillsResolver = config.skills;
    this.#searchEngine = config.searchEngine;
    this.#validateOnLoad = config.validateOnLoad ?? true;
  }
  // ===========================================================================
  // Discovery
  // ===========================================================================
  async list() {
    await this.#ensureInitialized();
    return Array.from(this.#skills.values()).map((skill) => ({
      name: skill.name,
      description: skill.description,
      license: skill.license,
      compatibility: skill.compatibility,
      metadata: skill.metadata
    }));
  }
  async get(name) {
    await this.#ensureInitialized();
    const skill = this.#skills.get(name);
    if (!skill) return null;
    const { indexableContent: _, ...skillData } = skill;
    return skillData;
  }
  async has(name) {
    await this.#ensureInitialized();
    return this.#skills.has(name);
  }
  async refresh() {
    this.#skills.clear();
    this.#searchEngine?.clear();
    this.#initialized = false;
    this.#initPromise = null;
    await this.#discoverSkills();
    this.#initialized = true;
  }
  async maybeRefresh(context) {
    await this.#ensureInitialized();
    const currentPaths = await this.#resolvePaths(context);
    const pathsChanged = !this.#arePathsEqual(this.#resolvedPaths, currentPaths);
    if (pathsChanged) {
      this.#resolvedPaths = currentPaths;
      await this.refresh();
      return;
    }
    const isStale = await this.#isSkillsPathStale();
    if (isStale) {
      await this.refresh();
    }
  }
  async addSkill(skillPath) {
    await this.#ensureInitialized();
    let skillFilePath;
    let dirName;
    if (skillPath.endsWith("/SKILL.md") || skillPath === "SKILL.md") {
      skillFilePath = skillPath;
      dirName = this.#getParentPath(skillPath).split("/").pop() || "unknown";
    } else {
      skillFilePath = this.#joinPath(skillPath, "SKILL.md");
      dirName = skillPath.split("/").pop() || "unknown";
    }
    const source = this.#inferSource(skillPath);
    const skill = await this.#parseSkillFile(skillFilePath, dirName, source);
    const existing = this.#skills.get(skill.name);
    if (existing) {
      await this.#removeSkillFromIndex(existing);
    }
    this.#skills.set(skill.name, skill);
    await this.#indexSkill(skill);
    this.#lastDiscoveryTime = Date.now();
  }
  async removeSkill(skillName) {
    await this.#ensureInitialized();
    const skill = this.#skills.get(skillName);
    if (!skill) return;
    await this.#removeSkillFromIndex(skill);
    this.#skills.delete(skillName);
    this.#lastDiscoveryTime = Date.now();
  }
  /**
   * Resolve skills paths from the resolver (static array or function).
   */
  async #resolvePaths(context) {
    if (Array.isArray(this.#skillsResolver)) {
      return this.#skillsResolver;
    }
    return this.#skillsResolver(context ?? {});
  }
  /**
   * Compare two path arrays for equality (order-independent).
   */
  #arePathsEqual(a, b) {
    if (a.length !== b.length) return false;
    const sortedA = [...a].sort();
    const sortedB = [...b].sort();
    return sortedA.every((path6, i) => path6 === sortedB[i]);
  }
  // ===========================================================================
  // Search
  // ===========================================================================
  async search(query, options = {}) {
    await this.#ensureInitialized();
    if (!this.#searchEngine) {
      return this.#simpleSearch(query, options);
    }
    const { topK = 5, minScore, skillNames, includeReferences = true, mode } = options;
    const expandedTopK = skillNames ? topK * 3 : topK;
    const searchResults = await this.#searchEngine.search(query, {
      topK: expandedTopK,
      minScore,
      mode
    });
    const results = [];
    for (const result of searchResults) {
      const skillName = result.metadata?.skillName;
      const source = result.metadata?.source;
      if (!skillName || !source) continue;
      if (skillNames && !skillNames.includes(skillName)) {
        continue;
      }
      if (!includeReferences && source !== "SKILL.md") {
        continue;
      }
      results.push({
        skillName,
        source,
        content: result.content,
        score: result.score,
        lineRange: result.lineRange,
        scoreDetails: result.scoreDetails
      });
      if (results.length >= topK) break;
    }
    return results;
  }
  // ===========================================================================
  // Single-item Accessors
  // ===========================================================================
  async getReference(skillName, referencePath) {
    await this.#ensureInitialized();
    const skill = this.#skills.get(skillName);
    if (!skill) return null;
    const safeRefPath = this.#assertRelativePath(referencePath, "reference");
    const refFilePath = this.#joinPath(skill.path, safeRefPath);
    if (!await this.#source.exists(refFilePath)) {
      return null;
    }
    try {
      const content = await this.#source.readFile(refFilePath);
      return typeof content === "string" ? content : content.toString("utf-8");
    } catch {
      return null;
    }
  }
  async getScript(skillName, scriptPath) {
    await this.#ensureInitialized();
    const skill = this.#skills.get(skillName);
    if (!skill) return null;
    const safeScriptPath = this.#assertRelativePath(scriptPath, "script");
    const scriptFilePath = this.#joinPath(skill.path, safeScriptPath);
    if (!await this.#source.exists(scriptFilePath)) {
      return null;
    }
    try {
      const content = await this.#source.readFile(scriptFilePath);
      return typeof content === "string" ? content : content.toString("utf-8");
    } catch {
      return null;
    }
  }
  async getAsset(skillName, assetPath) {
    await this.#ensureInitialized();
    const skill = this.#skills.get(skillName);
    if (!skill) return null;
    const safeAssetPath = this.#assertRelativePath(assetPath, "asset");
    const assetFilePath = this.#joinPath(skill.path, safeAssetPath);
    if (!await this.#source.exists(assetFilePath)) {
      return null;
    }
    try {
      const content = await this.#source.readFile(assetFilePath);
      return typeof content === "string" ? Buffer.from(content, "utf-8") : content;
    } catch {
      return null;
    }
  }
  // ===========================================================================
  // Listing Accessors
  // ===========================================================================
  async listReferences(skillName) {
    await this.#ensureInitialized();
    const skill = this.#skills.get(skillName);
    return skill?.references ?? [];
  }
  async listScripts(skillName) {
    await this.#ensureInitialized();
    const skill = this.#skills.get(skillName);
    return skill?.scripts ?? [];
  }
  async listAssets(skillName) {
    await this.#ensureInitialized();
    const skill = this.#skills.get(skillName);
    return skill?.assets ?? [];
  }
  // ===========================================================================
  // Private Methods
  // ===========================================================================
  /**
   * Ensure skills have been discovered.
   * Uses a promise to prevent concurrent discovery.
   */
  async #ensureInitialized() {
    if (this.#initialized) {
      return;
    }
    if (this.#initPromise) {
      await this.#initPromise;
      return;
    }
    this.#initPromise = (async () => {
      try {
        if (this.#resolvedPaths.length === 0) {
          this.#resolvedPaths = await this.#resolvePaths();
        }
        await this.#discoverSkills();
        this.#initialized = true;
      } finally {
        this.#initPromise = null;
      }
    })();
    await this.#initPromise;
  }
  /**
   * Discover skills from all skills paths.
   * Uses currently resolved paths (must be set before calling).
   *
   * Paths can be plain directories (e.g., '/skills') or glob patterns
   * (e.g., '**\/skills'). Glob patterns resolve to directories that match
   * the pattern, each of which is then scanned for skills.
   */
  async #discoverSkills() {
    this.#globDirCache.clear();
    this.#globResolveTimes.clear();
    for (const skillsPath of this.#resolvedPaths) {
      const source = this.#determineSource(skillsPath);
      if (isGlobPattern(skillsPath)) {
        const matchingDirs = await this.#resolveGlobToDirectories(skillsPath);
        this.#globDirCache.set(skillsPath, matchingDirs);
        this.#globResolveTimes.set(skillsPath, Date.now());
        for (const dir of matchingDirs) {
          await this.#discoverSkillsInPath(dir, source);
        }
      } else {
        const isDirect = await this.#discoverDirectSkill(skillsPath, source);
        if (!isDirect) {
          await this.#discoverSkillsInPath(skillsPath, source);
        }
      }
    }
    this.#lastDiscoveryTime = Date.now();
  }
  /**
   * Resolve a glob pattern to a list of matching directories.
   * Walks from extractGlobBase() and tests each directory against the pattern.
   *
   * Note: Broad patterns like `/** /skills` resolve to a walk root of `/`,
   * scanning the entire workspace tree. This is cached per-pattern with a
   * TTL (GLOB_RESOLVE_INTERVAL) to limit I/O. For large workspaces, prefer
   * more specific patterns like `/src/** /skills` to narrow the walk root.
   */
  async #resolveGlobToDirectories(pattern) {
    const walkRoot = extractGlobBase(pattern);
    const matcher = createGlobMatcher(pattern, { dot: true });
    const matchingDirs = [];
    await this.#walkForDirectories(walkRoot, (dirPath) => {
      if (matcher(dirPath)) {
        matchingDirs.push(dirPath);
      }
    });
    return matchingDirs;
  }
  /**
   * Walk a directory tree and call callback for each directory found.
   */
  async #walkForDirectories(basePath, callback, depth = 0, maxDepth = 4) {
    if (depth >= maxDepth) return;
    try {
      const entries = await this.#source.readdir(basePath);
      for (const entry of entries) {
        if (entry.type !== "directory" || entry.isSymlink) continue;
        const entryPath = basePath === "/" ? `/${entry.name}` : `${basePath}/${entry.name}`;
        callback(entryPath);
        await this.#walkForDirectories(entryPath, callback, depth + 1, maxDepth);
      }
    } catch {
    }
  }
  /**
   * Discover skills in a single path
   */
  async #discoverSkillsInPath(skillsPath, source) {
    try {
      if (!await this.#source.exists(skillsPath)) {
        return;
      }
    } catch (error) {
      if (error instanceof Error) {
        console.warn(`[WorkspaceSkills] Cannot access skills path "${skillsPath}": ${error.message}`);
      } else {
        console.warn(`[WorkspaceSkills] Cannot access skills path "${skillsPath}": ${String(error)}`);
      }
      return;
    }
    try {
      const entries = await this.#source.readdir(skillsPath);
      for (const entry of entries) {
        if (entry.type !== "directory") continue;
        const entryPath = this.#joinPath(skillsPath, entry.name);
        const skillFilePath = this.#joinPath(entryPath, "SKILL.md");
        if (await this.#source.exists(skillFilePath)) {
          try {
            const skill = await this.#parseSkillFile(skillFilePath, entry.name, source);
            this.#skills.set(skill.name, skill);
            await this.#indexSkill(skill);
          } catch (error) {
            if (error instanceof Error) {
              console.error(`[WorkspaceSkills] Failed to load skill from ${skillFilePath}:`, error.message);
            }
          }
        }
      }
    } catch (error) {
      if (error instanceof Error) {
        console.error(`[WorkspaceSkills] Failed to scan skills directory ${skillsPath}:`, error.message);
      }
    }
  }
  /**
   * Attempt to discover a skill from a direct path reference.
   *
   * Handles two cases:
   * - Path ends with `/SKILL.md` â†’ parse directly, extract dirName from parent
   * - Path is a directory containing `SKILL.md` â†’ parse it as a single skill
   *
   * Returns `true` if the path was a direct skill reference (skip subdirectory scan),
   * `false` to fall through to the normal subdirectory scan.
   */
  async #discoverDirectSkill(skillsPath, source) {
    try {
      if (skillsPath.endsWith("/SKILL.md") || skillsPath === "SKILL.md") {
        if (!await this.#source.exists(skillsPath)) {
          return true;
        }
        const skillDir = this.#getParentPath(skillsPath);
        const dirName = skillDir.split("/").pop() || skillDir;
        try {
          const skill = await this.#parseSkillFile(skillsPath, dirName, source);
          this.#skills.set(skill.name, skill);
          await this.#indexSkill(skill);
        } catch (error) {
          if (error instanceof Error) {
            console.error(`[WorkspaceSkills] Failed to load skill from ${skillsPath}:`, error.message);
          }
        }
        return true;
      }
      if (await this.#source.exists(skillsPath)) {
        const skillFilePath = this.#joinPath(skillsPath, "SKILL.md");
        if (await this.#source.exists(skillFilePath)) {
          const dirName = skillsPath.split("/").pop() || skillsPath;
          try {
            const skill = await this.#parseSkillFile(skillFilePath, dirName, source);
            this.#skills.set(skill.name, skill);
            await this.#indexSkill(skill);
          } catch (error) {
            if (error instanceof Error) {
              console.error(`[WorkspaceSkills] Failed to load skill from ${skillFilePath}:`, error.message);
            }
          }
          return true;
        }
      }
      return false;
    } catch {
      return false;
    }
  }
  /**
   * Check if any skills path directory has been modified since last discovery.
   * Compares directory mtime to lastDiscoveryTime.
   * For glob patterns, checks the walk root and expanded directories.
   */
  async #isSkillsPathStale() {
    if (this.#lastDiscoveryTime === 0) {
      return true;
    }
    if (Date.now() - this.#lastDiscoveryTime < _WorkspaceSkillsImpl.STALENESS_CHECK_COOLDOWN) {
      return false;
    }
    for (const skillsPath of this.#resolvedPaths) {
      let pathsToCheck;
      if (isGlobPattern(skillsPath)) {
        const now = Date.now();
        const lastResolved = this.#globResolveTimes.get(skillsPath) ?? 0;
        if (now - lastResolved > _WorkspaceSkillsImpl.GLOB_RESOLVE_INTERVAL || !this.#globDirCache.has(skillsPath)) {
          const dirs = await this.#resolveGlobToDirectories(skillsPath);
          this.#globDirCache.set(skillsPath, dirs);
          this.#globResolveTimes.set(skillsPath, now);
        }
        pathsToCheck = this.#globDirCache.get(skillsPath) ?? [];
      } else {
        pathsToCheck = [skillsPath];
      }
      for (const pathToCheck of pathsToCheck) {
        try {
          const stat3 = await this.#source.stat(pathToCheck);
          const mtime = stat3.modifiedAt.getTime();
          if (mtime > this.#lastDiscoveryTime) {
            return true;
          }
          if (stat3.type !== "directory") {
            continue;
          }
          const entries = await this.#source.readdir(pathToCheck);
          for (const entry of entries) {
            if (entry.type !== "directory") continue;
            const entryPath = this.#joinPath(pathToCheck, entry.name);
            try {
              const entryStat = await this.#source.stat(entryPath);
              if (entryStat.modifiedAt.getTime() > this.#lastDiscoveryTime) {
                return true;
              }
            } catch {
            }
          }
        } catch {
          continue;
        }
      }
    }
    return false;
  }
  /**
   * Parse a SKILL.md file
   */
  async #parseSkillFile(filePath, dirName, source) {
    const rawContent = await this.#source.readFile(filePath);
    const content = typeof rawContent === "string" ? rawContent : rawContent.toString("utf-8");
    const parsed = matter(content);
    const frontmatter = parsed.data;
    const body = parsed.content.trim();
    const metadata = {
      name: frontmatter.name,
      description: frontmatter.description,
      license: frontmatter.license,
      compatibility: frontmatter.compatibility,
      metadata: frontmatter.metadata
    };
    if (this.#validateOnLoad) {
      const validation = this.#validateSkillMetadata(metadata, dirName, body);
      if (!validation.valid) {
        throw new Error(`Invalid skill metadata in ${filePath}:
${validation.errors.join("\n")}`);
      }
    }
    const skillPath = this.#getParentPath(filePath);
    const references = await this.#discoverFilesInSubdir(skillPath, "references");
    const scripts = await this.#discoverFilesInSubdir(skillPath, "scripts");
    const assets = await this.#discoverFilesInSubdir(skillPath, "assets");
    const indexableContent = await this.#buildIndexableContent(body, skillPath, references);
    return {
      ...metadata,
      path: skillPath,
      instructions: body,
      source,
      references,
      scripts,
      assets,
      indexableContent
    };
  }
  /**
   * Validate skill metadata (delegates to shared validation function)
   */
  #validateSkillMetadata(metadata, dirName, instructions) {
    const result = validateSkillMetadata(metadata, dirName, instructions);
    if (result.warnings.length > 0) {
      for (const warning of result.warnings) {
        console.warn(`[WorkspaceSkills] ${metadata.name}: ${warning}`);
      }
    }
    return result;
  }
  /**
   * Discover files in a subdirectory of a skill (references/, scripts/, assets/)
   */
  async #discoverFilesInSubdir(skillPath, subdir) {
    const subdirPath = this.#joinPath(skillPath, subdir);
    const files = [];
    if (!await this.#source.exists(subdirPath)) {
      return files;
    }
    try {
      await this.#walkDirectory(subdirPath, subdirPath, (relativePath) => {
        files.push(relativePath);
      });
    } catch {
    }
    return files;
  }
  /**
   * Walk a directory recursively and call callback for each file.
   * Limited to maxDepth (default 20) to prevent stack overflow on deep hierarchies.
   */
  async #walkDirectory(basePath, dirPath, callback, depth = 0, maxDepth = 20) {
    if (depth >= maxDepth) {
      return;
    }
    const entries = await this.#source.readdir(dirPath);
    for (const entry of entries) {
      const entryPath = this.#joinPath(dirPath, entry.name);
      if (entry.type === "directory" && !entry.isSymlink) {
        await this.#walkDirectory(basePath, entryPath, callback, depth + 1, maxDepth);
      } else {
        const relativePath = entryPath.substring(basePath.length + 1);
        callback(relativePath);
      }
    }
  }
  /**
   * Build indexable content from instructions and references
   */
  async #buildIndexableContent(instructions, skillPath, references) {
    const parts = [instructions];
    for (const refPath of references) {
      const fullPath = this.#joinPath(skillPath, "references", refPath);
      try {
        const rawContent = await this.#source.readFile(fullPath);
        const content = typeof rawContent === "string" ? rawContent : rawContent.toString("utf-8");
        parts.push(content);
      } catch {
      }
    }
    return parts.join("\n\n");
  }
  /**
   * Remove a skill's entries from the search index.
   */
  async #removeSkillFromIndex(skill) {
    if (!this.#searchEngine?.remove) return;
    const ids = [`skill:${skill.name}:SKILL.md`, ...skill.references.map((r) => `skill:${skill.name}:${r}`)];
    for (const id of ids) {
      try {
        await this.#searchEngine.remove(id);
      } catch {
      }
    }
  }
  /**
   * Infer the ContentSource for a skill path by matching against resolved paths.
   */
  #inferSource(skillPath) {
    for (const rp of this.#resolvedPaths) {
      if (skillPath === rp || skillPath.startsWith(rp + "/")) {
        return this.#determineSource(rp);
      }
    }
    return this.#determineSource(skillPath);
  }
  /**
   * Index a skill for search
   */
  async #indexSkill(skill) {
    if (!this.#searchEngine) return;
    await this.#searchEngine.index({
      id: `skill:${skill.name}:SKILL.md`,
      content: skill.instructions,
      metadata: {
        skillName: skill.name,
        source: "SKILL.md"
      }
    });
    for (const refPath of skill.references) {
      const fullPath = this.#joinPath(skill.path, "references", refPath);
      try {
        const rawContent = await this.#source.readFile(fullPath);
        const content = typeof rawContent === "string" ? rawContent : rawContent.toString("utf-8");
        await this.#searchEngine.index({
          id: `skill:${skill.name}:${refPath}`,
          content,
          metadata: {
            skillName: skill.name,
            source: `references/${refPath}`
          }
        });
      } catch {
      }
    }
  }
  /**
   * Simple text search fallback when no search engine is configured
   */
  async #simpleSearch(query, options) {
    const { topK = 5, skillNames, includeReferences = true } = options;
    const queryLower = query.toLowerCase();
    const results = [];
    for (const skill of this.#skills.values()) {
      if (skillNames && !skillNames.includes(skill.name)) {
        continue;
      }
      if (skill.instructions.toLowerCase().includes(queryLower)) {
        results.push({
          skillName: skill.name,
          source: "SKILL.md",
          content: skill.instructions.substring(0, 200),
          score: 1
        });
      }
      if (includeReferences) {
        for (const refPath of skill.references) {
          if (results.length >= topK) break;
          const content = await this.getReference(skill.name, `references/${refPath}`);
          if (content && content.toLowerCase().includes(queryLower)) {
            results.push({
              skillName: skill.name,
              source: `references/${refPath}`,
              content: content.substring(0, 200),
              score: 0.8
            });
          }
        }
      }
      if (results.length >= topK) break;
    }
    return results.slice(0, topK);
  }
  /**
   * Determine the source type based on the path
   */
  #determineSource(skillsPath) {
    const segments = skillsPath.split("/");
    if (segments.includes("node_modules")) {
      return { type: "external", packagePath: skillsPath };
    }
    if (skillsPath.includes("/.mastra/skills") || skillsPath.startsWith(".mastra/skills")) {
      return { type: "managed", mastraPath: skillsPath };
    }
    return { type: "local", projectPath: skillsPath };
  }
  /**
   * Join path segments (workspace paths use forward slashes)
   */
  #joinPath(...segments) {
    return segments.map((seg, i) => {
      if (i === 0) return seg.replace(/\/+$/, "");
      return seg.replace(/^\/+|\/+$/g, "");
    }).filter(Boolean).join("/");
  }
  /**
   * Validate and normalize a relative path to prevent directory traversal.
   * Throws if the path contains traversal segments (..) or is absolute.
   */
  #assertRelativePath(input, label) {
    const normalized = input.replace(/\\/g, "/");
    const segments = normalized.split("/").filter((seg) => Boolean(seg) && seg !== ".");
    if (normalized.startsWith("/") || segments.some((seg) => seg === "..")) {
      throw new Error(`Invalid ${label} path: ${input}`);
    }
    return segments.join("/");
  }
  /**
   * Get parent path
   */
  #getParentPath(path6) {
    const lastSlash = path6.lastIndexOf("/");
    return lastSlash > 0 ? path6.substring(0, lastSlash) : "/";
  }
};
function hashContent(content) {
  if (Buffer.isBuffer(content)) {
    return createHash("sha256").update(content).digest("hex");
  }
  return createHash("sha256").update(content, "utf-8").digest("hex");
}
function detectMimeType(filename) {
  const ext = filename.slice(filename.lastIndexOf(".")).toLowerCase();
  const mimeTypes = {
    ".md": "text/markdown",
    ".txt": "text/plain",
    ".json": "application/json",
    ".yaml": "text/yaml",
    ".yml": "text/yaml",
    ".sh": "text/x-shellscript",
    ".py": "text/x-python",
    ".js": "text/javascript",
    ".ts": "text/typescript",
    ".html": "text/html",
    ".css": "text/css",
    ".png": "image/png",
    ".jpg": "image/jpeg",
    ".jpeg": "image/jpeg",
    ".svg": "image/svg+xml"
  };
  return mimeTypes[ext];
}
function isBinaryMimeType(mimeType) {
  if (!mimeType) return false;
  if (mimeType.startsWith("text/")) return false;
  if (mimeType === "application/json") return false;
  if (mimeType === "image/svg+xml") return false;
  return true;
}
async function walkSkillDirectory(source, basePath, currentPath = basePath) {
  const entries = await source.readdir(currentPath);
  const files = [];
  for (const entry of entries) {
    const entryPath = joinPath(currentPath, entry.name);
    if (entry.type === "directory") {
      const subFiles = await walkSkillDirectory(source, basePath, entryPath);
      files.push(...subFiles);
    } else {
      const rawContent = await source.readFile(entryPath);
      const relativePath = entryPath.substring(basePath.length + 1);
      const mimeType = detectMimeType(entry.name);
      const isBinary = isBinaryMimeType(mimeType);
      if (isBinary) {
        const buf = Buffer.isBuffer(rawContent) ? rawContent : Buffer.from(rawContent, "utf-8");
        files.push({ path: relativePath, content: buf, isBinary: true });
      } else {
        const content = typeof rawContent === "string" ? rawContent : rawContent.toString("utf-8");
        files.push({ path: relativePath, content, isBinary: false });
      }
    }
  }
  return files;
}
function joinPath(...segments) {
  return segments.map((seg, i) => {
    if (i === 0) return seg.replace(/\/+$/, "");
    return seg.replace(/^\/+|\/+$/g, "");
  }).filter(Boolean).join("/");
}
function collectSubdirPaths(allPaths, subdir) {
  const prefix = subdir + "/";
  return allPaths.filter((p) => p.startsWith(prefix)).map((p) => p.substring(prefix.length));
}
async function collectSkillForPublish(source, skillPath) {
  const files = await walkSkillDirectory(source, skillPath);
  const treeEntries = {};
  const blobMap = /* @__PURE__ */ new Map();
  const now = /* @__PURE__ */ new Date();
  for (const file of files) {
    const hash = hashContent(file.content);
    const mimeType = detectMimeType(file.path);
    if (file.isBinary) {
      const buf = Buffer.isBuffer(file.content) ? file.content : Buffer.from(file.content);
      const size = buf.length;
      const base64Content = buf.toString("base64");
      treeEntries[file.path] = {
        blobHash: hash,
        size,
        mimeType,
        encoding: "base64"
      };
      if (!blobMap.has(hash)) {
        blobMap.set(hash, {
          hash,
          content: base64Content,
          size,
          mimeType,
          createdAt: now
        });
      }
    } else {
      const content = file.content;
      const size = Buffer.byteLength(content, "utf-8");
      treeEntries[file.path] = {
        blobHash: hash,
        size,
        mimeType
      };
      if (!blobMap.has(hash)) {
        blobMap.set(hash, {
          hash,
          content,
          size,
          mimeType,
          createdAt: now
        });
      }
    }
  }
  const tree = { entries: treeEntries };
  const blobs = Array.from(blobMap.values());
  const skillMdFile = files.find((f) => f.path === "SKILL.md");
  if (!skillMdFile) {
    throw new Error(`SKILL.md not found in ${skillPath}`);
  }
  const parsed = matter(skillMdFile.content);
  const frontmatter = parsed.data;
  const instructions = parsed.content.trim();
  const allPaths = files.map((f) => f.path);
  const references = collectSubdirPaths(allPaths, "references");
  const scripts = collectSubdirPaths(allPaths, "scripts");
  const assets = collectSubdirPaths(allPaths, "assets");
  const snapshot = {
    name: frontmatter.name,
    description: frontmatter.description,
    instructions,
    license: frontmatter.license,
    compatibility: frontmatter.compatibility,
    metadata: frontmatter.metadata,
    ...references.length > 0 ? { references } : {},
    ...scripts.length > 0 ? { scripts } : {},
    ...assets.length > 0 ? { assets } : {}
  };
  return { snapshot, tree, blobs };
}
async function publishSkillFromSource(source, skillPath, blobStore) {
  const result = await collectSkillForPublish(source, skillPath);
  await blobStore.putMany(result.blobs);
  return result;
}

// src/workspace/workspace.ts
var Workspace = class {
  id;
  name;
  createdAt;
  lastAccessedAt;
  _status = "pending";
  _fs;
  _sandbox;
  _config;
  _searchEngine;
  _skills;
  _lsp;
  constructor(config) {
    this.id = config.id ?? this.generateId();
    this.name = config.name ?? `workspace-${this.id.slice(0, 8)}`;
    this.createdAt = /* @__PURE__ */ new Date();
    this.lastAccessedAt = /* @__PURE__ */ new Date();
    this._config = config;
    this._sandbox = config.sandbox;
    if (config.mounts && Object.keys(config.mounts).length > 0) {
      if (config.filesystem) {
        throw new WorkspaceError('Cannot use both "filesystem" and "mounts"', "INVALID_CONFIG");
      }
      this._fs = new CompositeFilesystem({ mounts: config.mounts });
      if (this._sandbox?.mounts) {
        this._sandbox.mounts.setContext({ sandbox: this._sandbox, workspace: this });
        this._sandbox.mounts.add(config.mounts);
        if (config.onMount) {
          this._sandbox.mounts.setOnMount(config.onMount);
        }
      }
    } else {
      this._fs = config.filesystem;
    }
    if (config.vectorStore && !config.embedder) {
      throw new WorkspaceError("vectorStore requires an embedder", "INVALID_SEARCH_CONFIG");
    }
    if (config.bm25 || config.vectorStore && config.embedder) {
      const buildIndexName = () => {
        const defaultName = `${this.id}_search`.replace(/[^a-zA-Z0-9_]/g, "_");
        const indexName = config.searchIndexName ?? defaultName;
        if (!/^[a-zA-Z_][a-zA-Z0-9_]*$/.test(indexName)) {
          throw new WorkspaceError(
            `Invalid searchIndexName: "${indexName}". Must start with a letter or underscore, and contain only letters, numbers, or underscores.`,
            "INVALID_SEARCH_CONFIG",
            this.id
          );
        }
        if (indexName.length > 63) {
          throw new WorkspaceError(
            `searchIndexName exceeds 63 characters (got ${indexName.length})`,
            "INVALID_SEARCH_CONFIG",
            this.id
          );
        }
        return indexName;
      };
      this._searchEngine = new SearchEngine({
        bm25: config.bm25 ? {
          bm25: typeof config.bm25 === "object" ? config.bm25 : void 0
        } : void 0,
        vector: config.vectorStore && config.embedder ? {
          vectorStore: config.vectorStore,
          embedder: config.embedder,
          indexName: buildIndexName()
        } : void 0
      });
    }
    if (config.lsp) {
      const processes = this._sandbox?.processes;
      if (!this._sandbox) {
        console.warn(
          `[Workspace "${this.name}"] lsp: true requires a sandbox with a process manager. No sandbox configured \u2014 LSP disabled.`
        );
      } else if (!processes) {
        console.warn(
          `[Workspace "${this.name}"] lsp: true requires a sandbox with a process manager. Sandbox "${this._sandbox.name ?? "unknown"}" does not provide one \u2014 LSP disabled.`
        );
      } else if (!isLSPAvailable()) {
        console.warn(
          `[Workspace "${this.name}"] lsp: true requires vscode-jsonrpc and vscode-languageserver-protocol packages. Install them to enable LSP diagnostics.`
        );
      } else {
        const lspConfig = config.lsp === true ? {} : config.lsp;
        const defaultRoot = lspConfig.root ?? findProjectRoot(process.cwd()) ?? process.cwd();
        this._lsp = new LSPManager(processes, defaultRoot, lspConfig, this._fs);
      }
    }
    if (!this._fs && !this._sandbox && !this.hasSkillsConfig()) {
      throw new WorkspaceError("Workspace requires at least a filesystem, sandbox, or skills", "NO_PROVIDERS");
    }
  }
  generateId() {
    return `ws-${Date.now().toString(36)}-${Math.random().toString(36).slice(2, 8)}`;
  }
  hasSkillsConfig() {
    return this._config.skills !== void 0 && (typeof this._config.skills === "function" || this._config.skills.length > 0);
  }
  get status() {
    return this._status;
  }
  /**
   * The filesystem provider (if configured).
   *
   * Returns the concrete type you passed to the constructor.
   * When `mounts` is used instead of `filesystem`, returns `CompositeFilesystem`
   * parameterized with the concrete mount types.
   */
  get filesystem() {
    return this._fs;
  }
  /**
   * The sandbox provider (if configured).
   *
   * Returns the concrete type you passed to the constructor.
   */
  get sandbox() {
    return this._sandbox;
  }
  /**
   * Get the per-tool configuration for this workspace.
   * Returns undefined if no tools config was provided.
   */
  getToolsConfig() {
    return this._config.tools;
  }
  /**
   * The LSP manager (if configured, initialized, and a process manager is available).
   * Returns undefined if LSP is not configured, deps are missing, or sandbox has no process manager.
   */
  get lsp() {
    return this._lsp;
  }
  /**
   * Update the per-tool configuration for this workspace.
   * Takes effect on the next `createWorkspaceTools()` call.
   *
   * @example
   * ```typescript
   * // Disable write tools for read-only mode
   * workspace.setToolsConfig({
   *   mastra_workspace_write_file: { enabled: false },
   *   mastra_workspace_edit_file: { enabled: false },
   * });
   *
   * // Re-enable all tools
   * workspace.setToolsConfig(undefined);
   * ```
   */
  setToolsConfig(config) {
    this._config.tools = config;
  }
  /**
   * Access skills stored in this workspace.
   * Skills are SKILL.md files discovered from the configured skillPaths.
   *
   * Returns undefined if no skillPaths are configured.
   *
   * @example
   * ```typescript
   * const skills = await workspace.skills?.list();
   * const skill = await workspace.skills?.get('brand-guidelines');
   * const results = await workspace.skills?.search('brand colors');
   * ```
   */
  get skills() {
    if (!this.hasSkillsConfig()) {
      return void 0;
    }
    if (!this._skills) {
      const source = this._config.skillSource ?? this._fs ?? new LocalSkillSource();
      this._skills = new WorkspaceSkillsImpl({
        source,
        skills: this._config.skills,
        searchEngine: this._searchEngine,
        validateOnLoad: true
      });
    }
    return this._skills;
  }
  // ---------------------------------------------------------------------------
  // Search Capabilities
  // ---------------------------------------------------------------------------
  /**
   * Check if BM25 keyword search is available.
   */
  get canBM25() {
    return this._searchEngine?.canBM25 ?? false;
  }
  /**
   * Check if vector semantic search is available.
   */
  get canVector() {
    return this._searchEngine?.canVector ?? false;
  }
  /**
   * Check if hybrid search is available.
   */
  get canHybrid() {
    return this._searchEngine?.canHybrid ?? false;
  }
  // ---------------------------------------------------------------------------
  // Search Operations
  // ---------------------------------------------------------------------------
  /**
   * Index content for search.
   * The path becomes the document ID in search results.
   *
   * @param path - File path (used as document ID)
   * @param content - Text content to index
   * @param options - Index options (metadata, type hints)
   * @throws {SearchNotAvailableError} if search is not configured
   */
  async index(path6, content, options) {
    if (!this._searchEngine) {
      throw new SearchNotAvailableError();
    }
    this.lastAccessedAt = /* @__PURE__ */ new Date();
    const doc = {
      id: path6,
      content,
      metadata: {
        type: options?.type,
        mimeType: options?.mimeType,
        ...options?.metadata
      },
      startLineOffset: options?.startLineOffset
    };
    await this._searchEngine.index(doc);
  }
  /**
   * Search indexed content.
   *
   * @param query - Search query string
   * @param options - Search options (topK, mode, filters)
   * @returns Array of search results
   * @throws {SearchNotAvailableError} if search is not configured
   */
  async search(query, options) {
    if (!this._searchEngine) {
      throw new SearchNotAvailableError();
    }
    this.lastAccessedAt = /* @__PURE__ */ new Date();
    return this._searchEngine.search(query, options);
  }
  /**
   * Rebuild the search index from filesystem paths.
   * Used internally for auto-indexing on init.
   *
   * Paths can be plain directories (e.g., '/docs') or glob patterns
   * (e.g., '/docs/**\/*.md'). Glob patterns are resolved to a walk root
   * via extractGlobBase, then files are filtered by the pattern.
   */
  async rebuildSearchIndex(paths) {
    if (!this._searchEngine || !this._fs || paths.length === 0) {
      return;
    }
    this._searchEngine.clear();
    for (const pathOrGlob of paths) {
      try {
        if (isGlobPattern(pathOrGlob)) {
          const walkRoot = extractGlobBase(pathOrGlob);
          const matcher = createGlobMatcher(pathOrGlob);
          const files = await this.getAllFiles(walkRoot);
          for (const filePath of files) {
            if (!matcher(filePath)) continue;
            await this.indexFileForSearch(filePath);
          }
        } else {
          const files = await this.getAllFiles(pathOrGlob);
          for (const filePath of files) {
            await this.indexFileForSearch(filePath);
          }
        }
      } catch {
      }
    }
  }
  /**
   * Index a single file for search. Skips files that can't be read as text.
   */
  async indexFileForSearch(filePath) {
    try {
      const content = await this._fs.readFile(filePath, { encoding: "utf-8" });
      await this._searchEngine.index({
        id: filePath,
        content
      });
    } catch {
    }
  }
  async getAllFiles(dir, depth = 0, maxDepth = 10) {
    if (!this._fs || depth >= maxDepth) return [];
    const files = [];
    const entries = await this._fs.readdir(dir);
    for (const entry of entries) {
      const fullPath = dir === "/" ? `/${entry.name}` : `${dir}/${entry.name}`;
      if (entry.type === "file") {
        files.push(fullPath);
      } else if (entry.type === "directory" && !entry.isSymlink) {
        files.push(...await this.getAllFiles(fullPath, depth + 1, maxDepth));
      }
    }
    return files;
  }
  // ---------------------------------------------------------------------------
  // Lifecycle
  // ---------------------------------------------------------------------------
  /**
   * Initialize the workspace.
   * Starts the sandbox, initializes the filesystem, and auto-mounts filesystems.
   */
  async init() {
    this._status = "initializing";
    try {
      if (this._fs) {
        await callLifecycle(this._fs, "init");
      }
      if (this._sandbox) {
        await callLifecycle(this._sandbox, "start");
      }
      if (this._searchEngine && this._config.autoIndexPaths && this._config.autoIndexPaths.length > 0) {
        await this.rebuildSearchIndex(this._config.autoIndexPaths ?? []);
      }
      this._status = "ready";
    } catch (error) {
      this._status = "error";
      throw error;
    }
  }
  /**
   * Destroy the workspace and clean up all resources.
   */
  async destroy() {
    this._status = "destroying";
    try {
      if (this._lsp) {
        try {
          await this._lsp.shutdownAll();
        } catch {
        }
        this._lsp = void 0;
      }
      if (this._sandbox) {
        await callLifecycle(this._sandbox, "destroy");
      }
      if (this._fs) {
        await callLifecycle(this._fs, "destroy");
      }
      this._status = "destroyed";
    } catch (error) {
      this._status = "error";
      throw error;
    }
  }
  /**
   * Get workspace information.
   * @param options.includeFileCount - Whether to count total files (can be slow for large workspaces)
   */
  async getInfo(options) {
    const info = {
      id: this.id,
      name: this.name,
      status: this._status,
      createdAt: this.createdAt,
      lastAccessedAt: this.lastAccessedAt
    };
    if (this._fs) {
      const fsInfo = await this._fs.getInfo?.();
      info.filesystem = {
        id: fsInfo?.id ?? this._fs.id,
        name: fsInfo?.name ?? this._fs.name,
        provider: fsInfo?.provider ?? this._fs.provider,
        readOnly: fsInfo?.readOnly ?? this._fs.readOnly,
        status: fsInfo?.status,
        error: fsInfo?.error,
        icon: fsInfo?.icon,
        metadata: fsInfo?.metadata
      };
      if (options?.includeFileCount) {
        try {
          const files = await this.getAllFiles("/");
          info.filesystem.totalFiles = files.length;
        } catch {
        }
      }
    }
    if (this._sandbox) {
      const sandboxInfo = await this._sandbox.getInfo?.();
      info.sandbox = {
        provider: this._sandbox.provider,
        status: sandboxInfo?.status ?? this._sandbox.status,
        resources: sandboxInfo?.resources
      };
    }
    return info;
  }
  /**
   * Get human-readable instructions describing the workspace environment.
   *
   * When both a sandbox with mounts and a filesystem exist, each mount path
   * is classified as sandbox-accessible (state === 'mounted') or
   * workspace-only (pending / mounting / error / unsupported). When there's
   * no sandbox or no mounts, falls back to provider-level instructions.
   *
   * @param opts - Optional options including request context for per-request customisation
   * @returns Combined instructions string (may be empty)
   */
  getInstructions(opts) {
    const parts = [];
    const sandboxInstructions = this._sandbox?.getInstructions?.(opts);
    if (sandboxInstructions) parts.push(sandboxInstructions);
    const mountEntries = this._sandbox?.mounts?.entries;
    if (mountEntries && mountEntries.size > 0) {
      const sandboxAccessible = [];
      const workspaceOnly = [];
      for (const [mountPath, entry] of mountEntries) {
        const fsName = entry.filesystem.displayName || entry.filesystem.provider;
        const access2 = entry.filesystem.readOnly ? "read-only" : "read-write";
        if (entry.state === "mounted") {
          sandboxAccessible.push(`  - ${mountPath}: ${fsName} (${access2})`);
        } else {
          workspaceOnly.push(`  - ${mountPath}: ${fsName} (${access2})`);
        }
      }
      if (sandboxAccessible.length) {
        parts.push(`Sandbox-mounted filesystems (accessible in shell commands):
${sandboxAccessible.join("\n")}`);
      }
      if (workspaceOnly.length) {
        parts.push(
          `Workspace-only filesystems (use file tools, NOT available in shell commands):
${workspaceOnly.join("\n")}`
        );
      }
    } else {
      const fsInstructions = this._fs?.getInstructions?.(opts);
      if (fsInstructions) parts.push(fsInstructions);
    }
    return parts.join("\n\n");
  }
  /**
   * Get information about how filesystem and sandbox paths relate.
   * Useful for understanding how to access workspace files from sandbox code.
   *
   * @deprecated Use {@link getInstructions} instead. `getInstructions()` is
   * mount-state-aware and feeds into the system message via
   * `WorkspaceInstructionsProcessor`.
   *
   * @returns PathContext with paths and instructions from providers
   */
  getPathContext() {
    const fsInstructions = this._fs?.getInstructions?.();
    const sandboxInstructions = this._sandbox?.getInstructions?.();
    const instructions = [fsInstructions, sandboxInstructions].filter(Boolean).join(" ");
    return {
      filesystem: this._fs ? {
        provider: this._fs.provider,
        basePath: this._fs.basePath
      } : void 0,
      sandbox: this._sandbox ? {
        provider: this._sandbox.provider,
        workingDirectory: this._sandbox.workingDirectory
      } : void 0,
      instructions
    };
  }
  // ---------------------------------------------------------------------------
  // Logger Integration
  // ---------------------------------------------------------------------------
  /**
   * Set the logger for this workspace and propagate to providers.
   * Called by Mastra when the logger is set.
   * @internal
   */
  __setLogger(logger) {
    if (this._fs instanceof MastraFilesystem) {
      this._fs.__setLogger(logger);
    }
    if (this._sandbox instanceof MastraSandbox) {
      this._sandbox.__setLogger(logger);
    }
  }
};
var ProcessHandle = class {
  /** The command that was spawned (set by the process manager) */
  command;
  /**
   * Wait for the process to finish and return the result.
   *
   * Optionally pass `onStdout`/`onStderr` callbacks to stream output chunks
   * while waiting. The callbacks are automatically removed when `wait()`
   * resolves, so there's no cleanup needed by the caller.
   *
   * Subclasses implement `wait()` with platform-specific logic â€” the base
   * constructor wraps it to handle the optional streaming callbacks.
   */
  async wait(_options) {
    throw new Error(`${this.constructor.name} must implement wait()`);
  }
  _stdout = "";
  _stderr = "";
  _stdoutListeners = /* @__PURE__ */ new Set();
  _stderrListeners = /* @__PURE__ */ new Set();
  _reader;
  _writer;
  constructor(options) {
    if (options?.onStdout) this._stdoutListeners.add(options.onStdout);
    if (options?.onStderr) this._stderrListeners.add(options.onStderr);
    const implWait = this.wait.bind(this);
    this.wait = async (waitOptions) => {
      if (waitOptions?.onStdout) this._stdoutListeners.add(waitOptions.onStdout);
      if (waitOptions?.onStderr) this._stderrListeners.add(waitOptions.onStderr);
      try {
        return await implWait();
      } finally {
        if (waitOptions?.onStdout) this._stdoutListeners.delete(waitOptions.onStdout);
        if (waitOptions?.onStderr) this._stderrListeners.delete(waitOptions.onStderr);
      }
    };
  }
  /** Accumulated stdout so far */
  get stdout() {
    return this._stdout;
  }
  /** Accumulated stderr so far */
  get stderr() {
    return this._stderr;
  }
  /**
   * Emit stdout data â€” accumulates, dispatches to user callback, and pushes to reader stream.
   * @internal Called by subclasses and process managers to dispatch transport data.
   */
  emitStdout(data) {
    this._stdout += data;
    for (const listener of this._stdoutListeners) listener(data);
    this._reader?.push(data);
  }
  /**
   * Emit stderr data â€” accumulates and dispatches to user callback.
   * @internal Called by subclasses and process managers to dispatch transport data.
   */
  emitStderr(data) {
    this._stderr += data;
    for (const listener of this._stderrListeners) listener(data);
  }
  /** Readable stream of stdout (for use with StreamMessageReader, pipes, etc.) */
  get reader() {
    if (!this._reader) {
      this._reader = new Readable({ read() {
      } });
      void this.wait().then(
        () => this._reader.push(null),
        () => this._reader.push(null)
      );
    }
    return this._reader;
  }
  /** Writable stream to stdin (for use with StreamMessageWriter, pipes, etc.) */
  get writer() {
    if (!this._writer) {
      this._writer = new Writable({
        write: (chunk, _encoding, cb) => {
          this.sendStdin(chunk.toString()).then(() => cb(), cb);
        }
      });
    }
    return this._writer;
  }
};

// src/workspace/sandbox/process-manager/process-manager.ts
var SandboxProcessManager = class {
  /**
   * The sandbox this process manager belongs to.
   * Set automatically by MastraSandbox when processes are passed into the constructor.
   * @internal
   */
  sandbox;
  env;
  /** Tracked process handles keyed by PID. Populated by spawn(), used by get()/kill(). */
  _tracked = /* @__PURE__ */ new Map();
  /** PIDs that have been read after exit and should not be re-discovered by subclass fallbacks. */
  _dismissed = /* @__PURE__ */ new Set();
  constructor({ env = {} } = {}) {
    this.env = env;
    const impl = {
      spawn: this.spawn.bind(this),
      list: this.list.bind(this),
      get: this.get.bind(this)
    };
    this.spawn = async (...args) => {
      await this.sandbox.ensureRunning();
      const handle = await impl.spawn(...args);
      handle.command = args[0];
      return handle;
    };
    this.list = async () => {
      await this.sandbox.ensureRunning();
      return impl.list();
    };
    this.get = async (...args) => {
      await this.sandbox.ensureRunning();
      if (this._dismissed.has(args[0])) return void 0;
      const handle = await impl.get(...args);
      if (handle?.exitCode !== void 0) {
        this._tracked.delete(handle.pid);
        this._dismissed.add(handle.pid);
      }
      return handle;
    };
  }
  /** Spawn a process. */
  // eslint-disable-next-line @typescript-eslint/no-unused-vars
  async spawn(command, options = {}) {
    throw new Error(`${this.constructor.name} must implement spawn()`);
  }
  /** List all tracked processes. */
  async list() {
    throw new Error(`${this.constructor.name} must implement list()`);
  }
  /** Get a handle to a process by PID. Subclasses can override for fallback behavior. */
  async get(pid) {
    return this._tracked.get(pid);
  }
  /** Kill a process by PID. Returns true if killed, false if not found. */
  async kill(pid) {
    const handle = await this.get(pid);
    if (!handle) return false;
    const killed = await handle.kill();
    if (killed) {
      await handle.wait().catch(() => {
      });
    }
    this._tracked.delete(pid);
    this._dismissed.add(pid);
    return killed;
  }
};

// src/workspace/sandbox/local-process-manager.ts
var LocalProcessHandle = class extends ProcessHandle {
  pid;
  exitCode;
  proc;
  waitPromise;
  startTime;
  constructor(proc, startTime, options) {
    super(options);
    if (!proc.pid) {
      throw new Error("Process has no PID - it may have failed to spawn");
    }
    this.pid = proc.pid;
    this.proc = proc;
    this.startTime = startTime;
    let timedOut = false;
    const timeoutId = options?.timeout ? setTimeout(() => {
      timedOut = true;
      try {
        process.kill(-this.pid, "SIGTERM");
      } catch {
        proc.kill("SIGTERM");
      }
    }, options.timeout) : void 0;
    this.waitPromise = new Promise((resolve3) => {
      proc.on("close", (code, signal) => {
        if (timeoutId) clearTimeout(timeoutId);
        if (timedOut) {
          const timeoutMsg = `
Process timed out after ${options.timeout}ms`;
          this.emitStderr(timeoutMsg);
          this.exitCode = 124;
        } else {
          this.exitCode = signal && code === null ? 128 : code ?? 0;
        }
        resolve3({
          success: this.exitCode === 0,
          exitCode: this.exitCode,
          stdout: this.stdout,
          stderr: this.stderr,
          executionTimeMs: Date.now() - this.startTime,
          killed: signal !== null,
          timedOut
        });
      });
      proc.on("error", (err) => {
        if (timeoutId) clearTimeout(timeoutId);
        this.emitStderr(err.message);
        this.exitCode = 1;
        resolve3({
          success: false,
          exitCode: 1,
          stdout: this.stdout,
          stderr: this.stderr,
          executionTimeMs: Date.now() - this.startTime
        });
      });
    });
    proc.stdout?.on("data", (data) => {
      this.emitStdout(data.toString());
    });
    proc.stderr?.on("data", (data) => {
      this.emitStderr(data.toString());
    });
  }
  async wait() {
    return this.waitPromise;
  }
  async kill() {
    if (this.exitCode !== void 0) return false;
    try {
      process.kill(-this.pid, "SIGKILL");
      return true;
    } catch {
      return this.proc.kill("SIGKILL");
    }
  }
  async sendStdin(data) {
    if (this.exitCode !== void 0) {
      throw new Error(`Process ${this.pid} has already exited with code ${this.exitCode}`);
    }
    if (!this.proc.stdin) {
      throw new Error(`Process ${this.pid} does not have stdin available`);
    }
    return new Promise((resolve3, reject) => {
      this.proc.stdin.write(data, (err) => err ? reject(err) : resolve3());
    });
  }
};
var LocalProcessManager = class extends SandboxProcessManager {
  async spawn(command, options = {}) {
    const cwd = options.cwd ?? this.sandbox.workingDirectory;
    const env = this.sandbox.buildEnv(options.env);
    const wrapped = this.sandbox.wrapCommandForIsolation(command);
    const proc = childProcess.spawn(wrapped.command, wrapped.args, {
      cwd,
      env,
      shell: this.sandbox.isolation === "none",
      detached: true
    });
    const handle = new LocalProcessHandle(proc, Date.now(), options);
    this._tracked.set(handle.pid, handle);
    return handle;
  }
  async list() {
    return Array.from(this._tracked.values()).map((handle) => ({
      pid: handle.pid,
      running: handle.exitCode === void 0,
      exitCode: handle.exitCode
    }));
  }
};
function commandExists(command) {
  try {
    execFileSync("which", [command], { stdio: "ignore" });
    return true;
  } catch {
    return false;
  }
}
function isSeatbeltAvailable() {
  if (os__default.platform() !== "darwin") {
    return false;
  }
  return commandExists("sandbox-exec");
}
function isBwrapAvailable() {
  if (os__default.platform() !== "linux") {
    return false;
  }
  return commandExists("bwrap");
}
function detectIsolation() {
  const platform2 = os__default.platform();
  if (platform2 === "darwin") {
    const available = isSeatbeltAvailable();
    return {
      backend: "seatbelt",
      available,
      message: available ? "macOS seatbelt (sandbox-exec) is available" : "macOS seatbelt (sandbox-exec) not found - this is unexpected on macOS"
    };
  }
  if (platform2 === "linux") {
    const available = isBwrapAvailable();
    return {
      backend: "bwrap",
      available,
      message: available ? "Linux bubblewrap (bwrap) is available" : "Linux bubblewrap (bwrap) not found. Install with: apt install bubblewrap (Debian/Ubuntu) or dnf install bubblewrap (Fedora)"
    };
  }
  return {
    backend: "none",
    available: false,
    message: `Native sandboxing is not supported on ${platform2}. Commands will run without isolation.`
  };
}
function isIsolationAvailable(backend) {
  switch (backend) {
    case "seatbelt":
      return isSeatbeltAvailable();
    case "bwrap":
      return isBwrapAvailable();
    case "none":
      return true;
    default:
      return false;
  }
}
function getRecommendedIsolation() {
  const result = detectIsolation();
  return result.available ? result.backend : "none";
}

// src/workspace/sandbox/native-sandbox/seatbelt.ts
var MACH_SERVICES = [
  "com.apple.distributed_notifications@Uv3",
  "com.apple.logd",
  "com.apple.system.logger",
  "com.apple.system.notification_center",
  "com.apple.system.opendirectoryd.libinfo",
  "com.apple.system.opendirectoryd.membership",
  "com.apple.bsd.dirhelper",
  "com.apple.securityd.xpc",
  "com.apple.SecurityServer",
  "com.apple.trustd.agent"
];
function escapePath(pathStr) {
  return JSON.stringify(pathStr);
}
function generateSeatbeltProfile(workspacePath, config) {
  if (config.allowSystemBinaries === false) {
    throw new Error(
      "allowSystemBinaries: false is not supported by seatbelt (macOS). Use bubblewrap on Linux or remove this restriction."
    );
  }
  const lines = [];
  lines.push("(version 1)");
  lines.push('(deny default (with message "mastra-sandbox"))');
  lines.push("");
  lines.push("; Process permissions");
  lines.push("(allow process-exec)");
  lines.push("(allow process-fork)");
  lines.push("(allow process-info* (target same-sandbox))");
  lines.push("(allow signal (target same-sandbox))");
  lines.push("");
  lines.push("; Mach IPC");
  lines.push("(allow mach-lookup");
  for (const service of MACH_SERVICES) {
    lines.push(`  (global-name "${service}")`);
  }
  lines.push(")");
  lines.push("");
  lines.push("; IPC");
  lines.push("(allow ipc-posix-shm)");
  lines.push("(allow ipc-posix-sem)");
  lines.push("");
  lines.push("; User preferences");
  lines.push("(allow user-preference-read)");
  lines.push("");
  lines.push("; sysctl");
  lines.push("(allow sysctl-read)");
  lines.push("");
  lines.push("; Device files");
  lines.push('(allow file-ioctl (literal "/dev/null"))');
  lines.push('(allow file-ioctl (literal "/dev/zero"))');
  lines.push('(allow file-ioctl (literal "/dev/random"))');
  lines.push('(allow file-ioctl (literal "/dev/urandom"))');
  lines.push('(allow file-ioctl (literal "/dev/tty"))');
  lines.push("");
  lines.push("; File read access (allow all - macOS sandbox limitation)");
  lines.push("(allow file-read*)");
  for (const p of config.readOnlyPaths ?? []) {
    lines.push(`(allow file-read* (subpath ${escapePath(p)}))`);
  }
  lines.push("");
  lines.push("; File write access (restricted to workspace and temp)");
  lines.push(`(allow file-write* (subpath ${escapePath(workspacePath)}))`);
  lines.push('(allow file-write* (subpath "/private/tmp"))');
  lines.push('(allow file-write* (subpath "/var/folders"))');
  lines.push('(allow file-write* (subpath "/private/var/folders"))');
  for (const p of config.readWritePaths ?? []) {
    lines.push(`(allow file-write* (subpath ${escapePath(p)}))`);
  }
  lines.push("");
  lines.push("; Network");
  if (config.allowNetwork) {
    lines.push("(allow network*)");
  } else {
    lines.push('(deny network* (with message "mastra-sandbox-network"))');
  }
  return lines.join("\n");
}
function buildSeatbeltCommand(command, profile) {
  return {
    command: "sandbox-exec",
    args: ["-p", profile, "sh", "-c", command]
  };
}

// src/workspace/sandbox/native-sandbox/bubblewrap.ts
var DEFAULT_READONLY_BINDS = [
  "/usr",
  "/lib",
  "/lib64",
  "/bin",
  "/sbin",
  "/etc/alternatives",
  "/etc/ssl",
  "/etc/ca-certificates",
  "/etc/resolv.conf",
  "/etc/hosts",
  "/etc/passwd",
  "/etc/group",
  "/etc/nsswitch.conf",
  "/etc/ld.so.cache",
  "/etc/localtime"
];
function buildBwrapCommand(command, workspacePath, config) {
  if (config.bwrapArgs && config.bwrapArgs.length > 0) {
    return {
      command: "bwrap",
      args: [...config.bwrapArgs, "--", "sh", "-c", command]
    };
  }
  const bwrapArgs = [];
  bwrapArgs.push("--unshare-pid");
  bwrapArgs.push("--unshare-ipc");
  bwrapArgs.push("--unshare-uts");
  if (!config.allowNetwork) {
    bwrapArgs.push("--unshare-net");
  }
  bwrapArgs.push("--proc", "/proc");
  bwrapArgs.push("--tmpfs", "/tmp");
  for (const path6 of DEFAULT_READONLY_BINDS) {
    bwrapArgs.push("--ro-bind-try", path6, path6);
  }
  for (const path6 of config.readOnlyPaths ?? []) {
    bwrapArgs.push("--ro-bind", path6, path6);
  }
  if (config.allowSystemBinaries !== false) {
    const nodePath4 = process.execPath;
    const nodeDir = nodePath4.substring(0, nodePath4.lastIndexOf("/"));
    if (!DEFAULT_READONLY_BINDS.some((p) => nodeDir.startsWith(p))) {
      bwrapArgs.push("--ro-bind", nodeDir, nodeDir);
    }
    bwrapArgs.push("--ro-bind-try", "/opt", "/opt");
    bwrapArgs.push("--ro-bind-try", "/snap", "/snap");
  }
  bwrapArgs.push("--bind", workspacePath, workspacePath);
  for (const path6 of config.readWritePaths ?? []) {
    bwrapArgs.push("--bind", path6, path6);
  }
  bwrapArgs.push("--chdir", workspacePath);
  bwrapArgs.push("--die-with-parent");
  bwrapArgs.push("--", "sh", "-c", command);
  return {
    command: "bwrap",
    args: bwrapArgs
  };
}

// src/workspace/sandbox/native-sandbox/wrapper.ts
function wrapCommand(command, options) {
  switch (options.backend) {
    case "seatbelt": {
      const profile = options.seatbeltProfile ?? generateSeatbeltProfile(options.workspacePath, options.config);
      return buildSeatbeltCommand(command, profile);
    }
    case "bwrap": {
      return buildBwrapCommand(command, options.workspacePath, options.config);
    }
    case "none":
    default:
      return { command, args: [] };
  }
}

// src/workspace/sandbox/local-sandbox.ts
var LocalSandbox = class extends MastraSandbox {
  id;
  name = "LocalSandbox";
  provider = "local";
  status = "pending";
  workingDirectory;
  isolation;
  env;
  _nativeSandboxConfig;
  _seatbeltProfile;
  _seatbeltProfilePath;
  _sandboxFolderPath;
  _userProvidedProfilePath = false;
  _createdAt;
  _instructionsOverride;
  constructor(options = {}) {
    const requestedIsolation = options.isolation ?? "none";
    if (requestedIsolation !== "none" && !isIsolationAvailable(requestedIsolation)) {
      const detection = detectIsolation();
      throw new IsolationUnavailableError(requestedIsolation, detection.message);
    }
    super({
      ...options,
      name: "LocalSandbox",
      processes: new LocalProcessManager({ env: options.env ?? {} })
    });
    this.id = options.id ?? this.generateId();
    this._createdAt = /* @__PURE__ */ new Date();
    this.workingDirectory = options.workingDirectory ?? nodePath.join(process.cwd(), ".sandbox");
    this.env = options.env ?? {};
    this._nativeSandboxConfig = options.nativeSandbox ?? {};
    this.isolation = requestedIsolation;
    this._instructionsOverride = options.instructions;
  }
  // ---------------------------------------------------------------------------
  // Lifecycle
  // ---------------------------------------------------------------------------
  /**
   * Start the local sandbox.
   * Creates working directory and sets up seatbelt profile if using macOS isolation.
   * Status management is handled by the base class.
   */
  async start() {
    this.logger.debug("[LocalSandbox] Starting sandbox", {
      workingDirectory: this.workingDirectory,
      isolation: this.isolation
    });
    await fs2.mkdir(this.workingDirectory, { recursive: true });
    if (this.isolation === "seatbelt") {
      const userProvidedPath = this._nativeSandboxConfig.seatbeltProfilePath;
      if (userProvidedPath) {
        this._seatbeltProfilePath = userProvidedPath;
        this._userProvidedProfilePath = true;
        try {
          this._seatbeltProfile = await fs2.readFile(userProvidedPath, "utf-8");
        } catch (err) {
          if (err instanceof Error && "code" in err && err.code !== "ENOENT") {
            throw err;
          }
          this._seatbeltProfile = generateSeatbeltProfile(this.workingDirectory, this._nativeSandboxConfig);
          await fs2.mkdir(nodePath.dirname(userProvidedPath), { recursive: true });
          await fs2.writeFile(userProvidedPath, this._seatbeltProfile, "utf-8");
        }
      } else {
        this._seatbeltProfile = generateSeatbeltProfile(this.workingDirectory, this._nativeSandboxConfig);
        const configHash = crypto.createHash("sha256").update(this.workingDirectory).update(JSON.stringify(this._nativeSandboxConfig)).digest("hex").slice(0, 8);
        this._sandboxFolderPath = nodePath.join(process.cwd(), ".sandbox-profiles");
        await fs2.mkdir(this._sandboxFolderPath, { recursive: true });
        this._seatbeltProfilePath = nodePath.join(this._sandboxFolderPath, `seatbelt-${configHash}.sb`);
        await fs2.writeFile(this._seatbeltProfilePath, this._seatbeltProfile, "utf-8");
      }
    }
    this.logger.debug("[LocalSandbox] Sandbox started", { workingDirectory: this.workingDirectory });
  }
  /**
   * Stop the local sandbox.
   * Status management is handled by the base class.
   */
  async stop() {
    this.logger.debug("[LocalSandbox] Stopping sandbox", { workingDirectory: this.workingDirectory });
  }
  /**
   * Destroy the local sandbox and clean up resources.
   * Cleans up seatbelt profile if auto-generated.
   * Status management is handled by the base class.
   */
  async destroy() {
    this.logger.debug("[LocalSandbox] Destroying sandbox", { workingDirectory: this.workingDirectory });
    const procs = await this.processes.list();
    await Promise.all(procs.map((p) => this.processes.kill(p.pid)));
    if (this._seatbeltProfilePath && !this._userProvidedProfilePath) {
      try {
        await fs2.unlink(this._seatbeltProfilePath);
      } catch {
      }
    }
    this._seatbeltProfilePath = void 0;
    this._seatbeltProfile = void 0;
    this._userProvidedProfilePath = false;
    if (this._sandboxFolderPath) {
      try {
        await fs2.rmdir(this._sandboxFolderPath);
      } catch {
      }
      this._sandboxFolderPath = void 0;
    }
  }
  /** @deprecated Use `status === 'running'` instead. */
  async isReady() {
    return this.status === "running";
  }
  async getInfo() {
    return {
      id: this.id,
      name: this.name,
      provider: this.provider,
      status: this.status,
      createdAt: this._createdAt,
      resources: {
        memoryMB: Math.round(os.totalmem() / 1024 / 1024),
        cpuCores: os.cpus().length
      },
      metadata: {
        workingDirectory: this.workingDirectory,
        platform: os.platform(),
        nodeVersion: process.version,
        isolation: this.isolation,
        isolationConfig: this.isolation !== "none" ? {
          allowNetwork: this._nativeSandboxConfig.allowNetwork ?? false,
          readOnlyPaths: this._nativeSandboxConfig.readOnlyPaths,
          readWritePaths: this._nativeSandboxConfig.readWritePaths
        } : void 0
      }
    };
  }
  getInstructions(opts) {
    return resolveInstructions(this._instructionsOverride, () => this._getDefaultInstructions(), opts?.requestContext);
  }
  _getDefaultInstructions() {
    return `Local command execution. Working directory: "${this.workingDirectory}".`;
  }
  // ---------------------------------------------------------------------------
  // Internal Utils
  // ---------------------------------------------------------------------------
  generateId() {
    return `local-sandbox-${Date.now().toString(36)}-${Math.random().toString(36).slice(2, 8)}`;
  }
  /**
   * Build the environment object for execution.
   * Always includes PATH by default (needed for finding executables).
   * Merges the sandbox's configured env with any additional env from the command.
   * @internal Used by LocalProcessManager.
   */
  buildEnv(additionalEnv) {
    return {
      PATH: process.env.PATH,
      // Always include PATH for finding executables
      ...this.env,
      ...additionalEnv
    };
  }
  /**
   * Wrap a command with the configured isolation backend.
   * @internal Used by LocalProcessManager for background process isolation.
   */
  wrapCommandForIsolation(command) {
    if (this.isolation === "none") {
      return { command, args: [] };
    }
    return wrapCommand(command, {
      backend: this.isolation,
      workspacePath: this.workingDirectory,
      seatbeltProfile: this._seatbeltProfile,
      config: this._nativeSandboxConfig
    });
  }
  /**
   * Detect the best available isolation backend for this platform.
   * Returns detection result with backend recommendation and availability.
   *
   * @example
   * ```typescript
   * const result = LocalSandbox.detectIsolation();
   * const sandbox = new LocalSandbox({
   *   isolation: result.available ? result.backend : 'none',
   * });
   * ```
   */
  static detectIsolation() {
    return detectIsolation();
  }
};

// src/workspace/constants/index.ts
var WORKSPACE_TOOLS_PREFIX = "mastra_workspace";
var WORKSPACE_TOOLS = {
  FILESYSTEM: {
    READ_FILE: `${WORKSPACE_TOOLS_PREFIX}_read_file`,
    WRITE_FILE: `${WORKSPACE_TOOLS_PREFIX}_write_file`,
    EDIT_FILE: `${WORKSPACE_TOOLS_PREFIX}_edit_file`,
    LIST_FILES: `${WORKSPACE_TOOLS_PREFIX}_list_files`,
    DELETE: `${WORKSPACE_TOOLS_PREFIX}_delete`,
    FILE_STAT: `${WORKSPACE_TOOLS_PREFIX}_file_stat`,
    MKDIR: `${WORKSPACE_TOOLS_PREFIX}_mkdir`,
    GREP: `${WORKSPACE_TOOLS_PREFIX}_grep`,
    AST_EDIT: `${WORKSPACE_TOOLS_PREFIX}_ast_edit`
  },
  SANDBOX: {
    EXECUTE_COMMAND: `${WORKSPACE_TOOLS_PREFIX}_execute_command`,
    GET_PROCESS_OUTPUT: `${WORKSPACE_TOOLS_PREFIX}_get_process_output`,
    KILL_PROCESS: `${WORKSPACE_TOOLS_PREFIX}_kill_process`
  },
  SEARCH: {
    SEARCH: `${WORKSPACE_TOOLS_PREFIX}_search`,
    INDEX: `${WORKSPACE_TOOLS_PREFIX}_index`
  }
};
function requireWorkspace(context) {
  if (!context?.workspace) {
    throw new WorkspaceNotAvailableError();
  }
  return context.workspace;
}
function requireFilesystem(context) {
  const workspace = requireWorkspace(context);
  if (!workspace.filesystem) {
    throw new FilesystemNotAvailableError();
  }
  return { workspace, filesystem: workspace.filesystem };
}
function requireSandbox(context) {
  const workspace = requireWorkspace(context);
  if (!workspace.sandbox) {
    throw new SandboxNotAvailableError();
  }
  return { workspace, sandbox: workspace.sandbox };
}
async function emitWorkspaceMetadata(context, toolName) {
  const workspace = requireWorkspace(context);
  const info = await workspace.getInfo();
  const toolCallId = context?.agent?.toolCallId;
  await context?.writer?.custom({
    type: "data-workspace-metadata",
    data: { toolName, toolCallId, ...info }
  });
}
async function getEditDiagnosticsText(workspace, filePath, content) {
  try {
    const lspManager = workspace.lsp;
    if (!lspManager) return "";
    const absolutePath = workspace.filesystem?.resolveAbsolutePath?.(filePath) ?? nodePath__default.resolve(lspManager.root, filePath.replace(/^\/+/, ""));
    const DIAG_TIMEOUT_MS = 1e4;
    let diagTimer;
    const diagnostics = await Promise.race([
      lspManager.getDiagnostics(absolutePath, content),
      new Promise((_, reject) => {
        diagTimer = setTimeout(() => reject(new Error("LSP diagnostics timeout")), DIAG_TIMEOUT_MS);
      })
    ]).finally(() => clearTimeout(diagTimer));
    if (diagnostics.length === 0) return "";
    const seen = /* @__PURE__ */ new Set();
    const deduped = diagnostics.filter((d) => {
      const key = `${d.severity}:${d.line}:${d.character}:${d.message}`;
      if (seen.has(key)) return false;
      seen.add(key);
      return true;
    });
    const groups = {
      error: [],
      warning: [],
      info: [],
      hint: []
    };
    for (const d of deduped) {
      groups[d.severity].push(d);
    }
    const lines = ["\n\nLSP Diagnostics:"];
    const severityLabels = [
      ["error", "Errors"],
      ["warning", "Warnings"],
      ["info", "Info"],
      ["hint", "Hints"]
    ];
    for (const [severity, label] of severityLabels) {
      const items = groups[severity];
      if (items.length === 0) continue;
      lines.push(`${label}:`);
      for (const d of items) {
        const source = d.source ? ` [${d.source}]` : "";
        lines.push(`  ${d.line}:${d.character} - ${d.message}${source}`);
      }
    }
    let result = lines.join("\n");
    const maxChars = 2e3;
    if (result.length > maxChars) {
      const cutoff = result.lastIndexOf("\n", maxChars);
      result = result.slice(0, cutoff > 0 ? cutoff : maxChars) + "\n  ... (truncated)";
    }
    return result;
  } catch {
    return "";
  }
}

// src/workspace/tools/ast-edit.ts
var astGrepModule;
var loadingPromise;
async function loadAstGrep() {
  if (astGrepModule !== void 0) {
    return astGrepModule;
  }
  if (!loadingPromise) {
    loadingPromise = (async () => {
      try {
        const moduleName = "@ast-grep/napi";
        const mod = await import(
          /* webpackIgnore: true */
          moduleName
        );
        astGrepModule = { parse: mod.parse, Lang: mod.Lang };
        return astGrepModule;
      } catch {
        astGrepModule = null;
        return null;
      }
    })();
  }
  return loadingPromise;
}
function isAstGrepAvailable() {
  if (astGrepModule !== void 0) {
    return astGrepModule !== null;
  }
  try {
    const req = createRequire(import.meta.url);
    req.resolve("@ast-grep/napi");
    return true;
  } catch {
    return false;
  }
}
function getLanguageFromPath(filePath, Lang) {
  const ext = filePath.split(".").pop()?.toLowerCase();
  switch (ext) {
    case "ts":
      return Lang.TypeScript;
    case "tsx":
    case "jsx":
      return Lang.Tsx;
    case "js":
      return Lang.JavaScript;
    case "html":
      return Lang.Html;
    case "css":
      return Lang.Css;
    default:
      return null;
  }
}
function escapeRegex(str) {
  return str.replace(/[.*+?^${}()|[\]\\]/g, "\\$&");
}
function renameIdentifiers(content, root, oldName, newName) {
  let modifiedContent = content;
  let count = 0;
  const identifiers = root.findAll({
    rule: {
      kind: "identifier",
      regex: `^${escapeRegex(oldName)}$`
    }
  });
  const replacements = [];
  const seen = /* @__PURE__ */ new Set();
  for (const id of identifiers) {
    const range = id.range();
    if (seen.has(range.start.index)) continue;
    seen.add(range.start.index);
    replacements.push({ start: range.start.index, end: range.end.index, text: newName });
    count++;
  }
  replacements.sort((a, b) => b.start - a.start);
  for (const { start, end, text } of replacements) {
    modifiedContent = modifiedContent.slice(0, start) + text + modifiedContent.slice(end);
  }
  return { content: modifiedContent, count };
}
function buildImportStatement(defaultName, namedImports, moduleStr) {
  if (defaultName && namedImports.length > 0) {
    return `import ${defaultName}, { ${namedImports.join(", ")} } from ${moduleStr};`;
  } else if (defaultName) {
    return `import ${defaultName} from ${moduleStr};`;
  } else {
    return `import { ${namedImports.join(", ")} } from ${moduleStr};`;
  }
}
function mergeIntoExistingImport(content, existingImport, names, isDefault) {
  const text = existingImport.text();
  if (/^import\s+\*\s+as\s+/.test(text)) return null;
  const defaultMatch = text.match(/^import\s+(?!type\s)(?!\{)(\w+)/);
  const namedMatch = text.match(/\{([^}]*)\}/);
  const moduleMatch = text.match(/(["'][^"']+["'])\s*;?\s*$/);
  if (!moduleMatch) return null;
  const moduleStr = moduleMatch[1] ?? "";
  let existingDefault = defaultMatch ? defaultMatch[1] ?? null : null;
  const existingNamed = namedMatch ? (namedMatch[1] ?? "").split(",").map((s) => s.trim()).filter(Boolean) : [];
  let newDefault = existingDefault;
  const newNamed = [...existingNamed];
  if (isDefault && names.length > 0) {
    if (!existingDefault) {
      newDefault = names[0] ?? null;
    }
    for (const name of names.slice(1)) {
      if (!newNamed.includes(name)) {
        newNamed.push(name);
      }
    }
  } else {
    for (const name of names) {
      if (!newNamed.includes(name)) {
        newNamed.push(name);
      }
    }
  }
  const defaultChanged = newDefault !== existingDefault;
  const namedChanged = newNamed.length !== existingNamed.length;
  if (!defaultChanged && !namedChanged) return null;
  const importStatement = buildImportStatement(newDefault, newNamed, moduleStr);
  const range = existingImport.range();
  return content.slice(0, range.start.index) + importStatement + content.slice(range.end.index);
}
function addImport(content, root, importSpec) {
  const { module, names, isDefault } = importSpec;
  const imports = root.findAll({ rule: { kind: "import_statement" } });
  const existingImport = imports.find((imp) => {
    const text = imp.text();
    if (/^import\s+type\s/.test(text)) return false;
    if (/^import\s+\*\s+as\s+/.test(text)) return false;
    return text.includes(`'${module}'`) || text.includes(`"${module}"`);
  });
  if (existingImport) {
    return mergeIntoExistingImport(content, existingImport, names, isDefault) ?? content;
  }
  const moduleStr = `'${module}'`;
  const importStatement = buildImportStatement(
    isDefault ? names[0] : null,
    isDefault ? names.slice(1) : names,
    moduleStr
  );
  const lastImport = imports.at(-1);
  if (lastImport) {
    const pos = lastImport.range().end.index;
    return content.slice(0, pos) + "\n" + importStatement + content.slice(pos);
  } else {
    return importStatement + "\n\n" + content;
  }
}
function removeImport(content, root, targetName) {
  const imports = root.findAll({ rule: { kind: "import_statement" } });
  for (const imp of imports) {
    const text = imp.text();
    if (text.includes(`'${targetName}'`) || text.includes(`"${targetName}"`)) {
      const range = imp.range();
      const start = range.start.index;
      let end = range.end.index;
      if (content[end] === "\n") end++;
      return content.slice(0, start) + content.slice(end);
    }
  }
  return content;
}
function patternReplace(content, root, pattern, replacement) {
  let modifiedContent = content;
  let count = 0;
  try {
    const matches = root.findAll({ rule: { pattern } });
    const replacements = [];
    const metaVars = [...pattern.matchAll(/\$(\w+)/g)].map((m) => m[1]).filter((v) => v !== void 0);
    for (const match of matches) {
      const range = match.range();
      let replacementText = replacement;
      for (const varName of metaVars) {
        const matchedNode = match.getMatch(varName);
        if (matchedNode) {
          replacementText = replacementText.replace(new RegExp(`\\$${varName}`, "g"), matchedNode.text());
        }
      }
      replacements.push({ start: range.start.index, end: range.end.index, text: replacementText });
      count++;
    }
    replacements.sort((a, b) => b.start - a.start);
    for (const { start, end, text } of replacements) {
      modifiedContent = modifiedContent.slice(0, start) + text + modifiedContent.slice(end);
    }
  } catch (err) {
    return {
      content: modifiedContent,
      count: 0,
      error: err instanceof Error ? err.message : "Pattern matching failed"
    };
  }
  return { content: modifiedContent, count };
}
var astEditTool = createTool({
  id: WORKSPACE_TOOLS.FILESYSTEM.AST_EDIT,
  description: `Edit code using AST-based analysis for intelligent transformations.

Use \`transform\` for structured operations (imports, renames). Use \`pattern\`/\`replacement\` only for general find-and-replace.

Transforms:
- add-import: Add or merge imports. Skips duplicates. For default imports, put the default name first in \`names\`.
  { transform: "add-import", importSpec: { module: "react", names: ["useState", "useEffect"] } }
  { transform: "add-import", importSpec: { module: "express", names: ["express"], isDefault: true } }
  { transform: "add-import", importSpec: { module: "express", names: ["express", "Router"], isDefault: true } } \u2192 import express, { Router } from 'express'
- remove-import: Remove an import by module name.
  { transform: "remove-import", targetName: "lodash" }
- rename: Rename all occurrences of an identifier (not scope-aware).
  { transform: "rename", targetName: "oldName", newName: "newName" }

Pattern replace (for everything else):
  { pattern: "console.log($ARG)", replacement: "logger.debug($ARG)" }`,
  inputSchema: z.object({
    path: z.string().describe("The path to the file to edit"),
    pattern: z.string().optional().describe('AST pattern to search for (supports $VARIABLE placeholders, e.g., "console.log($ARG)")'),
    replacement: z.string().optional().describe('Replacement pattern (can use captured $VARIABLES, e.g., "logger.debug($ARG)")'),
    transform: z.enum(["add-import", "remove-import", "rename"]).optional().describe("Structured transformation to apply"),
    targetName: z.string().optional().describe("Required for remove-import and rename transforms. The current name to target."),
    newName: z.string().optional().describe("Required for rename transform. The new name to replace targetName with."),
    importSpec: z.object({
      module: z.string().describe("Module to import from"),
      names: z.array(z.string()).min(1).describe("Names to import. For default imports, put the default name first."),
      isDefault: z.boolean().optional().describe("Whether the first name is a default import")
    }).optional().describe("Required for add-import transform. Specifies the module and names to import.")
  }),
  execute: async ({ path: path6, pattern, replacement, transform, targetName, newName, importSpec }, context) => {
    const { workspace, filesystem } = requireFilesystem(context);
    await emitWorkspaceMetadata(context, WORKSPACE_TOOLS.FILESYSTEM.AST_EDIT);
    if (filesystem.readOnly) {
      throw new WorkspaceReadOnlyError("ast_edit");
    }
    const astGrep = await loadAstGrep();
    if (!astGrep) {
      return "@ast-grep/napi is not available. Install it to use AST editing.";
    }
    const { parse: parse2, Lang } = astGrep;
    let content;
    try {
      content = await filesystem.readFile(path6, { encoding: "utf-8" });
    } catch (error) {
      if (error instanceof FileNotFoundError) {
        return `File not found: ${path6}. Use ${WORKSPACE_TOOLS.FILESYSTEM.WRITE_FILE} to create it first.`;
      }
      throw error;
    }
    if (typeof content !== "string") {
      return `Cannot perform AST edits on binary files. Use ${WORKSPACE_TOOLS.FILESYSTEM.WRITE_FILE} instead.`;
    }
    const lang = getLanguageFromPath(path6, Lang);
    if (!lang) {
      return `Unsupported file type for AST editing: ${path6}`;
    }
    const ast = parse2(lang, content);
    const root = ast.root();
    let modifiedContent = content;
    const changes = [];
    if (transform) {
      switch (transform) {
        case "add-import": {
          if (!importSpec) {
            return "Error: importSpec is required for add-import transform";
          }
          modifiedContent = addImport(content, root, importSpec);
          changes.push(`Added import from '${importSpec.module}'`);
          break;
        }
        case "remove-import": {
          if (!targetName) {
            return "Error: targetName is required for remove-import transform";
          }
          modifiedContent = removeImport(content, root, targetName);
          changes.push(`Removed import '${targetName}'`);
          break;
        }
        case "rename": {
          if (!targetName || !newName) {
            return "Error: targetName and newName are required for rename transform";
          }
          const renameResult = renameIdentifiers(content, root, targetName, newName);
          modifiedContent = renameResult.content;
          changes.push(`Renamed '${targetName}' to '${newName}' (${renameResult.count} occurrences)`);
          break;
        }
      }
    } else if (pattern && replacement !== void 0) {
      const result = patternReplace(content, root, pattern, replacement);
      if (result.error) {
        return `Error: AST pattern matching failed: ${result.error}`;
      }
      modifiedContent = result.content;
      changes.push(`Replaced ${result.count} occurrences of pattern`);
    } else if (pattern && replacement === void 0) {
      return "Error: replacement is required when pattern is provided";
    } else if (!pattern && replacement !== void 0) {
      return "Error: pattern is required when replacement is provided";
    } else {
      return "Error: Must provide either transform or pattern/replacement";
    }
    const wasModified = modifiedContent !== content;
    if (wasModified) {
      await filesystem.writeFile(path6, modifiedContent, { overwrite: true });
    }
    if (!wasModified) {
      return `No changes made to ${path6} (${changes.join("; ")})`;
    }
    let output = `${path6}: ${changes.join("; ")}`;
    output += await getEditDiagnosticsText(workspace, path6, modifiedContent);
    return output;
  }
});
var deleteFileTool = createTool({
  id: WORKSPACE_TOOLS.FILESYSTEM.DELETE,
  description: "Delete a file or directory from the workspace filesystem",
  inputSchema: z.object({
    path: z.string().describe("The path to the file or directory to delete"),
    recursive: z.boolean().optional().default(false).describe("If true, delete directories and their contents recursively. Required for non-empty directories.")
  }),
  execute: async ({ path: path6, recursive }, context) => {
    const { filesystem } = requireFilesystem(context);
    await emitWorkspaceMetadata(context, WORKSPACE_TOOLS.FILESYSTEM.DELETE);
    if (filesystem.readOnly) {
      throw new WorkspaceReadOnlyError("delete");
    }
    const stat3 = await filesystem.stat(path6);
    if (stat3.type === "directory") {
      await filesystem.rmdir(path6, { recursive, force: recursive });
    } else {
      await filesystem.deleteFile(path6);
    }
    return `Deleted ${path6}`;
  }
});
var editFileTool = createTool({
  id: WORKSPACE_TOOLS.FILESYSTEM.EDIT_FILE,
  description: `Edit a file by replacing specific text. The old_string must match exactly and be unique in the file.

Usage:
- Read the file first to get the exact text to replace.
- By default, ${WORKSPACE_TOOLS.FILESYSTEM.READ_FILE} output includes line number prefixes (e.g., "     1\u2192"). Ensure you preserve the exact indentation as it appears AFTER the arrow. Never include any part of the line number prefix in old_string or new_string.
- Include enough surrounding context (multiple lines) to make old_string unique. If it still isn't unique, include more lines.
- Use replace_all only when intentionally replacing all occurrences.`,
  inputSchema: z.object({
    path: z.string().describe("The path to the file to edit"),
    old_string: z.string().describe("The exact text to find and replace. Must be unique in the file."),
    new_string: z.string().describe("The text to replace old_string with"),
    replace_all: z.boolean().optional().default(false).describe("If true, replace all occurrences. If false (default), old_string must be unique.")
  }),
  execute: async ({ path: path6, old_string, new_string, replace_all }, context) => {
    const { workspace, filesystem } = requireFilesystem(context);
    await emitWorkspaceMetadata(context, WORKSPACE_TOOLS.FILESYSTEM.EDIT_FILE);
    if (filesystem.readOnly) {
      throw new WorkspaceReadOnlyError("edit_file");
    }
    try {
      const content = await filesystem.readFile(path6, { encoding: "utf-8" });
      if (typeof content !== "string") {
        return `Cannot edit binary files. Use ${WORKSPACE_TOOLS.FILESYSTEM.WRITE_FILE} instead.`;
      }
      const result = replaceString(content, old_string, new_string, replace_all);
      await filesystem.writeFile(path6, result.content, { overwrite: true });
      let output = `Replaced ${result.replacements} occurrence${result.replacements !== 1 ? "s" : ""} in ${path6}`;
      output += await getEditDiagnosticsText(workspace, path6, result.content);
      return output;
    } catch (error) {
      if (error instanceof StringNotFoundError) {
        return error.message;
      }
      if (error instanceof StringNotUniqueError) {
        return error.message;
      }
      throw error;
    }
  }
});

// src/workspace/tools/output-helpers.ts
var DEFAULT_TAIL_LINES = 200;
var MAX_OUTPUT_CHARS = 3e4;
function applyTail(output, tail) {
  if (!output) return output;
  const n = Math.abs(tail ?? DEFAULT_TAIL_LINES);
  if (n === 0) return output;
  const trailingNewline = output.endsWith("\n");
  const lines = (trailingNewline ? output.slice(0, -1) : output).split("\n");
  if (lines.length <= n) return output;
  const sliced = lines.slice(-n).join("\n");
  const body = trailingNewline ? sliced + "\n" : sliced;
  return `[showing last ${n} of ${lines.length} lines]
${body}`;
}
function applyCharLimit(output, limit = MAX_OUTPUT_CHARS) {
  if (!output || output.length <= limit) return output;
  const truncated = output.slice(-limit);
  return `[output truncated: showing last ${limit} of ${output.length} characters]
${truncated}`;
}
function truncateOutput(output, tail, charLimit) {
  return applyCharLimit(applyTail(output, tail), charLimit);
}

// src/workspace/tools/execute-command.ts
var executeCommandInputSchema = z.object({
  command: z.string().describe('The shell command to execute (e.g., "npm install", "ls -la src/", "cat file.txt | grep error")'),
  timeout: z.number().nullish().describe("Maximum execution time in milliseconds. Example: 60000 for 1 minute."),
  cwd: z.string().nullish().describe("Working directory for the command"),
  tail: z.number().nullish().describe(
    `For foreground commands: limit output to the last N lines, similar to tail -n. Defaults to ${DEFAULT_TAIL_LINES}. Use 0 for no limit.`
  )
});
var executeCommandWithBackgroundSchema = executeCommandInputSchema.extend({
  background: z.boolean().optional().describe(
    "Run the command in the background. Returns a PID immediately instead of waiting for completion. Use get_process_output to check on it later."
  )
});
async function executeCommand(input, context) {
  const { command, timeout, cwd, tail } = input;
  const background = input.background;
  const { sandbox } = requireSandbox(context);
  await emitWorkspaceMetadata(context, WORKSPACE_TOOLS.SANDBOX.EXECUTE_COMMAND);
  const toolCallId = context?.agent?.toolCallId;
  if (background) {
    if (!sandbox.processes) {
      throw new SandboxFeatureNotSupportedError("processes");
    }
    const handle = await sandbox.processes.spawn(command, {
      cwd: cwd ?? void 0,
      timeout: timeout ?? void 0
    });
    return `Started background process (PID: ${handle.pid})`;
  }
  if (!sandbox.executeCommand) {
    throw new SandboxFeatureNotSupportedError("executeCommand");
  }
  const startedAt = Date.now();
  let stdout = "";
  let stderr = "";
  try {
    const result = await sandbox.executeCommand(command, [], {
      timeout: timeout ?? void 0,
      cwd: cwd ?? void 0,
      onStdout: async (data) => {
        stdout += data;
        await context?.writer?.custom({
          type: "data-sandbox-stdout",
          data: { output: data, timestamp: Date.now(), toolCallId }
        });
      },
      onStderr: async (data) => {
        stderr += data;
        await context?.writer?.custom({
          type: "data-sandbox-stderr",
          data: { output: data, timestamp: Date.now(), toolCallId }
        });
      }
    });
    await context?.writer?.custom({
      type: "data-sandbox-exit",
      data: {
        exitCode: result.exitCode,
        success: result.success,
        executionTimeMs: result.executionTimeMs,
        toolCallId
      }
    });
    if (!result.success) {
      const parts = [truncateOutput(result.stdout, tail), truncateOutput(result.stderr, tail)].filter(Boolean);
      parts.push(`Exit code: ${result.exitCode}`);
      return parts.join("\n");
    }
    return truncateOutput(result.stdout, tail) || "(no output)";
  } catch (error) {
    await context?.writer?.custom({
      type: "data-sandbox-exit",
      data: {
        exitCode: -1,
        success: false,
        executionTimeMs: Date.now() - startedAt,
        toolCallId
      }
    });
    const parts = [truncateOutput(stdout, tail), truncateOutput(stderr, tail)].filter(Boolean);
    const errorMessage = error instanceof Error ? error.message : String(error);
    parts.push(`Error: ${errorMessage}`);
    return parts.join("\n");
  }
}
var baseDescription = `Execute a shell command in the workspace sandbox.

Examples:
  "npm install && npm run build"
  "ls -la src/"
  "cat config.json | jq '.database'"
  "cd /app && python main.py"

Usage:
- Commands run in a shell, so pipes, redirects, and chaining (&&, ||, ;) all work.
- Always quote file paths that contain spaces (e.g., cd "/path/with spaces").
- Use the timeout parameter to limit execution time. Behavior when omitted depends on the sandbox provider.
- Optionally use cwd to override the working directory. Commands run from the sandbox default if omitted.`;
var executeCommandTool = createTool({
  id: WORKSPACE_TOOLS.SANDBOX.EXECUTE_COMMAND,
  description: baseDescription,
  inputSchema: executeCommandInputSchema,
  execute: executeCommand
});
var executeCommandWithBackgroundTool = createTool({
  id: WORKSPACE_TOOLS.SANDBOX.EXECUTE_COMMAND,
  description: `${baseDescription}

Set background: true to run long-running commands (dev servers, watchers) without blocking. You'll get a PID to track the process.`,
  inputSchema: executeCommandWithBackgroundSchema,
  execute: executeCommand
});
var fileStatTool = createTool({
  id: WORKSPACE_TOOLS.FILESYSTEM.FILE_STAT,
  description: "Get file or directory metadata from the workspace. Returns existence, type, size, and modification time.",
  inputSchema: z.object({
    path: z.string().describe("The path to check")
  }),
  execute: async ({ path: path6 }, context) => {
    const { filesystem } = requireFilesystem(context);
    await emitWorkspaceMetadata(context, WORKSPACE_TOOLS.FILESYSTEM.FILE_STAT);
    try {
      const stat3 = await filesystem.stat(path6);
      const modifiedAt = stat3.modifiedAt.toISOString();
      const parts = [`${path6}`, `Type: ${stat3.type}`];
      if (stat3.size !== void 0) parts.push(`Size: ${stat3.size} bytes`);
      parts.push(`Modified: ${modifiedAt}`);
      return parts.join(" ");
    } catch (error) {
      if (error instanceof FileNotFoundError) {
        return `${path6}: not found`;
      }
      throw error;
    }
  }
});
var getProcessOutputTool = createTool({
  id: WORKSPACE_TOOLS.SANDBOX.GET_PROCESS_OUTPUT,
  description: `Get the current output (stdout, stderr) and status of a background process by its PID.

Use this after starting a background command with execute_command (background: true) to check if the process is still running and read its output.`,
  inputSchema: z.object({
    pid: z.number().describe("The process ID returned when the background command was started"),
    tail: z.number().optional().describe(
      `Number of lines to return, similar to tail -n. Positive or negative returns last N lines from end. Defaults to ${DEFAULT_TAIL_LINES}. Use 0 for no limit.`
    ),
    wait: z.boolean().optional().describe(
      "If true, block until the process exits and return the final output. Useful for short-lived background commands where you want to wait for the result."
    )
  }),
  execute: async ({ pid, tail, wait: shouldWait }, context) => {
    const { sandbox } = requireSandbox(context);
    if (!sandbox.processes) {
      throw new SandboxFeatureNotSupportedError("processes");
    }
    await emitWorkspaceMetadata(context, WORKSPACE_TOOLS.SANDBOX.GET_PROCESS_OUTPUT);
    const toolCallId = context?.agent?.toolCallId;
    const handle = await sandbox.processes.get(pid);
    if (!handle) {
      return `No background process found with PID ${pid}.`;
    }
    if (handle.command) {
      await context?.writer?.custom({
        type: "data-sandbox-command",
        data: { command: handle.command, pid, toolCallId }
      });
    }
    if (shouldWait && handle.exitCode === void 0) {
      const result = await handle.wait({
        onStdout: context?.writer ? async (data) => {
          await context.writer.custom({
            type: "data-sandbox-stdout",
            data: { output: data, timestamp: Date.now(), toolCallId }
          });
        } : void 0,
        onStderr: context?.writer ? async (data) => {
          await context.writer.custom({
            type: "data-sandbox-stderr",
            data: { output: data, timestamp: Date.now(), toolCallId }
          });
        } : void 0
      });
      await context?.writer?.custom({
        type: "data-sandbox-exit",
        data: {
          exitCode: result.exitCode,
          success: result.success,
          executionTimeMs: result.executionTimeMs,
          toolCallId
        }
      });
    }
    const running = handle.exitCode === void 0;
    const stdout = truncateOutput(handle.stdout, tail);
    const stderr = truncateOutput(handle.stderr, tail);
    if (!stdout && !stderr) {
      return "(no output yet)";
    }
    const parts = [];
    if (stdout && stderr) {
      parts.push("stdout:", stdout, "", "stderr:", stderr);
    } else if (stdout) {
      parts.push(stdout);
    } else {
      parts.push("stderr:", stderr);
    }
    if (!running) {
      parts.push("", `Exit code: ${handle.exitCode}`);
    }
    return parts.join("\n");
  }
});
var grepTool = createTool({
  id: WORKSPACE_TOOLS.FILESYSTEM.GREP,
  description: `Search file contents using a regex pattern. Walks the filesystem and returns matching lines with file paths and line numbers.

Usage:
- Basic search: { pattern: "TODO" }
- Regex: { pattern: "function\\s+\\w+\\(" }
- Multiple terms: { pattern: "TODO|FIXME|HACK" }
- Case-insensitive: { pattern: "error", caseSensitive: false }
- Search in directory: { pattern: "import", path: "./src" }
- Filter by glob: { pattern: "import", path: "**/*.ts" }
- Combined path + glob: { pattern: "import", path: "src/**/*.ts" }
- Multiple file types: { pattern: "import", path: "**/*.{ts,tsx,js}" }
- Multiple directories: { pattern: "TODO", path: "{src,lib}/**/*.ts" }
- With context: { pattern: "function", contextLines: 2 }`,
  inputSchema: z.object({
    pattern: z.string().describe("Regex pattern to search for"),
    path: z.string().optional().default("./").describe(
      'File, directory, or glob pattern to search within (default: "./"). A plain path searches that file or directory. A glob pattern (e.g., "**/*.ts", "src/**/*.test.ts") filters which files to search.'
    ),
    contextLines: z.number().optional().default(0).describe("Number of lines of context to include before and after each match (default: 0)"),
    maxCount: z.number().optional().describe(
      "Maximum matches per file. Moves on to the next file after this many matches. Similar to grep -m flag."
    ),
    caseSensitive: z.boolean().optional().default(true).describe("Whether the search is case-sensitive (default: true)"),
    includeHidden: z.boolean().optional().default(false).describe('Include hidden files and directories (names starting with ".") in the search (default: false)')
  }),
  execute: async ({ pattern, path: inputPath = "./", contextLines = 0, maxCount, caseSensitive = true, includeHidden = false }, context) => {
    const { filesystem } = requireFilesystem(context);
    await emitWorkspaceMetadata(context, WORKSPACE_TOOLS.FILESYSTEM.GREP);
    const MAX_PATTERN_LENGTH = 1e3;
    if (pattern.length > MAX_PATTERN_LENGTH) {
      return `Error: Pattern too long (${pattern.length} chars, max ${MAX_PATTERN_LENGTH}). Use a shorter pattern.`;
    }
    let regex;
    try {
      regex = new RegExp(pattern, caseSensitive ? "g" : "gi");
    } catch (e) {
      return `Error: Invalid regex pattern: ${e.message}`;
    }
    let searchPath;
    let globMatcher;
    if (isGlobPattern(inputPath)) {
      searchPath = extractGlobBase(inputPath);
      globMatcher = createGlobMatcher(inputPath, { dot: includeHidden });
    } else {
      searchPath = inputPath;
    }
    let filePaths;
    try {
      const stat3 = await filesystem.stat(searchPath);
      if (stat3.type === "file") {
        filePaths = isTextFile(searchPath) ? [searchPath] : [];
      } else {
        const collectFiles = async (dir) => {
          const files = [];
          let entries;
          try {
            entries = await filesystem.readdir(dir);
          } catch {
            return files;
          }
          for (const entry of entries) {
            if (!includeHidden && entry.name.startsWith(".")) continue;
            const fullPath = dir.endsWith("/") ? `${dir}${entry.name}` : `${dir}/${entry.name}`;
            if (entry.type === "file") {
              if (!isTextFile(entry.name)) continue;
              if (globMatcher && !globMatcher(fullPath)) continue;
              files.push(fullPath);
            } else if (entry.type === "directory" && !entry.isSymlink) {
              files.push(...await collectFiles(fullPath));
            }
          }
          return files;
        };
        filePaths = await collectFiles(searchPath);
      }
    } catch {
      filePaths = [];
    }
    const outputLines = [];
    const filesWithMatches = /* @__PURE__ */ new Set();
    let totalMatchCount = 0;
    let truncated = false;
    const MAX_LINE_LENGTH = 500;
    const GLOBAL_CAP = 1e3;
    for (const filePath of filePaths) {
      if (truncated) break;
      let content;
      try {
        const raw = await filesystem.readFile(filePath, { encoding: "utf-8" });
        if (typeof raw !== "string") continue;
        content = raw;
      } catch {
        continue;
      }
      const lines = content.split("\n");
      let fileMatchCount = 0;
      for (let i = 0; i < lines.length; i++) {
        const currentLine = lines[i];
        regex.lastIndex = 0;
        const lineMatch = regex.exec(currentLine);
        if (!lineMatch) continue;
        filesWithMatches.add(filePath);
        let lineContent = currentLine;
        if (lineContent.length > MAX_LINE_LENGTH) {
          lineContent = lineContent.slice(0, MAX_LINE_LENGTH) + "...";
        }
        if (contextLines > 0) {
          const beforeStart = Math.max(0, i - contextLines);
          for (let b = beforeStart; b < i; b++) {
            outputLines.push(`${filePath}:${b + 1}- ${lines[b]}`);
          }
        }
        outputLines.push(`${filePath}:${i + 1}:${lineMatch.index + 1}: ${lineContent}`);
        if (contextLines > 0) {
          const afterEnd = Math.min(lines.length - 1, i + contextLines);
          for (let a = i + 1; a <= afterEnd; a++) {
            outputLines.push(`${filePath}:${a + 1}- ${lines[a]}`);
          }
          outputLines.push("--");
        }
        totalMatchCount++;
        fileMatchCount++;
        if (maxCount !== void 0 && fileMatchCount >= maxCount) break;
        if (totalMatchCount >= GLOBAL_CAP) {
          truncated = true;
          break;
        }
      }
    }
    outputLines.push("---");
    const parts = [`${totalMatchCount} match${totalMatchCount !== 1 ? "es" : ""}`];
    parts.push(`across ${filesWithMatches.size} file${filesWithMatches.size !== 1 ? "s" : ""}`);
    if (truncated) {
      parts.push(`(truncated at ${GLOBAL_CAP})`);
    }
    outputLines.push(parts.join(" "));
    return outputLines.join("\n");
  }
});
var indexContentTool = createTool({
  id: WORKSPACE_TOOLS.SEARCH.INDEX,
  description: "Index content for search. The path becomes the document ID in search results.",
  inputSchema: z.object({
    path: z.string().describe("The document ID/path for search results"),
    content: z.string().describe("The text content to index"),
    metadata: z.record(z.unknown()).optional().describe("Optional metadata to store with the document")
  }),
  execute: async ({ path: path6, content, metadata }, context) => {
    const workspace = requireWorkspace(context);
    await emitWorkspaceMetadata(context, WORKSPACE_TOOLS.SEARCH.INDEX);
    await workspace.index(path6, content, { metadata });
    return `Indexed ${path6}`;
  }
});
var KILL_TAIL_LINES = 50;
var killProcessTool = createTool({
  id: WORKSPACE_TOOLS.SANDBOX.KILL_PROCESS,
  description: `Kill a background process by its PID.

Use this to stop a long-running background process that was started with execute_command (background: true). Returns the last ${KILL_TAIL_LINES} lines of output.`,
  inputSchema: z.object({
    pid: z.number().describe("The process ID of the background process to kill")
  }),
  execute: async ({ pid }, context) => {
    const { sandbox } = requireSandbox(context);
    if (!sandbox.processes) {
      throw new SandboxFeatureNotSupportedError("processes");
    }
    await emitWorkspaceMetadata(context, WORKSPACE_TOOLS.SANDBOX.KILL_PROCESS);
    const toolCallId = context?.agent?.toolCallId;
    const handle = await sandbox.processes.get(pid);
    if (handle?.command) {
      await context?.writer?.custom({
        type: "data-sandbox-command",
        data: { command: handle.command, pid, toolCallId }
      });
    }
    const killed = await sandbox.processes.kill(pid);
    if (!killed) {
      await context?.writer?.custom({
        type: "data-sandbox-exit",
        data: { exitCode: handle?.exitCode ?? -1, success: false, killed: false, toolCallId }
      });
      return `Process ${pid} was not found or had already exited.`;
    }
    await context?.writer?.custom({
      type: "data-sandbox-exit",
      data: { exitCode: handle?.exitCode ?? 137, success: false, killed: true, toolCallId }
    });
    const parts = [`Process ${pid} has been killed.`];
    if (handle) {
      const stdout = handle.stdout ? truncateOutput(handle.stdout, KILL_TAIL_LINES) : "";
      const stderr = handle.stderr ? truncateOutput(handle.stderr, KILL_TAIL_LINES) : "";
      if (stdout) {
        parts.push("", "--- stdout (last output) ---", stdout);
      }
      if (stderr) {
        parts.push("", "--- stderr (last output) ---", stderr);
      }
    }
    return parts.join("\n");
  }
});

// src/workspace/tools/tree-formatter.ts
var BRANCH = "\u251C\u2500\u2500 ";
var LAST_BRANCH = "\u2514\u2500\u2500 ";
var VERTICAL = "\u2502   ";
var SPACE = "    ";
async function formatAsTree(fs5, path6, options) {
  const maxDepth = options?.maxDepth ?? Infinity;
  const showHidden = options?.showHidden ?? false;
  const dirsOnly = options?.dirsOnly ?? false;
  const exclude = options?.exclude;
  const extension = options?.extension;
  const pattern = options?.pattern;
  let globMatcher;
  if (pattern) {
    const patterns = Array.isArray(pattern) ? pattern : [pattern];
    globMatcher = createGlobMatcher(patterns, { dot: showHidden });
  }
  const lines = ["."];
  let dirCount = 0;
  let fileCount = 0;
  let truncated = false;
  async function buildTree(currentPath, prefix, depth) {
    if (depth >= maxDepth) {
      truncated = true;
      return;
    }
    let entries;
    try {
      entries = await fs5.readdir(currentPath);
    } catch (error) {
      if (depth === 0) {
        throw error;
      }
      return;
    }
    let filtered = entries;
    if (!showHidden) {
      filtered = filtered.filter((e) => !e.name.startsWith("."));
    }
    if (exclude) {
      const patterns = Array.isArray(exclude) ? exclude : [exclude];
      filtered = filtered.filter((e) => {
        return !patterns.some((pattern2) => e.name.includes(pattern2));
      });
    }
    if (dirsOnly) {
      filtered = filtered.filter((e) => e.type === "directory");
    }
    if (extension && !dirsOnly) {
      const extensions = Array.isArray(extension) ? extension : [extension];
      filtered = filtered.filter((e) => {
        if (e.type === "directory") return true;
        return extensions.some((ext) => {
          const normalizedExt = ext.startsWith(".") ? ext : `.${ext}`;
          return e.name.endsWith(normalizedExt);
        });
      });
    }
    if (globMatcher && !dirsOnly) {
      filtered = filtered.filter((e) => {
        if (e.type === "directory") return true;
        const entryPath = currentPath === path6 ? e.name : `${currentPath === "/" ? "" : currentPath}/${e.name}`;
        let relativePath;
        if (path6 === "/" || path6 === "") {
          relativePath = entryPath.startsWith("/") ? entryPath.slice(1) : entryPath;
        } else {
          relativePath = entryPath.startsWith(path6 + "/") ? entryPath.slice(path6.length + 1) : entryPath;
          if (!relativePath) relativePath = entryPath;
        }
        return globMatcher(relativePath);
      });
    }
    filtered.sort((a, b) => {
      if (a.type === "directory" && b.type !== "directory") return -1;
      if (a.type !== "directory" && b.type === "directory") return 1;
      return a.name < b.name ? -1 : a.name > b.name ? 1 : 0;
    });
    for (let i = 0; i < filtered.length; i++) {
      const entry = filtered[i];
      const isLast = i === filtered.length - 1;
      const connector = isLast ? LAST_BRANCH : BRANCH;
      const childPrefix = prefix + (isLast ? SPACE : VERTICAL);
      const displayName = entry.isSymlink && entry.symlinkTarget ? `${entry.name} -> ${entry.symlinkTarget}` : entry.name;
      lines.push(prefix + connector + displayName);
      if (entry.type === "directory") {
        dirCount++;
        if (!entry.isSymlink) {
          const childPath = joinPath2(currentPath, entry.name);
          await buildTree(childPath, childPrefix, depth + 1);
        }
      } else {
        fileCount++;
      }
    }
  }
  await buildTree(path6, "", 0);
  const dirPart = dirCount === 1 ? "1 directory" : `${dirCount} directories`;
  const filePart = fileCount === 1 ? "1 file" : `${fileCount} files`;
  let summary = `${dirPart}, ${filePart}`;
  if (truncated) {
    summary += ` (truncated at depth ${maxDepth})`;
  }
  return {
    tree: lines.join("\n"),
    summary,
    dirCount,
    fileCount,
    truncated
  };
}
function joinPath2(base, name) {
  if (base === "/" || base === "") {
    return `/${name}`;
  }
  return `${base}/${name}`;
}

// src/workspace/tools/list-files.ts
var listFilesTool = createTool({
  id: WORKSPACE_TOOLS.FILESYSTEM.LIST_FILES,
  description: `List files and directories in the workspace filesystem.
Returns a tree-style view (like the Unix "tree" command) for easy visualization.
The output is displayed to the user as a tree-like structure in the tool result.
Options mirror common tree command flags for familiarity.

Examples:
- List root: { path: "./" }
- Deep listing: { path: "./src", maxDepth: 5 }
- Directories only: { path: "./", dirsOnly: true }
- Exclude node_modules: { path: "./", exclude: "node_modules" }
- Find TypeScript files: { path: "./src", pattern: "**/*.ts" }
- Find config files: { path: "./", pattern: "*.config.{js,ts}" }
- Multiple patterns: { path: "./", pattern: ["**/*.ts", "**/*.tsx"] }`,
  inputSchema: z.object({
    path: z.string().default("./").describe("Directory path to list"),
    maxDepth: z.number().optional().default(3).describe("Maximum depth to descend (default: 3). Similar to tree -L flag."),
    showHidden: z.boolean().optional().default(false).describe('Show hidden files starting with "." (default: false). Similar to tree -a flag.'),
    dirsOnly: z.boolean().optional().default(false).describe("List directories only, no files (default: false). Similar to tree -d flag."),
    exclude: z.string().optional().describe('Pattern to exclude (e.g., "node_modules"). Similar to tree -I flag.'),
    extension: z.string().optional().describe('Filter by file extension (e.g., ".ts"). Similar to tree -P flag.'),
    pattern: z.union([z.string(), z.array(z.string())]).optional().describe(
      'Glob pattern(s) to filter files. Examples: "**/*.ts", "src/**/*.test.ts", "*.config.{js,ts}". Directories always pass through.'
    )
  }),
  execute: async ({ path: path6 = "./", maxDepth = 3, showHidden, dirsOnly, exclude, extension, pattern }, context) => {
    const { filesystem } = requireFilesystem(context);
    await emitWorkspaceMetadata(context, WORKSPACE_TOOLS.FILESYSTEM.LIST_FILES);
    const result = await formatAsTree(filesystem, path6, {
      maxDepth,
      showHidden,
      dirsOnly,
      exclude: exclude || void 0,
      extension: extension || void 0,
      pattern: pattern || void 0
    });
    return `${result.tree}

${result.summary}`;
  }
});
var mkdirTool = createTool({
  id: WORKSPACE_TOOLS.FILESYSTEM.MKDIR,
  description: "Create a directory in the workspace filesystem",
  inputSchema: z.object({
    path: z.string().describe("The path of the directory to create"),
    recursive: z.boolean().optional().default(true).describe("Whether to create parent directories if they do not exist")
  }),
  execute: async ({ path: path6, recursive }, context) => {
    const { filesystem } = requireFilesystem(context);
    await emitWorkspaceMetadata(context, WORKSPACE_TOOLS.FILESYSTEM.MKDIR);
    if (filesystem.readOnly) {
      throw new WorkspaceReadOnlyError("mkdir");
    }
    await filesystem.mkdir(path6, { recursive });
    return `Created directory ${path6}`;
  }
});
var readFileTool = createTool({
  id: WORKSPACE_TOOLS.FILESYSTEM.READ_FILE,
  description: "Read the contents of a file from the workspace filesystem. Use offset/limit parameters to read specific line ranges for large files.",
  inputSchema: z.object({
    path: z.string().describe('The path to the file to read (e.g., "/data/config.json")'),
    encoding: z.enum(["utf-8", "utf8", "base64", "hex", "binary"]).optional().describe("The encoding to use when reading the file. Defaults to utf-8 for text files."),
    offset: z.number().optional().describe("Line number to start reading from (1-indexed). If omitted, starts from line 1."),
    limit: z.number().optional().describe("Maximum number of lines to read. If omitted, reads to the end of the file."),
    showLineNumbers: z.boolean().optional().default(true).describe("Whether to prefix each line with its line number (default: true)")
  }),
  execute: async ({ path: path6, encoding, offset, limit, showLineNumbers }, context) => {
    const { filesystem } = requireFilesystem(context);
    await emitWorkspaceMetadata(context, WORKSPACE_TOOLS.FILESYSTEM.READ_FILE);
    const effectiveEncoding = encoding ?? "utf-8";
    const fullContent = await filesystem.readFile(path6, { encoding: effectiveEncoding });
    const stat3 = await filesystem.stat(path6);
    const isTextEncoding = !encoding || encoding === "utf-8" || encoding === "utf8";
    if (!isTextEncoding) {
      return `${stat3.path} (${stat3.size} bytes, ${effectiveEncoding})
${fullContent}`;
    }
    if (typeof fullContent !== "string") {
      return `${stat3.path} (${stat3.size} bytes, base64)
${fullContent.toString("base64")}`;
    }
    const hasLineRange = offset !== void 0 || limit !== void 0;
    const result = extractLinesWithLimit(fullContent, offset, limit);
    const shouldShowLineNumbers = showLineNumbers !== false;
    const formattedContent = shouldShowLineNumbers ? formatWithLineNumbers(result.content, result.lines.start) : result.content;
    let header;
    if (hasLineRange) {
      header = `${stat3.path} (lines ${result.lines.start}-${result.lines.end} of ${result.totalLines}, ${stat3.size} bytes)`;
    } else {
      header = `${stat3.path} (${stat3.size} bytes)`;
    }
    return `${header}
${formattedContent}`;
  }
});
var searchTool = createTool({
  id: WORKSPACE_TOOLS.SEARCH.SEARCH,
  description: "Search indexed content in the workspace. Supports keyword (BM25), semantic (vector), and hybrid search modes.",
  inputSchema: z.object({
    query: z.string().describe("The search query string"),
    topK: z.number().optional().default(5).describe("Maximum number of results to return"),
    mode: z.enum(["bm25", "vector", "hybrid"]).optional().describe("Search mode: bm25 for keyword search, vector for semantic search, hybrid for both combined"),
    minScore: z.number().optional().describe("Minimum score threshold (0-1 for normalized scores)")
  }),
  execute: async ({ query, topK, mode, minScore }, context) => {
    const workspace = requireWorkspace(context);
    await emitWorkspaceMetadata(context, WORKSPACE_TOOLS.SEARCH.SEARCH);
    const results = await workspace.search(query, {
      topK,
      mode,
      minScore
    });
    const effectiveMode = mode ?? (workspace.canHybrid ? "hybrid" : workspace.canVector ? "vector" : "bm25");
    const lines = results.map((r) => {
      const lineInfo = r.lineRange ? `:${r.lineRange.start}-${r.lineRange.end}` : "";
      return `${r.id}${lineInfo}: ${r.content}`;
    });
    lines.push("---");
    lines.push(`${results.length} result${results.length !== 1 ? "s" : ""} (${effectiveMode} search)`);
    return lines.join("\n");
  }
});
var writeFileTool = createTool({
  id: WORKSPACE_TOOLS.FILESYSTEM.WRITE_FILE,
  description: "Write content to a file in the workspace filesystem. Creates parent directories if needed.",
  inputSchema: z.object({
    path: z.string().describe('The path where to write the file (e.g., "/data/output.txt")'),
    content: z.string().describe("The content to write to the file"),
    overwrite: z.boolean().optional().default(true).describe("Whether to overwrite the file if it already exists")
  }),
  execute: async ({ path: path6, content, overwrite }, context) => {
    const { workspace, filesystem } = requireFilesystem(context);
    await emitWorkspaceMetadata(context, WORKSPACE_TOOLS.FILESYSTEM.WRITE_FILE);
    if (filesystem.readOnly) {
      throw new WorkspaceReadOnlyError("write_file");
    }
    await filesystem.writeFile(path6, content, { overwrite });
    const size = Buffer.byteLength(content, "utf-8");
    let output = `Wrote ${size} bytes to ${path6}`;
    output += await getEditDiagnosticsText(workspace, path6, content);
    return output;
  }
});

// src/workspace/tools/tools.ts
function resolveToolConfig(toolsConfig, toolName) {
  let enabled = true;
  let requireApproval = false;
  let requireReadBeforeWrite;
  if (toolsConfig) {
    if (toolsConfig.enabled !== void 0) {
      enabled = toolsConfig.enabled;
    }
    if (toolsConfig.requireApproval !== void 0) {
      requireApproval = toolsConfig.requireApproval;
    }
    const perToolConfig = toolsConfig[toolName];
    if (perToolConfig) {
      if (perToolConfig.enabled !== void 0) {
        enabled = perToolConfig.enabled;
      }
      if (perToolConfig.requireApproval !== void 0) {
        requireApproval = perToolConfig.requireApproval;
      }
      if (perToolConfig.requireReadBeforeWrite !== void 0) {
        requireReadBeforeWrite = perToolConfig.requireReadBeforeWrite;
      }
    }
  }
  return { enabled, requireApproval, requireReadBeforeWrite };
}
function wrapTool(tool, workspace, config) {
  return {
    ...tool,
    requireApproval: config.requireApproval,
    execute: async (input, context = {}) => {
      const enrichedContext = { ...context, workspace: context?.workspace ?? workspace };
      return tool.execute(input, enrichedContext);
    }
  };
}
function wrapWithReadTracker(tool, workspace, readTracker, config, mode) {
  return {
    ...tool,
    requireApproval: config.requireApproval,
    execute: async (input, context = {}) => {
      const enrichedContext = { ...context, workspace: context?.workspace ?? workspace };
      if (mode === "write" && config.requireReadBeforeWrite) {
        try {
          const stat3 = await workspace.filesystem.stat(input.path);
          const check = readTracker.needsReRead(input.path, stat3.modifiedAt);
          if (check.needsReRead) {
            throw new FileReadRequiredError(input.path, check.reason);
          }
        } catch (error) {
          if (!(error instanceof FileNotFoundError)) {
            throw error;
          }
        }
      }
      const result = await tool.execute(input, enrichedContext);
      if (mode === "read") {
        try {
          const stat3 = await workspace.filesystem.stat(input.path);
          readTracker.recordRead(input.path, stat3.modifiedAt);
        } catch {
        }
      } else if (mode === "write") {
        readTracker.clearReadRecord(input.path);
      }
      return result;
    }
  };
}
function wrapWithWriteLock(tool, writeLock) {
  return {
    ...tool,
    execute: async (input, context = {}) => {
      if (!input.path) {
        throw new Error("wrapWithWriteLock: input.path is required");
      }
      return writeLock.withLock(input.path, () => tool.execute(input, context));
    }
  };
}
function createWorkspaceTools(workspace) {
  const tools = {};
  const toolsConfig = workspace.getToolsConfig();
  const isReadOnly = workspace.filesystem?.readOnly ?? false;
  const writeLock = new InMemoryFileWriteLock();
  let readTracker;
  const writeFileConfig = resolveToolConfig(toolsConfig, WORKSPACE_TOOLS.FILESYSTEM.WRITE_FILE);
  const editFileConfig = resolveToolConfig(toolsConfig, WORKSPACE_TOOLS.FILESYSTEM.EDIT_FILE);
  const astEditConfig = resolveToolConfig(toolsConfig, WORKSPACE_TOOLS.FILESYSTEM.AST_EDIT);
  if (writeFileConfig.requireReadBeforeWrite || editFileConfig.requireReadBeforeWrite || astEditConfig.requireReadBeforeWrite) {
    readTracker = new InMemoryFileReadTracker();
  }
  const addTool = (name, tool, opts) => {
    const config = resolveToolConfig(toolsConfig, name);
    if (!config.enabled) return;
    if (opts?.requireWrite && isReadOnly) return;
    let wrapped;
    if (readTracker && opts?.readTrackerMode) {
      wrapped = wrapWithReadTracker(tool, workspace, readTracker, config, opts.readTrackerMode);
    } else {
      wrapped = wrapTool(tool, workspace, config);
    }
    if (opts?.useWriteLock) {
      wrapped = wrapWithWriteLock(wrapped, writeLock);
    }
    tools[name] = wrapped;
  };
  if (workspace.filesystem) {
    addTool(WORKSPACE_TOOLS.FILESYSTEM.READ_FILE, readFileTool, { readTrackerMode: "read" });
    addTool(WORKSPACE_TOOLS.FILESYSTEM.WRITE_FILE, writeFileTool, {
      requireWrite: true,
      readTrackerMode: "write",
      useWriteLock: true
    });
    addTool(WORKSPACE_TOOLS.FILESYSTEM.EDIT_FILE, editFileTool, {
      requireWrite: true,
      readTrackerMode: "write",
      useWriteLock: true
    });
    addTool(WORKSPACE_TOOLS.FILESYSTEM.LIST_FILES, listFilesTool);
    addTool(WORKSPACE_TOOLS.FILESYSTEM.DELETE, deleteFileTool, { requireWrite: true, useWriteLock: true });
    addTool(WORKSPACE_TOOLS.FILESYSTEM.FILE_STAT, fileStatTool);
    addTool(WORKSPACE_TOOLS.FILESYSTEM.MKDIR, mkdirTool, { requireWrite: true });
    addTool(WORKSPACE_TOOLS.FILESYSTEM.GREP, grepTool);
    if (isAstGrepAvailable()) {
      addTool(WORKSPACE_TOOLS.FILESYSTEM.AST_EDIT, astEditTool, {
        requireWrite: true,
        readTrackerMode: "write",
        useWriteLock: true
      });
    }
  }
  if (workspace.canBM25 || workspace.canVector) {
    addTool(WORKSPACE_TOOLS.SEARCH.SEARCH, searchTool);
    addTool(WORKSPACE_TOOLS.SEARCH.INDEX, indexContentTool, { requireWrite: true });
  }
  if (workspace.sandbox) {
    const executeCommandConfig = resolveToolConfig(toolsConfig, WORKSPACE_TOOLS.SANDBOX.EXECUTE_COMMAND);
    if (workspace.sandbox.executeCommand && executeCommandConfig.enabled) {
      const baseTool = workspace.sandbox.processes ? executeCommandWithBackgroundTool : executeCommandTool;
      tools[WORKSPACE_TOOLS.SANDBOX.EXECUTE_COMMAND] = wrapTool(baseTool, workspace, executeCommandConfig);
    }
    if (workspace.sandbox.processes) {
      addTool(WORKSPACE_TOOLS.SANDBOX.GET_PROCESS_OUTPUT, getProcessOutputTool);
      addTool(WORKSPACE_TOOLS.SANDBOX.KILL_PROCESS, killProcessTool);
    }
  }
  return tools;
}

export { BM25Index, CompositeFilesystem, CompositeVersionedSkillSource, DirectoryNotEmptyError, DirectoryNotFoundError, FileExistsError, FileNotFoundError, FileReadRequiredError, FilesystemError, FilesystemNotAvailableError, FilesystemNotMountableError, FilesystemNotReadyError, IsDirectoryError, IsolationUnavailableError, LocalFilesystem, LocalSandbox, LocalSkillSource, MastraFilesystem, MastraSandbox, MountError, MountManager, MountNotSupportedError, NotDirectoryError, PermissionError, ProcessHandle, SandboxError, SandboxExecutionError, SandboxFeatureNotSupportedError, SandboxNotAvailableError, SandboxNotReadyError, SandboxProcessManager, SandboxTimeoutError, SearchNotAvailableError, VersionedSkillSource, WORKSPACE_TOOLS, WORKSPACE_TOOLS_PREFIX, Workspace, WorkspaceError, WorkspaceNotAvailableError, WorkspaceNotReadyError, WorkspaceReadOnlyError, callLifecycle, collectSkillForPublish, createGlobMatcher, createWorkspaceTools, deleteFileTool, detectIsolation, editFileTool, executeCommandTool, extractGlobBase, extractLines, fileStatTool, getRecommendedIsolation, indexContentTool, isGlobPattern, isIsolationAvailable, listFilesTool, matchGlob, mkdirTool, publishSkillFromSource, readFileTool, requireFilesystem, requireSandbox, requireWorkspace, resolveToolConfig, searchTool, writeFileTool };
//# sourceMappingURL=chunk-4H5F6AFP.js.map
//# sourceMappingURL=chunk-4H5F6AFP.js.map